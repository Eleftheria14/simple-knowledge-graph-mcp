{
  "name": "DocsGPT-Correct-Node-Types",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "docsgpt-process",
        "responseMode": "lastNode",
        "responseData": "allEntries"
      },
      "id": "docsgpt-webhook",
      "name": "DocsGPT Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [240, 300],
      "webhookId": "docsgpt-process"
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Parse DocsGPT payload\nconst webhookData = $input.all()[0].json;\n\nlet documentData = {\n  file_path: webhookData.file_path || '/data/sample.pdf',\n  filename: webhookData.filename || 'sample.pdf',\n  user_id: webhookData.user_id || 'test_user',\n  batch_id: webhookData.batch_id || `batch_${Date.now()}`\n};\n\nconst documentId = documentData.filename\n  .replace('.pdf', '')\n  .replace(/[^a-zA-Z0-9]/g, '_')\n  .toLowerCase();\n\nreturn [{\n  json: {\n    ...documentData,\n    document_id: documentId,\n    processing_started: new Date().toISOString()\n  }\n}];"
      },
      "id": "parse-payload",
      "name": "Parse Payload", 
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 300]
    },
    {
      "parameters": {
        "resource": "parsing",
        "operation": "parse",
        "filePath": "={{ $json.file_path }}"
      },
      "id": "llamaparse-node",
      "name": "LlamaParse",
      "type": "CUSTOM.LlamaCloud",
      "typeVersion": 1,
      "position": [680, 300],
      "credentials": {
        "LlamaCloudApi": {
          "id": "llamacloud_creds",
          "name": "LlamaCloud API"
        }
      }
    },
    {
      "parameters": {
        "model": "llama-3.1-70b-versatile",
        "messages": {
          "values": [
            {
              "content": "Extract entities and relationships from this document. Return JSON format:\n{\n  \"entities\": [{\"id\": \"unique_id\", \"name\": \"entity_name\", \"type\": \"person|organization|concept\", \"description\": \"description\"}],\n  \"relationships\": [{\"source\": \"entity_id_1\", \"target\": \"entity_id_2\", \"type\": \"relationship_type\", \"context\": \"supporting_text\"}]\n}",
              "role": "system"
            },
            {
              "content": "Document: {{ $('Parse Payload').first().json.filename }}\n\nContent: {{ $('LlamaParse').first().json.text || $('LlamaParse').first().json.content || JSON.stringify($('LlamaParse').first().json) }}",
              "role": "user"
            }
          ]
        },
        "options": {
          "temperature": 0.1,
          "maxTokens": 3000
        }
      },
      "id": "groq-extraction",
      "name": "Groq Entity Extraction",
      "type": "n8n-nodes-base.llm",
      "typeVersion": 1,
      "position": [900, 300],
      "credentials": {
        "groqApi": {
          "id": "groq_creds",
          "name": "Groq API"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Process results and prepare for Neo4j\nconst payloadData = $('Parse Payload').first().json;\nconst llamaResult = $('LlamaParse').first().json;\nconst groqResult = $('Groq Entity Extraction').first().json;\n\n// Extract content\nlet content = llamaResult.text || llamaResult.content || JSON.stringify(llamaResult);\n\n// Parse extraction results\nlet extracted = { entities: [], relationships: [] };\ntry {\n  const groqContent = groqResult.text || groqResult.content || JSON.stringify(groqResult);\n  extracted = JSON.parse(groqContent);\n} catch (error) {\n  extracted = {\n    entities: [{ id: 'doc_entity', name: 'Document', type: 'concept', description: 'Main document' }],\n    relationships: []\n  };\n}\n\n// Create text chunks\nfunction createChunks(text, size = 500) {\n  const words = text.split(/\\s+/);\n  const chunks = [];\n  for (let i = 0; i < words.length; i += size) {\n    chunks.push(words.slice(i, i + size).join(' '));\n  }\n  return chunks;\n}\n\nconst textChunks = createChunks(content);\n\nreturn [{\n  json: {\n    document: {\n      id: payloadData.document_id,\n      title: payloadData.filename.replace('.pdf', ''),\n      filename: payloadData.filename,\n      content: content.substring(0, 5000)\n    },\n    entities: extracted.entities || [],\n    relationships: extracted.relationships || [],\n    text_chunks: textChunks\n  }\n}];"
      },
      "id": "prepare-data",
      "name": "Prepare Data",
      "type": "n8n-nodes-base.code", 
      "typeVersion": 2,
      "position": [1120, 300] 
    },
    {
      "parameters": {
        "operation": "addTexts",
        "texts": "={{ $json.text_chunks }}",
        "indexName": "document_vectors"
      },
      "id": "neo4j-vector",
      "name": "Neo4j Vector Store",
      "type": "n8n-nodes-neo4j.neo4j",
      "typeVersion": 1,
      "position": [1340, 200],
      "credentials": {
        "neo4jApi": {
          "id": "neo4j_creds",
          "name": "Neo4j Database"
        }
      }
    },
    {
      "parameters": {
        "operation": "executeQuery",
        "query": "CREATE (doc:Document {id: $doc.id, title: $doc.title, filename: $doc.filename, content: $doc.content, created_at: datetime()}) RETURN doc.id as document_created",
        "parameters": {
          "doc": "={{ $json.document }}"
        }
      },
      "id": "neo4j-graph",
      "name": "Neo4j Create Document",
      "type": "n8n-nodes-neo4j.neo4j",
      "typeVersion": 1,
      "position": [1340, 400],
      "credentials": {
        "neo4jApi": {
          "id": "neo4j_creds",
          "name": "Neo4j Database"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Format final response\nconst processedData = $('Prepare Data').first().json;\nconst vectorResult = $('Neo4j Vector Store').first().json;\nconst graphResult = $('Neo4j Create Document').first().json;\n\nconst response = {\n  success: true,\n  message: \"Document processed with correct node types!\",\n  document: processedData.document,\n  results: {\n    entities_extracted: processedData.entities.length,\n    relationships_extracted: processedData.relationships.length,  \n    chunks_created: processedData.text_chunks.length,\n    document_created: graphResult ? 1 : 0,\n    vectors_stored: processedData.text_chunks.length\n  },\n  node_types_used: {\n    llamaparse: 'CUSTOM.LlamaCloud ✅',\n    neo4j: 'n8n-nodes-neo4j.neo4j ✅',\n    standard_nodes: 'All working ✅'\n  },\n  processed_at: new Date().toISOString()\n};\n\nreturn { json: response };"
      },
      "id": "format-response",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1560, 300]
    }
  ],
  "connections": {
    "DocsGPT Webhook": {
      "main": [[{"node": "Parse Payload", "type": "main", "index": 0}]]
    },
    "Parse Payload": {
      "main": [[{"node": "LlamaParse", "type": "main", "index": 0}]]
    },
    "LlamaParse": {
      "main": [[{"node": "Groq Entity Extraction", "type": "main", "index": 0}]]
    },
    "Groq Entity Extraction": {
      "main": [[{"node": "Prepare Data", "type": "main", "index": 0}]]
    },
    "Prepare Data": {
      "main": [[
        {"node": "Neo4j Vector Store", "type": "main", "index": 0},
        {"node": "Neo4j Create Document", "type": "main", "index": 0}
      ]]
    },
    "Neo4j Vector Store": {
      "main": [[{"node": "Format Response", "type": "main", "index": 0}]]
    },
    "Neo4j Create Document": {
      "main": [[{"node": "Format Response", "type": "main", "index": 0}]]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "id": "docsgpt-correct-node-types",
  "tags": ["docsgpt", "correct-types", "CUSTOM.LlamaCloud", "n8n-nodes-neo4j.neo4j"],
  "meta": {
    "instanceId": "correct-node-types-workflow"
  }
}