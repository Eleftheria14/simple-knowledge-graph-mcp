{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔗 Tutorial 2: LangChain Fundamentals\n",
    "\n",
    "**Welcome back!** Now that you know how to chat with AI, let's learn how to work with documents and text files using LangChain.\n",
    "\n",
    "## 🎯 What You'll Learn:\n",
    "- What LangChain really does\n",
    "- How to load and read PDF files\n",
    "- How to break documents into smaller pieces\n",
    "- How to create \"prompts\" (instructions for AI)\n",
    "- How to build simple AI workflows\n",
    "\n",
    "## ⏱️ Time: 25-30 minutes\n",
    "## 📚 Level: Beginner\n",
    "## 📋 Prerequisites: Tutorial 1 completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤔 What is LangChain Really?\n",
    "\n",
    "In Tutorial 1, you used LangChain to chat with AI. But LangChain can do much more!\n",
    "\n",
    "### 🔧 Think of LangChain as a \"Toolkit\" for AI:\n",
    "- **Document Loaders**: Read PDF, Word, text files\n",
    "- **Text Splitters**: Break long documents into chunks\n",
    "- **Prompts**: Create better instructions for AI\n",
    "- **Chains**: Connect multiple AI steps together\n",
    "- **Memory**: Help AI remember previous conversations\n",
    "\n",
    "### 🌟 Real-World Example:\n",
    "Instead of just asking \"What's 2+2?\", you can:\n",
    "1. Load a 50-page research paper\n",
    "2. Ask \"What are the main findings in this paper?\"\n",
    "3. Get intelligent answers based on the actual content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Step 1: Setup and Imports\n",
    "\n",
    "Let's import the LangChain tools we'll need for working with documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools we need\n",
    "import sys\n",
    "sys.path.append('..')  # This lets us use our project files\n",
    "\n",
    "# LangChain tools for working with documents\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"📚 LangChain document tools imported!\")\n",
    "print(\"🔧 Ready to work with PDF files and text documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📄 Step 2: Loading Your First Document\n",
    "\n",
    "Let's learn how to load a PDF file. We'll use the example paper that comes with this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a PDF file\n",
    "print(\"📄 Loading a PDF document...\")\n",
    "\n",
    "# Path to our example paper\n",
    "pdf_path = \"../examples/d4sc03921a.pdf\"\n",
    "\n",
    "# Create a PDF loader\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "# Load the document\n",
    "print(\"⏳ Reading PDF... (this might take a few seconds)\")\n",
    "documents = pdf_loader.load()\n",
    "\n",
    "print(f\"✅ PDF loaded successfully!\")\n",
    "print(f\"📊 Number of pages: {len(documents)}\")\n",
    "print(f\"📝 First page has {len(documents[0].page_content)} characters\")\n",
    "\n",
    "# Let's see what the first page looks like\n",
    "print(\"\\n📖 First 200 characters of the paper:\")\n",
    "print(documents[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✂️ Step 3: Breaking Documents into Chunks\n",
    "\n",
    "AI models can only read a limited amount of text at once. So we need to break long documents into smaller \"chunks\".\n",
    "\n",
    "### 🧩 Why Split Documents?\n",
    "- **AI Limitation**: Can only process ~4000 words at once\n",
    "- **Better Answers**: Smaller chunks = more focused responses\n",
    "- **Efficiency**: Only use relevant parts of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text splitter\n",
    "print(\"✂️ Breaking document into smaller chunks...\")\n",
    "\n",
    "# This tool splits text intelligently\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # Each chunk is about 1000 characters\n",
    "    chunk_overlap=200,      # 200 characters overlap between chunks\n",
    "    length_function=len     # How to measure length\n",
    ")\n",
    "\n",
    "# Split our PDF into chunks\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"✅ Document split into {len(chunks)} chunks\")\n",
    "print(f\"📏 Average chunk size: {sum(len(chunk.page_content) for chunk in chunks) // len(chunks)} characters\")\n",
    "\n",
    "# Let's look at the first chunk\n",
    "print(\"\\n📝 First chunk:\")\n",
    "print(chunks[0].page_content)\n",
    "print(f\"\\n📊 This chunk has {len(chunks[0].page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💬 Step 4: Creating Better Prompts\n",
    "\n",
    "A \"prompt\" is like giving instructions to the AI. Good prompts get better answers!\n",
    "\n",
    "### 🎯 Prompt Tips:\n",
    "- Be specific about what you want\n",
    "- Give context and examples\n",
    "- Tell the AI what format to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a prompt template\n",
    "print(\"💬 Creating a smart prompt template...\")\n",
    "\n",
    "# This is a template for asking questions about documents\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant that reads scientific papers and answers questions.\n",
    "\n",
    "Here is a piece of text from a research paper:\n",
    "{document_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Please provide a clear, accurate answer based only on the text above. \n",
    "If the answer isn't in the text, say \"I can't find that information in this text.\"\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ Prompt template created!\")\n",
    "print(\"🎯 This template will help us ask better questions about documents\")\n",
    "\n",
    "# Let's see what the template looks like\n",
    "print(\"\\n📋 Our prompt template structure:\")\n",
    "print(\"   1. Tells AI it's a helpful assistant\")\n",
    "print(\"   2. Gives it the document text\")\n",
    "print(\"   3. Asks the specific question\")\n",
    "print(\"   4. Instructs how to answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔗 Step 5: Building Your First Chain\n",
    "\n",
    "A \"chain\" connects multiple steps together. Let's build a chain that can answer questions about documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AI assistant\n",
    "ai_assistant = ChatOllama(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0.1,    # Low temperature for factual answers\n",
    "    num_ctx=4096\n",
    ")\n",
    "\n",
    "# Create a chain: Prompt → AI → Text Output\n",
    "print(\"🔗 Building a document analysis chain...\")\n",
    "\n",
    "# This chain connects: prompt template → AI → text parser\n",
    "document_chain = prompt_template | ai_assistant | StrOutputParser()\n",
    "\n",
    "print(\"✅ Chain created!\")\n",
    "print(\"🔧 Chain flow: Prompt → AI → Clean Text Output\")\n",
    "print(\"📚 Ready to answer questions about documents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Step 6: Ask Questions About the Document\n",
    "\n",
    "Now let's use our chain to ask questions about the research paper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question about the first chunk\n",
    "print(\"🎯 Asking a question about the document...\")\n",
    "print(\"⏳ This might take 10-20 seconds...\")\n",
    "\n",
    "# Our question\n",
    "question = \"What is this paper about? Give me a brief summary.\"\n",
    "\n",
    "# Use the chain to get an answer\n",
    "answer = document_chain.invoke({\n",
    "    \"document_text\": chunks[0].page_content,  # Use first chunk\n",
    "    \"question\": question\n",
    "})\n",
    "\n",
    "print(f\"\\n❓ Question: {question}\")\n",
    "print(f\"\\n🤖 AI Answer:\")\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n💡 The AI read the document chunk and answered based on that content!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another question\n",
    "question2 = \"Who are the authors of this paper?\"\n",
    "\n",
    "print(f\"❓ Question: {question2}\")\n",
    "print(\"🤖 AI Answer:\")\n",
    "\n",
    "answer2 = document_chain.invoke({\n",
    "    \"document_text\": chunks[0].page_content,\n",
    "    \"question\": question2\n",
    "})\n",
    "\n",
    "print(answer2)\n",
    "\n",
    "print(\"\\n💡 The AI found author information in the document!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 7: Searching Through Multiple Chunks\n",
    "\n",
    "What if the answer isn't in the first chunk? Let's search through multiple chunks to find information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search through chunks for an answer\n",
    "def search_document(question, chunks, max_chunks=3):\n",
    "    \"\"\"Search through document chunks to find the best answer\"\"\"\n",
    "    \n",
    "    print(f\"🔍 Searching through {min(max_chunks, len(chunks))} chunks for: {question}\")\n",
    "    \n",
    "    best_answer = \"No relevant information found.\"\n",
    "    \n",
    "    for i, chunk in enumerate(chunks[:max_chunks]):\n",
    "        print(f\"   📄 Checking chunk {i+1}...\")\n",
    "        \n",
    "        answer = document_chain.invoke({\n",
    "            \"document_text\": chunk.page_content,\n",
    "            \"question\": question\n",
    "        })\n",
    "        \n",
    "        # If we get a useful answer (not \"can't find\"), use it\n",
    "        if \"can't find\" not in answer.lower() and \"not in\" not in answer.lower():\n",
    "            best_answer = answer\n",
    "            print(f\"   ✅ Found answer in chunk {i+1}!\")\n",
    "            break\n",
    "    \n",
    "    return best_answer\n",
    "\n",
    "# Test our search function\n",
    "question = \"What are the main conclusions or findings?\"\n",
    "answer = search_document(question, chunks, max_chunks=5)\n",
    "\n",
    "print(f\"\\n❓ Question: {question}\")\n",
    "print(f\"\\n🎯 Best Answer Found:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Step 8: Working with Different Document Types\n",
    "\n",
    "LangChain can work with many types of documents. Let's try creating and loading a simple text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple text file to practice with\n",
    "sample_text = \"\"\"\n",
    "Introduction to Machine Learning\n",
    "\n",
    "Machine learning is a type of artificial intelligence that allows computers to learn \n",
    "and make decisions without being explicitly programmed for every task.\n",
    "\n",
    "There are three main types of machine learning:\n",
    "1. Supervised Learning: Learning from examples with correct answers\n",
    "2. Unsupervised Learning: Finding patterns in data without examples\n",
    "3. Reinforcement Learning: Learning through trial and error with rewards\n",
    "\n",
    "Applications of machine learning include:\n",
    "- Email spam detection\n",
    "- Image recognition\n",
    "- Voice assistants\n",
    "- Recommendation systems\n",
    "\n",
    "Machine learning is used in many industries including healthcare, finance, \n",
    "transportation, and entertainment.\n",
    "\"\"\"\n",
    "\n",
    "# Save it as a text file\n",
    "with open(\"../tutorial/sample_text.txt\", \"w\") as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "print(\"📝 Created a sample text file!\")\n",
    "\n",
    "# Load the text file\n",
    "text_loader = TextLoader(\"../tutorial/sample_text.txt\")\n",
    "text_documents = text_loader.load()\n",
    "\n",
    "print(f\"✅ Text file loaded!\")\n",
    "print(f\"📊 Document length: {len(text_documents[0].page_content)} characters\")\n",
    "\n",
    "# Ask a question about our text\n",
    "question = \"What are the three types of machine learning?\"\n",
    "answer = document_chain.invoke({\n",
    "    \"document_text\": text_documents[0].page_content,\n",
    "    \"question\": question\n",
    "})\n",
    "\n",
    "print(f\"\\n❓ Question: {question}\")\n",
    "print(f\"🤖 Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Step 9: Experiment Time!\n",
    "\n",
    "Now it's your turn to experiment. Try different questions and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 YOUR TURN: Ask any question about the documents\n",
    "\n",
    "# Try questions about the research paper or the machine learning text\n",
    "your_question = \"What are some applications of machine learning?\"  # 👈 Change this!\n",
    "\n",
    "print(f\"❓ Your Question: {your_question}\")\n",
    "print(\"\\n🤖 Answer about the text file:\")\n",
    "\n",
    "# Answer from the text file\n",
    "answer = document_chain.invoke({\n",
    "    \"document_text\": text_documents[0].page_content,\n",
    "    \"question\": your_question\n",
    "})\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n🔍 Answer from searching the research paper:\")\n",
    "# Search through the research paper\n",
    "paper_answer = search_document(your_question, chunks, max_chunks=3)\n",
    "print(paper_answer)\n",
    "\n",
    "print(\"\\n💡 Notice how the AI gives different answers based on different documents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 What You've Learned\n",
    "\n",
    "**Excellent progress!** You've now learned the fundamentals of working with documents using LangChain.\n",
    "\n",
    "### ✅ **Key Concepts:**\n",
    "- **Document Loaders**: How to read PDF and text files\n",
    "- **Text Splitting**: Breaking long documents into manageable chunks\n",
    "- **Prompts**: Creating better instructions for AI\n",
    "- **Chains**: Connecting multiple steps together\n",
    "- **Document Search**: Finding information across multiple chunks\n",
    "\n",
    "### ✅ **Skills You've Gained:**\n",
    "- Loading and processing PDF files\n",
    "- Creating intelligent prompt templates\n",
    "- Building AI chains for document analysis\n",
    "- Searching through documents for specific information\n",
    "- Working with different document types\n",
    "\n",
    "### 🚀 **What's Next:**\n",
    "In **Tutorial 3**, you'll learn about **RAG (Retrieval-Augmented Generation)**:\n",
    "- What RAG means and why it's powerful\n",
    "- How to create embeddings (AI understanding of text)\n",
    "- How to find the most relevant parts of documents\n",
    "- Building a smart question-answering system\n",
    "\n",
    "### 🎯 **Practice Ideas:**\n",
    "- Try loading your own PDF files\n",
    "- Experiment with different chunk sizes\n",
    "- Create prompts for different types of questions\n",
    "- Test the system with various document types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏆 Final Challenge\n",
    "\n",
    "Test your understanding with this challenge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏆 CHALLENGE: Create a document summarizer\n",
    "print(\"🏆 FINAL CHALLENGE: Build a Document Summarizer\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# TODO: Create a prompt template that asks for a summary\n",
    "summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Please read this text and provide a brief, 2-3 sentence summary:\n",
    "\n",
    "{text}\n",
    "\n",
    "Summary:\n",
    "\"\"\")\n",
    "\n",
    "# TODO: Create a chain for summarizing\n",
    "summary_chain = summary_prompt | ai_assistant | StrOutputParser()\n",
    "\n",
    "# Test it on our machine learning text\n",
    "summary = summary_chain.invoke({\"text\": text_documents[0].page_content})\n",
    "\n",
    "print(\"📄 Original Text Length:\", len(text_documents[0].page_content), \"characters\")\n",
    "print(\"\\n📝 AI Summary:\")\n",
    "print(summary)\n",
    "print(\"\\n📊 Summary Length:\", len(summary), \"characters\")\n",
    "\n",
    "print(\"\\n🎉 Challenge Complete! You've built a document summarizer!\")\n",
    "print(\"🚀 Ready for Tutorial 3: Understanding RAG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}