{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”— Tutorial 2: LangChain Fundamentals\n",
    "\n",
    "**Welcome back!** Now that you know how to chat with AI, let's learn how to work with documents and text files using LangChain.\n",
    "\n",
    "## ğŸ¯ What You'll Learn:\n",
    "- What LangChain really does\n",
    "- How to load and read PDF files\n",
    "- How to break documents into smaller pieces\n",
    "- How to create \"prompts\" (instructions for AI)\n",
    "- How to build simple AI workflows\n",
    "\n",
    "## â±ï¸ Time: 25-30 minutes\n",
    "## ğŸ“š Level: Beginner\n",
    "## ğŸ“‹ Prerequisites: Tutorial 1 completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤” What is LangChain Really?\n",
    "\n",
    "In Tutorial 1, you used LangChain to chat with AI. But LangChain can do much more!\n",
    "\n",
    "### ğŸ”§ Think of LangChain as a \"Toolkit\" for AI:\n",
    "- **Document Loaders**: Read PDF, Word, text files\n",
    "- **Text Splitters**: Break long documents into chunks\n",
    "- **Prompts**: Create better instructions for AI\n",
    "- **Chains**: Connect multiple AI steps together\n",
    "- **Memory**: Help AI remember previous conversations\n",
    "\n",
    "### ğŸŒŸ Real-World Example:\n",
    "Instead of just asking \"What's 2+2?\", you can:\n",
    "1. Load a 50-page research paper\n",
    "2. Ask \"What are the main findings in this paper?\"\n",
    "3. Get intelligent answers based on the actual content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Step 1: Setup and Imports\n",
    "\n",
    "Let's import the LangChain tools we'll need for working with documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools we need\n",
    "import sys\n",
    "sys.path.append('..')  # This lets us use our project files\n",
    "\n",
    "# LangChain tools for working with documents\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"ğŸ“š LangChain document tools imported!\")\n",
    "print(\"ğŸ”§ Ready to work with PDF files and text documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ Step 2: Loading Your First Document\n",
    "\n",
    "Let's learn how to load a PDF file. We'll use the example paper that comes with this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a PDF file\n",
    "print(\"ğŸ“„ Loading a PDF document...\")\n",
    "\n",
    "# Path to our example paper\n",
    "pdf_path = \"../examples/d4sc03921a.pdf\"\n",
    "\n",
    "# Create a PDF loader\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "\n",
    "# Load the document\n",
    "print(\"â³ Reading PDF... (this might take a few seconds)\")\n",
    "documents = pdf_loader.load()\n",
    "\n",
    "print(f\"âœ… PDF loaded successfully!\")\n",
    "print(f\"ğŸ“Š Number of pages: {len(documents)}\")\n",
    "print(f\"ğŸ“ First page has {len(documents[0].page_content)} characters\")\n",
    "\n",
    "# Let's see what the first page looks like\n",
    "print(\"\\nğŸ“– First 200 characters of the paper:\")\n",
    "print(documents[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Step 3: Breaking Documents into Chunks\n",
    "\n",
    "AI models can only read a limited amount of text at once. So we need to break long documents into smaller \"chunks\".\n",
    "\n",
    "### ğŸ§© Why Split Documents?\n",
    "- **AI Limitation**: Can only process ~4000 words at once\n",
    "- **Better Answers**: Smaller chunks = more focused responses\n",
    "- **Efficiency**: Only use relevant parts of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text splitter\n",
    "print(\"âœ‚ï¸ Breaking document into smaller chunks...\")\n",
    "\n",
    "# This tool splits text intelligently\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # Each chunk is about 1000 characters\n",
    "    chunk_overlap=200,      # 200 characters overlap between chunks\n",
    "    length_function=len     # How to measure length\n",
    ")\n",
    "\n",
    "# Split our PDF into chunks\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"âœ… Document split into {len(chunks)} chunks\")\n",
    "print(f\"ğŸ“ Average chunk size: {sum(len(chunk.page_content) for chunk in chunks) // len(chunks)} characters\")\n",
    "\n",
    "# Let's look at the first chunk\n",
    "print(\"\\nğŸ“ First chunk:\")\n",
    "print(chunks[0].page_content)\n",
    "print(f\"\\nğŸ“Š This chunk has {len(chunks[0].page_content)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¬ Step 4: Creating Better Prompts\n",
    "\n",
    "A \"prompt\" is like giving instructions to the AI. Good prompts get better answers!\n",
    "\n",
    "### ğŸ¯ Prompt Tips:\n",
    "- Be specific about what you want\n",
    "- Give context and examples\n",
    "- Tell the AI what format to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a prompt template\n",
    "print(\"ğŸ’¬ Creating a smart prompt template...\")\n",
    "\n",
    "# This is a template for asking questions about documents\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant that reads scientific papers and answers questions.\n",
    "\n",
    "Here is a piece of text from a research paper:\n",
    "{document_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Please provide a clear, accurate answer based only on the text above. \n",
    "If the answer isn't in the text, say \"I can't find that information in this text.\"\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… Prompt template created!\")\n",
    "print(\"ğŸ¯ This template will help us ask better questions about documents\")\n",
    "\n",
    "# Let's see what the template looks like\n",
    "print(\"\\nğŸ“‹ Our prompt template structure:\")\n",
    "print(\"   1. Tells AI it's a helpful assistant\")\n",
    "print(\"   2. Gives it the document text\")\n",
    "print(\"   3. Asks the specific question\")\n",
    "print(\"   4. Instructs how to answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— Step 5: Building Your First Chain\n",
    "\n",
    "A \"chain\" connects multiple steps together. Let's build a chain that can answer questions about documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AI assistant\n",
    "ai_assistant = ChatOllama(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0.1,    # Low temperature for factual answers\n",
    "    num_ctx=4096\n",
    ")\n",
    "\n",
    "# Create a chain: Prompt â†’ AI â†’ Text Output\n",
    "print(\"ğŸ”— Building a document analysis chain...\")\n",
    "\n",
    "# This chain connects: prompt template â†’ AI â†’ text parser\n",
    "document_chain = prompt_template | ai_assistant | StrOutputParser()\n",
    "\n",
    "print(\"âœ… Chain created!\")\n",
    "print(\"ğŸ”§ Chain flow: Prompt â†’ AI â†’ Clean Text Output\")\n",
    "print(\"ğŸ“š Ready to answer questions about documents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Step 6: Ask Questions About the Document\n",
    "\n",
    "Now let's use our chain to ask questions about the research paper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question about the first chunk\n",
    "print(\"ğŸ¯ Asking a question about the document...\")\n",
    "print(\"â³ This might take 10-20 seconds...\")\n",
    "\n",
    "# Our question\n",
    "question = \"What is this paper about? Give me a brief summary.\"\n",
    "\n",
    "# Use the chain to get an answer\n",
    "answer = document_chain.invoke({\n",
    "    \"document_text\": chunks[0].page_content,  # Use first chunk\n",
    "    \"question\": question\n",
    "})\n",
    "\n",
    "print(f\"\\nâ“ Question: {question}\")\n",
    "print(f\"\\nğŸ¤– AI Answer:\")\n",
    "print(answer)\n",
    "\n",
    "print(\"\\nğŸ’¡ The AI read the document chunk and answered based on that content!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try another question\n",
    "question2 = \"Who are the authors of this paper?\"\n",
    "\n",
    "print(f\"â“ Question: {question2}\")\n",
    "print(\"ğŸ¤– AI Answer:\")\n",
    "\n",
    "answer2 = document_chain.invoke({\n",
    "    \"document_text\": chunks[0].page_content,\n",
    "    \"question\": question2\n",
    "})\n",
    "\n",
    "print(answer2)\n",
    "\n",
    "print(\"\\nğŸ’¡ The AI found author information in the document!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Step 7: Searching Through Multiple Chunks\n",
    "\n",
    "What if the answer isn't in the first chunk? Let's search through multiple chunks to find information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search through chunks for an answer\n",
    "def search_document(question, chunks, max_chunks=3):\n",
    "    \"\"\"Search through document chunks to find the best answer\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ” Searching through {min(max_chunks, len(chunks))} chunks for: {question}\")\n",
    "    \n",
    "    best_answer = \"No relevant information found.\"\n",
    "    \n",
    "    for i, chunk in enumerate(chunks[:max_chunks]):\n",
    "        print(f\"   ğŸ“„ Checking chunk {i+1}...\")\n",
    "        \n",
    "        answer = document_chain.invoke({\n",
    "            \"document_text\": chunk.page_content,\n",
    "            \"question\": question\n",
    "        })\n",
    "        \n",
    "        # If we get a useful answer (not \"can't find\"), use it\n",
    "        if \"can't find\" not in answer.lower() and \"not in\" not in answer.lower():\n",
    "            best_answer = answer\n",
    "            print(f\"   âœ… Found answer in chunk {i+1}!\")\n",
    "            break\n",
    "    \n",
    "    return best_answer\n",
    "\n",
    "# Test our search function\n",
    "question = \"What are the main conclusions or findings?\"\n",
    "answer = search_document(question, chunks, max_chunks=5)\n",
    "\n",
    "print(f\"\\nâ“ Question: {question}\")\n",
    "print(f\"\\nğŸ¯ Best Answer Found:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 8: Working with Different Document Types\n",
    "\n",
    "LangChain can work with many types of documents. Let's try creating and loading a simple text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple text file to practice with\n",
    "sample_text = \"\"\"\n",
    "Introduction to Machine Learning\n",
    "\n",
    "Machine learning is a type of artificial intelligence that allows computers to learn \n",
    "and make decisions without being explicitly programmed for every task.\n",
    "\n",
    "There are three main types of machine learning:\n",
    "1. Supervised Learning: Learning from examples with correct answers\n",
    "2. Unsupervised Learning: Finding patterns in data without examples\n",
    "3. Reinforcement Learning: Learning through trial and error with rewards\n",
    "\n",
    "Applications of machine learning include:\n",
    "- Email spam detection\n",
    "- Image recognition\n",
    "- Voice assistants\n",
    "- Recommendation systems\n",
    "\n",
    "Machine learning is used in many industries including healthcare, finance, \n",
    "transportation, and entertainment.\n",
    "\"\"\"\n",
    "\n",
    "# Save it as a text file\n",
    "with open(\"../tutorial/sample_text.txt\", \"w\") as f:\n",
    "    f.write(sample_text)\n",
    "\n",
    "print(\"ğŸ“ Created a sample text file!\")\n",
    "\n",
    "# Load the text file\n",
    "text_loader = TextLoader(\"../tutorial/sample_text.txt\")\n",
    "text_documents = text_loader.load()\n",
    "\n",
    "print(f\"âœ… Text file loaded!\")\n",
    "print(f\"ğŸ“Š Document length: {len(text_documents[0].page_content)} characters\")\n",
    "\n",
    "# Ask a question about our text\n",
    "question = \"What are the three types of machine learning?\"\n",
    "answer = document_chain.invoke({\n",
    "    \"document_text\": text_documents[0].page_content,\n",
    "    \"question\": question\n",
    "})\n",
    "\n",
    "print(f\"\\nâ“ Question: {question}\")\n",
    "print(f\"ğŸ¤– Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Step 9: Experiment Time!\n",
    "\n",
    "Now it's your turn to experiment. Try different questions and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ YOUR TURN: Ask any question about the documents\n",
    "\n",
    "# Try questions about the research paper or the machine learning text\n",
    "your_question = \"What are some applications of machine learning?\"  # ğŸ‘ˆ Change this!\n",
    "\n",
    "print(f\"â“ Your Question: {your_question}\")\n",
    "print(\"\\nğŸ¤– Answer about the text file:\")\n",
    "\n",
    "# Answer from the text file\n",
    "answer = document_chain.invoke({\n",
    "    \"document_text\": text_documents[0].page_content,\n",
    "    \"question\": your_question\n",
    "})\n",
    "print(answer)\n",
    "\n",
    "print(\"\\nğŸ” Answer from searching the research paper:\")\n",
    "# Search through the research paper\n",
    "paper_answer = search_document(your_question, chunks, max_chunks=3)\n",
    "print(paper_answer)\n",
    "\n",
    "print(\"\\nğŸ’¡ Notice how the AI gives different answers based on different documents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ What You've Learned\n",
    "\n",
    "**Excellent progress!** You've now learned the fundamentals of working with documents using LangChain.\n",
    "\n",
    "### âœ… **Key Concepts:**\n",
    "- **Document Loaders**: How to read PDF and text files\n",
    "- **Text Splitting**: Breaking long documents into manageable chunks\n",
    "- **Prompts**: Creating better instructions for AI\n",
    "- **Chains**: Connecting multiple steps together\n",
    "- **Document Search**: Finding information across multiple chunks\n",
    "\n",
    "### âœ… **Skills You've Gained:**\n",
    "- Loading and processing PDF files\n",
    "- Creating intelligent prompt templates\n",
    "- Building AI chains for document analysis\n",
    "- Searching through documents for specific information\n",
    "- Working with different document types\n",
    "\n",
    "### ğŸš€ **What's Next:**\n",
    "In **Tutorial 3**, you'll learn about **RAG (Retrieval-Augmented Generation)**:\n",
    "- What RAG means and why it's powerful\n",
    "- How to create embeddings (AI understanding of text)\n",
    "- How to find the most relevant parts of documents\n",
    "- Building a smart question-answering system\n",
    "\n",
    "### ğŸ¯ **Practice Ideas:**\n",
    "- Try loading your own PDF files\n",
    "- Experiment with different chunk sizes\n",
    "- Create prompts for different types of questions\n",
    "- Test the system with various document types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ† Final Challenge\n",
    "\n",
    "Test your understanding with this challenge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ† CHALLENGE: Create a document summarizer\n",
    "print(\"ğŸ† FINAL CHALLENGE: Build a Document Summarizer\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# TODO: Create a prompt template that asks for a summary\n",
    "summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Please read this text and provide a brief, 2-3 sentence summary:\n",
    "\n",
    "{text}\n",
    "\n",
    "Summary:\n",
    "\"\"\")\n",
    "\n",
    "# TODO: Create a chain for summarizing\n",
    "summary_chain = summary_prompt | ai_assistant | StrOutputParser()\n",
    "\n",
    "# Test it on our machine learning text\n",
    "summary = summary_chain.invoke({\"text\": text_documents[0].page_content})\n",
    "\n",
    "print(\"ğŸ“„ Original Text Length:\", len(text_documents[0].page_content), \"characters\")\n",
    "print(\"\\nğŸ“ AI Summary:\")\n",
    "print(summary)\n",
    "print(\"\\nğŸ“Š Summary Length:\", len(summary), \"characters\")\n",
    "\n",
    "print(\"\\nğŸ‰ Challenge Complete! You've built a document summarizer!\")\n",
    "print(\"ğŸš€ Ready for Tutorial 3: Understanding RAG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}