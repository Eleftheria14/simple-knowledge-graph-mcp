{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ•¸ï¸ Tutorial 4: Building Knowledge Graphs\n",
    "\n",
    "**Learn to build knowledge graphs from research papers using AI.**\n",
    "\n",
    "## What You'll Learn:\n",
    "- Extract entities from papers using AI\n",
    "- Build knowledge graphs automatically\n",
    "- Visualize research connections\n",
    "- Query graphs for insights\n",
    "\n",
    "**Time:** 15 minutes | **Level:** Beginner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Import what we need\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "if os.path.basename(os.getcwd()) == 'tutorial':\n",
    "    sys.path.insert(0, '..')\n",
    "else:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "# Enable widgets for visualization\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "    print(\"ðŸ“± Google Colab widget support enabled\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Import the GraphRAG system\n",
    "from src.langchain_graph_rag import LangChainGraphRAG\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create GraphRAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:src.langchain_graph_rag:ðŸ•¸ï¸ LangChain GraphRAG initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ•¸ï¸ Knowledge graph system ready!\n",
      "ðŸ“Š Current papers: 2\n"
     ]
    }
   ],
   "source": [
    "# Create knowledge graph system\n",
    "graph_rag = LangChainGraphRAG(\n",
    "    llm_model=\"llama3.1:8b\",\n",
    "    embedding_model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "print(\"ðŸ•¸ï¸ Knowledge graph system ready!\")\n",
    "print(f\"ðŸ“Š Current papers: {len(graph_rag.get_all_papers())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add Your First Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.langchain_graph_rag:ðŸ” Processing paper: Machine Learning for Drug Discovery\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:src.langchain_graph_rag:âœ… Added paper to graph: 1 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Paper added to knowledge graph!\n",
      "ðŸ“ Documents created: 1\n",
      "ðŸ·ï¸ Entities extracted: 6\n"
     ]
    }
   ],
   "source": [
    "# Sample research paper content\n",
    "paper_content = \"\"\"\n",
    "Machine Learning for Drug Discovery\n",
    "Authors: Dr. Sarah Chen (MIT), Prof. Michael Torres (Stanford)\n",
    "\n",
    "This study presents deep learning approaches for molecular property prediction.\n",
    "We developed ChemNet, a transformer architecture for chemical analysis.\n",
    "The model was trained on PubChem and ChEMBL datasets with 95% accuracy.\n",
    "Applications include drug discovery and materials science.\n",
    "\"\"\"\n",
    "\n",
    "# Add paper to knowledge graph\n",
    "result = graph_rag.extract_entities_and_relationships(\n",
    "    paper_content=paper_content,\n",
    "    paper_title=\"Machine Learning for Drug Discovery\",\n",
    "    paper_id=\"paper_1\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Paper added to knowledge graph!\")\n",
    "print(f\"ðŸ“ Documents created: {result['documents_added']}\")\n",
    "print(f\"ðŸ·ï¸ Entities extracted: {len([e for entities in result['entities'].values() for e in entities])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: See What AI Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– AI Found These Entities:\n",
      "==============================\n",
      "\n",
      "ðŸ“‹ AUTHORS:\n",
      "   â€¢ Dr. Sarah Chen\n",
      "   â€¢ Prof. Michael Torres\n",
      "\n",
      "ðŸ“‹ INSTITUTIONS:\n",
      "   â€¢ MIT\n",
      "   â€¢ Stanford\n",
      "\n",
      "ðŸ“‹ DATASETS:\n",
      "   â€¢ PubChem\n",
      "   â€¢ ChEMBL\n"
     ]
    }
   ],
   "source": [
    "# Show extracted entities\n",
    "entities = result['entities']\n",
    "\n",
    "print(\"ðŸ¤– AI Found These Entities:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for category, entity_list in entities.items():\n",
    "    if entity_list:\n",
    "        print(f\"\\nðŸ“‹ {category.upper()}:\")\n",
    "        for entity in entity_list:\n",
    "            print(f\"   â€¢ {entity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Add Another Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.langchain_graph_rag:ðŸ” Processing paper: Neural Networks in Chemical Research\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:src.langchain_graph_rag:âœ… Added paper to graph: 1 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Second paper added!\n",
      "ðŸ“š Total papers: 2\n"
     ]
    }
   ],
   "source": [
    "# Second paper with overlapping entities\n",
    "paper_content_2 = \"\"\"\n",
    "Neural Networks in Chemical Research\n",
    "Authors: Prof. Michael Torres (Stanford), Dr. Elena Rodriguez (UCSF)\n",
    "\n",
    "We explore transformer models for pharmaceutical applications.\n",
    "Our system uses attention mechanisms for molecular analysis.\n",
    "Training data included PubChem and proprietary datasets.\n",
    "Results show improved drug candidate generation.\n",
    "\"\"\"\n",
    "\n",
    "# Add second paper\n",
    "result_2 = graph_rag.extract_entities_and_relationships(\n",
    "    paper_content=paper_content_2,\n",
    "    paper_title=\"Neural Networks in Chemical Research\", \n",
    "    paper_id=\"paper_2\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Second paper added!\")\n",
    "print(f\"ðŸ“š Total papers: {len(graph_rag.get_all_papers())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Find Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Paper Connections Found:\n",
      "==============================\n",
      "\n",
      "ðŸ“„ Neural Networks in Chemical Research\n",
      "   ðŸ”— Shared authors: Prof. Michael Torres\n"
     ]
    }
   ],
   "source": [
    "# Find papers connected by shared authors\n",
    "connections = graph_rag.find_related_papers(\"paper_1\", \"authors\")\n",
    "\n",
    "print(\"ðŸ”— Paper Connections Found:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if connections['related_papers']:\n",
    "    for paper_id, info in connections['related_papers'].items():\n",
    "        print(f\"\\nðŸ“„ {info['paper_title']}\")\n",
    "        print(f\"   ðŸ”— Shared authors: {', '.join(info['shared_entities'])}\")\n",
    "else:\n",
    "    print(\"No connections found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Query the Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aimiegarces/Agents/tutorial/../src/langchain_graph_rag.py:80: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  initial_docs = self.retriever.get_relevant_documents(query)\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Query: 'machine learning and chemistry'\n",
      "========================================\n",
      "ðŸ“Š Found 2 relevant papers\n",
      "\n",
      "ðŸ“„ Machine Learning for Drug Discovery\n",
      "   ðŸ’¬ Relevant sections: 1\n",
      "   ðŸ“ Machine Learning for Drug Discovery\n",
      "Authors: Dr. Sarah Chen (MIT), Prof. Michael Torres (Stanford)\n",
      "\n",
      "...\n",
      "\n",
      "ðŸ“„ Neural Networks in Chemical Research\n",
      "   ðŸ’¬ Relevant sections: 1\n",
      "   ðŸ“ Neural Networks in Chemical Research\n",
      "Authors: Prof. Michael Torres (Stanford), Dr. Elena Rodriguez (...\n"
     ]
    }
   ],
   "source": [
    "# Ask questions about your research\n",
    "query = \"machine learning and chemistry\"\n",
    "\n",
    "results = graph_rag.query_graph(query)\n",
    "\n",
    "print(f\"ðŸ” Query: '{query}'\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ðŸ“Š Found {results['papers_found']} relevant papers\")\n",
    "\n",
    "for paper_id, paper_data in results['papers'].items():\n",
    "    print(f\"\\nðŸ“„ {paper_data['paper_title']}\")\n",
    "    print(f\"   ðŸ’¬ Relevant sections: {len(paper_data['chunks'])}\")\n",
    "    \n",
    "    # Show snippet\n",
    "    if paper_data['chunks']:\n",
    "        snippet = paper_data['chunks'][0][:100]\n",
    "        print(f\"   ðŸ“ {snippet}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Your Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¨ Creating knowledge graph visualization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee07f10013e408a8df9a52b4f9a877e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='500px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Interactive yFiles graph displayed above!\n",
      "ðŸŽ¯ Use the sidebar to explore nodes and relationships\n",
      "ðŸ” Try the search function to find specific entities\n",
      "\n",
      "ðŸ’¡ If you see a graph above, you can:\n",
      "   â€¢ Drag nodes to rearrange\n",
      "   â€¢ Use sidebar to explore properties\n",
      "   â€¢ Search for specific entities\n",
      "   â€¢ Zoom and pan to navigate\n"
     ]
    }
   ],
   "source": [
    "# Visualize Your Knowledge Graph\n",
    "from src.notebook_visualization import show_knowledge_graph\n",
    "\n",
    "print(\"ðŸŽ¨ Creating knowledge graph visualization...\")\n",
    "\n",
    "# Display interactive graph with professional features\n",
    "result = show_knowledge_graph(graph_rag)\n",
    "\n",
    "if result:\n",
    "    print(\"\\nðŸ’¡ If you see a graph above, you can:\")\n",
    "    print(\"   â€¢ Drag nodes to rearrange\")\n",
    "    print(\"   â€¢ Use sidebar to explore properties\") \n",
    "    print(\"   â€¢ Search for specific entities\")\n",
    "    print(\"   â€¢ Zoom and pan to navigate\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Visualization had issues - but your knowledge graph is working!\")\n",
    "    \n",
    "    # Show what we built anyway\n",
    "    summary = graph_rag.get_graph_summary()\n",
    "    print(f\"\\nðŸ“Š Your Knowledge Graph:\")\n",
    "    print(f\"   ðŸ“„ Papers: {summary['total_papers']}\")\n",
    "    print(f\"   ðŸ“ Documents: {summary['total_documents']}\")\n",
    "    print(f\"   ðŸ·ï¸ Entities: {sum(summary['unique_entities'].values())}\")\n",
    "    print(\"\\nðŸŽ‰ Knowledge graph built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Explore Your Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Knowledge Graph Summary:\n",
      "==============================\n",
      "ðŸ“„ Papers: 2\n",
      "ðŸ“ Document chunks: 28\n",
      "\n",
      "ðŸ·ï¸ Unique Entities:\n",
      "   â€¢ Authors: 3\n",
      "   â€¢ Institutions: 3\n",
      "   â€¢ Datasets: 2\n",
      "\n",
      "ðŸŽ‰ You built a knowledge graph!\n"
     ]
    }
   ],
   "source": [
    "# Get overview of your knowledge graph\n",
    "summary = graph_rag.get_graph_summary()\n",
    "\n",
    "print(\"ðŸ“Š Knowledge Graph Summary:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"ðŸ“„ Papers: {summary['total_papers']}\")\n",
    "print(f\"ðŸ“ Document chunks: {summary['total_documents']}\")\n",
    "\n",
    "print(\"\\nðŸ·ï¸ Unique Entities:\")\n",
    "for entity_type, count in summary['unique_entities'].items():\n",
    "    if count > 0:\n",
    "        print(f\"   â€¢ {entity_type.title()}: {count}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ You built a knowledge graph!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Add your own research content above to expand the graph!\n"
     ]
    }
   ],
   "source": [
    "# Add your own paper content here!\n",
    "your_paper = \"\"\"\n",
    "Replace this with content from your research area:\n",
    "- Title and authors\n",
    "- Abstract or summary\n",
    "- Key methods and findings\n",
    "- Datasets used\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment and modify to add your paper:\n",
    "# result = graph_rag.extract_entities_and_relationships(\n",
    "#     paper_content=your_paper,\n",
    "#     paper_title=\"Your Paper Title\",\n",
    "#     paper_id=\"your_paper\"\n",
    "# )\n",
    "# print(\"âœ… Your paper added to the knowledge graph!\")\n",
    "\n",
    "print(\"ðŸ’¡ Add your own research content above to expand the graph!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ What You Learned\n",
    "\n",
    "**Congratulations!** You built an AI-powered knowledge graph that:\n",
    "\n",
    "âœ… **Extracts entities** from research papers automatically  \n",
    "âœ… **Finds connections** between different papers  \n",
    "âœ… **Answers questions** about your research  \n",
    "âœ… **Visualizes relationships** in an interactive graph  \n",
    "\n",
    "### ðŸš€ Next Steps:\n",
    "- Add real papers from your research area\n",
    "- Try different query types\n",
    "- Explore the interactive visualization\n",
    "- Scale up to larger paper collections\n",
    "\n",
    "### ðŸ”— Real-world Applications:\n",
    "- **Literature reviews** - Find research gaps\n",
    "- **Collaboration mapping** - Discover research networks  \n",
    "- **Citation analysis** - Track research influence\n",
    "- **Knowledge discovery** - Uncover hidden connections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain-env)",
   "language": "python",
   "name": "langchain-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
