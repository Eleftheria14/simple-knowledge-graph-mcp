{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üï∏Ô∏è Tutorial 4: Building Knowledge Graphs\n",
    "\n",
    "**Learn to build knowledge graphs from research papers using AI.**\n",
    "\n",
    "## What You'll Learn:\n",
    "- Extract entities from papers using AI\n",
    "- Build knowledge graphs automatically\n",
    "- Visualize research connections\n",
    "- Query graphs for insights\n",
    "\n",
    "**Time:** 15 minutes | **Level:** Beginner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Import what we need\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path\n",
    "if os.path.basename(os.getcwd()) == 'tutorial':\n",
    "    sys.path.insert(0, '..')\n",
    "else:\n",
    "    sys.path.insert(0, '.')\n",
    "\n",
    "# Enable widgets for visualization\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "    print(\"üì± Google Colab widget support enabled\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Import the GraphRAG system\n",
    "from src.langchain_graph_rag import LangChainGraphRAG\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create GraphRAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO:src.langchain_graph_rag:üï∏Ô∏è LangChain GraphRAG initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üï∏Ô∏è Knowledge graph system ready!\n",
      "üìä Current papers: 2\n"
     ]
    }
   ],
   "source": [
    "# Create knowledge graph system\n",
    "graph_rag = LangChainGraphRAG(\n",
    "    llm_model=\"llama3.1:8b\",\n",
    "    embedding_model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "print(\"üï∏Ô∏è Knowledge graph system ready!\")\n",
    "print(f\"üìä Current papers: {len(graph_rag.get_all_papers())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add Your First Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.langchain_graph_rag:üîç Processing paper: Machine Learning for Drug Discovery\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:src.langchain_graph_rag:‚úÖ Added paper to graph: 1 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Paper added to knowledge graph!\n",
      "üìù Documents created: 1\n",
      "üè∑Ô∏è Entities extracted: 6\n"
     ]
    }
   ],
   "source": [
    "# Sample research paper content\n",
    "paper_content = \"\"\"\n",
    "Machine Learning for Drug Discovery\n",
    "Authors: Dr. Sarah Chen (MIT), Prof. Michael Torres (Stanford)\n",
    "\n",
    "This study presents deep learning approaches for molecular property prediction.\n",
    "We developed ChemNet, a transformer architecture for chemical analysis.\n",
    "The model was trained on PubChem and ChEMBL datasets with 95% accuracy.\n",
    "Applications include drug discovery and materials science.\n",
    "\"\"\"\n",
    "\n",
    "# Add paper to knowledge graph\n",
    "result = graph_rag.extract_entities_and_relationships(\n",
    "    paper_content=paper_content,\n",
    "    paper_title=\"Machine Learning for Drug Discovery\",\n",
    "    paper_id=\"paper_1\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Paper added to knowledge graph!\")\n",
    "print(f\"üìù Documents created: {result['documents_added']}\")\n",
    "print(f\"üè∑Ô∏è Entities extracted: {len([e for entities in result['entities'].values() for e in entities])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: See What AI Found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AI Found These Entities:\n",
      "==============================\n",
      "\n",
      "üìã AUTHORS:\n",
      "   ‚Ä¢ Dr. Sarah Chen\n",
      "   ‚Ä¢ Prof. Michael Torres\n",
      "\n",
      "üìã INSTITUTIONS:\n",
      "   ‚Ä¢ MIT\n",
      "   ‚Ä¢ Stanford\n",
      "\n",
      "üìã DATASETS:\n",
      "   ‚Ä¢ PubChem\n",
      "   ‚Ä¢ ChEMBL\n"
     ]
    }
   ],
   "source": [
    "# Show extracted entities\n",
    "entities = result['entities']\n",
    "\n",
    "print(\"ü§ñ AI Found These Entities:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for category, entity_list in entities.items():\n",
    "    if entity_list:\n",
    "        print(f\"\\nüìã {category.upper()}:\")\n",
    "        for entity in entity_list:\n",
    "            print(f\"   ‚Ä¢ {entity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Add Another Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.langchain_graph_rag:üîç Processing paper: Neural Networks in Chemical Research\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:src.langchain_graph_rag:‚úÖ Added paper to graph: 1 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Second paper added!\n",
      "üìö Total papers: 2\n"
     ]
    }
   ],
   "source": [
    "# Second paper with overlapping entities\n",
    "paper_content_2 = \"\"\"\n",
    "Neural Networks in Chemical Research\n",
    "Authors: Prof. Michael Torres (Stanford), Dr. Elena Rodriguez (UCSF)\n",
    "\n",
    "We explore transformer models for pharmaceutical applications.\n",
    "Our system uses attention mechanisms for molecular analysis.\n",
    "Training data included PubChem and proprietary datasets.\n",
    "Results show improved drug candidate generation.\n",
    "\"\"\"\n",
    "\n",
    "# Add second paper\n",
    "result_2 = graph_rag.extract_entities_and_relationships(\n",
    "    paper_content=paper_content_2,\n",
    "    paper_title=\"Neural Networks in Chemical Research\", \n",
    "    paper_id=\"paper_2\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Second paper added!\")\n",
    "print(f\"üìö Total papers: {len(graph_rag.get_all_papers())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Find Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Paper Connections Found:\n",
      "==============================\n",
      "\n",
      "üìÑ Neural Networks in Chemical Research\n",
      "   üîó Shared authors: Prof. Michael Torres\n"
     ]
    }
   ],
   "source": [
    "# Find papers connected by shared authors\n",
    "connections = graph_rag.find_related_papers(\"paper_1\", \"authors\")\n",
    "\n",
    "print(\"üîó Paper Connections Found:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if connections['related_papers']:\n",
    "    for paper_id, info in connections['related_papers'].items():\n",
    "        print(f\"\\nüìÑ {info['paper_title']}\")\n",
    "        print(f\"   üîó Shared authors: {', '.join(info['shared_entities'])}\")\n",
    "else:\n",
    "    print(\"No connections found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Query the Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aimiegarces/Agents/tutorial/../src/langchain_graph_rag.py:80: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  initial_docs = self.retriever.get_relevant_documents(query)\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Query: 'machine learning and chemistry'\n",
      "========================================\n",
      "üìä Found 2 relevant papers\n",
      "\n",
      "üìÑ Machine Learning for Drug Discovery\n",
      "   üí¨ Relevant sections: 1\n",
      "   üìù Machine Learning for Drug Discovery\n",
      "Authors: Dr. Sarah Chen (MIT), Prof. Michael Torres (Stanford)\n",
      "\n",
      "...\n",
      "\n",
      "üìÑ Neural Networks in Chemical Research\n",
      "   üí¨ Relevant sections: 1\n",
      "   üìù Neural Networks in Chemical Research\n",
      "Authors: Prof. Michael Torres (Stanford), Dr. Elena Rodriguez (...\n"
     ]
    }
   ],
   "source": [
    "# Ask questions about your research\n",
    "query = \"machine learning and chemistry\"\n",
    "\n",
    "results = graph_rag.query_graph(query)\n",
    "\n",
    "print(f\"üîç Query: '{query}'\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìä Found {results['papers_found']} relevant papers\")\n",
    "\n",
    "for paper_id, paper_data in results['papers'].items():\n",
    "    print(f\"\\nüìÑ {paper_data['paper_title']}\")\n",
    "    print(f\"   üí¨ Relevant sections: {len(paper_data['chunks'])}\")\n",
    "    \n",
    "    # Show snippet\n",
    "    if paper_data['chunks']:\n",
    "        snippet = paper_data['chunks'][0][:100]\n",
    "        print(f\"   üìù {snippet}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Your Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Creating knowledge graph visualization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee07f10013e408a8df9a52b4f9a877e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='500px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Interactive yFiles graph displayed above!\n",
      "üéØ Use the sidebar to explore nodes and relationships\n",
      "üîç Try the search function to find specific entities\n",
      "\n",
      "üí° If you see a graph above, you can:\n",
      "   ‚Ä¢ Drag nodes to rearrange\n",
      "   ‚Ä¢ Use sidebar to explore properties\n",
      "   ‚Ä¢ Search for specific entities\n",
      "   ‚Ä¢ Zoom and pan to navigate\n"
     ]
    }
   ],
   "source": [
    "# Visualize Your Knowledge Graph\n",
    "from src.notebook_visualization import show_knowledge_graph\n",
    "\n",
    "print(\"üé® Creating knowledge graph visualization...\")\n",
    "\n",
    "# Display interactive graph with professional features\n",
    "result = show_knowledge_graph(graph_rag)\n",
    "\n",
    "if result:\n",
    "    print(\"\\nüí° If you see a graph above, you can:\")\n",
    "    print(\"   ‚Ä¢ Drag nodes to rearrange\")\n",
    "    print(\"   ‚Ä¢ Use sidebar to explore properties\") \n",
    "    print(\"   ‚Ä¢ Search for specific entities\")\n",
    "    print(\"   ‚Ä¢ Zoom and pan to navigate\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Visualization had issues - but your knowledge graph is working!\")\n",
    "    \n",
    "    # Show what we built anyway\n",
    "    summary = graph_rag.get_graph_summary()\n",
    "    print(f\"\\nüìä Your Knowledge Graph:\")\n",
    "    print(f\"   üìÑ Papers: {summary['total_papers']}\")\n",
    "    print(f\"   üìù Documents: {summary['total_documents']}\")\n",
    "    print(f\"   üè∑Ô∏è Entities: {sum(summary['unique_entities'].values())}\")\n",
    "    print(\"\\nüéâ Knowledge graph built successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Explore Your Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Knowledge Graph Summary:\n",
      "==============================\n",
      "üìÑ Papers: 2\n",
      "üìù Document chunks: 28\n",
      "\n",
      "üè∑Ô∏è Unique Entities:\n",
      "   ‚Ä¢ Authors: 3\n",
      "   ‚Ä¢ Institutions: 3\n",
      "   ‚Ä¢ Datasets: 2\n",
      "\n",
      "üéâ You built a knowledge graph!\n"
     ]
    }
   ],
   "source": [
    "# Get overview of your knowledge graph\n",
    "summary = graph_rag.get_graph_summary()\n",
    "\n",
    "print(\"üìä Knowledge Graph Summary:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"üìÑ Papers: {summary['total_papers']}\")\n",
    "print(f\"üìù Document chunks: {summary['total_documents']}\")\n",
    "\n",
    "print(\"\\nüè∑Ô∏è Unique Entities:\")\n",
    "for entity_type, count in summary['unique_entities'].items():\n",
    "    if count > 0:\n",
    "        print(f\"   ‚Ä¢ {entity_type.title()}: {count}\")\n",
    "\n",
    "print(\"\\nüéâ You built a knowledge graph!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Add your own research content above to expand the graph!\n"
     ]
    }
   ],
   "source": [
    "# Add your own paper content here!\n",
    "your_paper = \"\"\"\n",
    "Replace this with content from your research area:\n",
    "- Title and authors\n",
    "- Abstract or summary\n",
    "- Key methods and findings\n",
    "- Datasets used\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment and modify to add your paper:\n",
    "# result = graph_rag.extract_entities_and_relationships(\n",
    "#     paper_content=your_paper,\n",
    "#     paper_title=\"Your Paper Title\",\n",
    "#     paper_id=\"your_paper\"\n",
    "# )\n",
    "# print(\"‚úÖ Your paper added to the knowledge graph!\")\n",
    "\n",
    "print(\"üí° Add your own research content above to expand the graph!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì What You Learned\n",
    "\n",
    "**Congratulations!** You built an AI-powered knowledge graph that:\n",
    "\n",
    "‚úÖ **Extracts entities** from research papers automatically  \n",
    "‚úÖ **Finds connections** between different papers  \n",
    "‚úÖ **Answers questions** about your research  \n",
    "‚úÖ **Visualizes relationships** in an interactive graph  \n",
    "\n",
    "### üöÄ Next Steps:\n",
    "- Add real papers from your research area\n",
    "- Try different query types\n",
    "- Explore the interactive visualization\n",
    "- Scale up to larger paper collections\n",
    "\n",
    "### üîó Real-world Applications:\n",
    "- **Literature reviews** - Find research gaps\n",
    "- **Collaboration mapping** - Discover research networks  \n",
    "- **Citation analysis** - Track research influence\n",
    "- **Knowledge discovery** - Uncover hidden connections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain-env)",
   "language": "python",
   "name": "langchain-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
