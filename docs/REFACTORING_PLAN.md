# GraphRAG MCP Refactoring Plan

## ğŸ¯ **Goal: Clean Up Large Files & Improve Separation of Concerns**

Make the codebase more maintainable by splitting large files and separating concerns, without over-engineering the research tool.

## ğŸ“Š **Current File Sizes Analysis**

### **Files That Need Splitting:**
- `processing_utils.py` (866 lines) - **HIGHEST PRIORITY**
- `literature_tools.py` (889 lines) - **MEDIUM PRIORITY**
- `citation_manager.py` (654 lines) - **MEDIUM PRIORITY**
- `cli/main.py` (934 lines) - **LOWER PRIORITY**
- `query_engine.py` (654 lines) - **LOWER PRIORITY**

### **Files That Are Good Size:**
- `document_processor.py` (373 lines) âœ…
- `analyzer.py` (397 lines) âœ…
- `chat_engine.py` (445 lines) âœ…
- `ollama_engine.py` (319 lines) âœ…

## ğŸ—ï¸ **Proposed Structure**

### **1. Split `processing_utils.py` (866 â†’ 4 files)**

#### **Current Structure:**
```
notebooks/Main/
â””â”€â”€ processing_utils.py (866 lines)
    â”œâ”€â”€ DocumentStatus dataclass
    â”œâ”€â”€ NotebookDocumentProcessor class
    â”œâ”€â”€ Complex import/reload logic
    â”œâ”€â”€ Document discovery
    â”œâ”€â”€ Processing coordination
    â”œâ”€â”€ Progress tracking
    â”œâ”€â”€ Analytics generation
    â”œâ”€â”€ Visualization (200+ lines)
    â””â”€â”€ Error handling
```

#### **Proposed Structure:**
```
notebooks/Main/
â”œâ”€â”€ document_discovery.py      (~100 lines)
â”‚   â”œâ”€â”€ DocumentStatus dataclass
â”‚   â”œâ”€â”€ DocumentDiscovery class
â”‚   â””â”€â”€ PDF scanning and file discovery
â”œâ”€â”€ processing_coordinator.py  (~200 lines)
â”‚   â”œâ”€â”€ ProcessingCoordinator class
â”‚   â”œâ”€â”€ Single document processing
â”‚   â”œâ”€â”€ Batch processing with progress
â”‚   â””â”€â”€ Error handling and retry logic
â”œâ”€â”€ analytics_utils.py         (~300 lines)
â”‚   â”œâ”€â”€ show_analytics() function
â”‚   â”œâ”€â”€ visualize_knowledge_graph() function
â”‚   â”œâ”€â”€ Progress tracking utilities
â”‚   â””â”€â”€ Chart generation functions
â”œâ”€â”€ notebook_interface.py      (~100 lines)
â”‚   â”œâ”€â”€ Simple NotebookInterface class
â”‚   â”œâ”€â”€ Clean imports (no reload logic)
â”‚   â””â”€â”€ Ties everything together
â””â”€â”€ Simple_Document_Processing.ipynb (updated)
```

### **2. Split `literature_tools.py` (889 â†’ 3 files)**

#### **Current Structure:**
```
graphrag_mcp/mcp/
â””â”€â”€ literature_tools.py (889 lines)
    â”œâ”€â”€ LiteratureToolsEngine class
    â”œâ”€â”€ gather_sources_for_topic
    â”œâ”€â”€ get_facts_with_citations
    â”œâ”€â”€ verify_claim_with_sources
    â”œâ”€â”€ get_topic_outline
    â”œâ”€â”€ track_citations_used
    â””â”€â”€ generate_bibliography
```

#### **Proposed Structure:**
```
graphrag_mcp/mcp/
â”œâ”€â”€ source_tools.py           (~300 lines)
â”‚   â”œâ”€â”€ gather_sources_for_topic
â”‚   â”œâ”€â”€ verify_claim_with_sources
â”‚   â””â”€â”€ Related source gathering functions
â”œâ”€â”€ citation_tools.py         (~300 lines)
â”‚   â”œâ”€â”€ get_facts_with_citations
â”‚   â”œâ”€â”€ track_citations_used
â”‚   â””â”€â”€ Citation integration functions
â”œâ”€â”€ writing_tools.py          (~300 lines)
â”‚   â”œâ”€â”€ get_topic_outline
â”‚   â”œâ”€â”€ generate_bibliography
â”‚   â””â”€â”€ Writing assistance functions
â””â”€â”€ literature_tools.py       (~100 lines)
    â””â”€â”€ LiteratureToolsEngine (coordinator)
```

### **3. Split `citation_manager.py` (654 â†’ 3 files)**

#### **Current Structure:**
```
graphrag_mcp/core/
â””â”€â”€ citation_manager.py (654 lines)
    â”œâ”€â”€ CitationTracker class
    â”œâ”€â”€ Citation tracking logic
    â”œâ”€â”€ Multiple format support (APA, IEEE, Nature, MLA)
    â”œâ”€â”€ Bibliography generation
    â””â”€â”€ Export functionality (JSON, CSV, BibTeX)
```

#### **Proposed Structure:**
```
graphrag_mcp/core/
â”œâ”€â”€ citation_tracker.py       (~200 lines)
â”‚   â”œâ”€â”€ Core CitationTracker class
â”‚   â”œâ”€â”€ Citation storage and tracking
â”‚   â””â”€â”€ Usage context management
â”œâ”€â”€ citation_formatter.py     (~250 lines)
â”‚   â”œâ”€â”€ Format citations in different styles
â”‚   â”œâ”€â”€ APA, IEEE, Nature, MLA formatters
â”‚   â””â”€â”€ Bibliography generation
â”œâ”€â”€ citation_export.py        (~200 lines)
â”‚   â”œâ”€â”€ Export to JSON, CSV, BibTeX
â”‚   â”œâ”€â”€ Import functionality
â”‚   â””â”€â”€ Data conversion utilities
â””â”€â”€ citation_manager.py       (~100 lines)
    â””â”€â”€ Main CitationManager (coordinator)
```

### **4. Split `cli/main.py` (934 â†’ 3 files)** *(Lower Priority)*

#### **Proposed Structure:**
```
graphrag_mcp/cli/
â”œâ”€â”€ serve_commands.py         (~300 lines)
â”‚   â”œâ”€â”€ MCP server commands
â”‚   â”œâ”€â”€ serve-universal
â”‚   â””â”€â”€ Server management
â”œâ”€â”€ process_commands.py       (~300 lines)
â”‚   â”œâ”€â”€ Document processing commands
â”‚   â”œâ”€â”€ Batch processing
â”‚   â””â”€â”€ Analysis commands
â”œâ”€â”€ utility_commands.py       (~300 lines)
â”‚   â”œâ”€â”€ Status checking
â”‚   â”œâ”€â”€ Template management
â”‚   â””â”€â”€ Configuration commands
â””â”€â”€ main.py                   (~100 lines)
    â””â”€â”€ Main CLI app and routing
```

## ğŸš€ **Implementation Strategy**

### **Phase 1: Notebook Interface (2-3 hours)**
**Priority: HIGHEST** - Most used by researchers

1. **Extract Analytics Functions** (1 hour)
   - Move `show_analytics()` and `visualize_knowledge_graph()` to `analytics_utils.py`
   - Keep as standalone functions, not class methods

2. **Extract Document Discovery** (1 hour)
   - Move `DocumentStatus` and discovery logic to `document_discovery.py`
   - Create clean `DocumentDiscovery` class

3. **Extract Processing Coordinator** (1 hour)
   - Move processing logic to `processing_coordinator.py`
   - Clean up async handling and error management

4. **Create Simple Interface** (30 minutes)
   - Create `notebook_interface.py` with clean imports
   - Remove complex module reloading logic

### **Phase 2: MCP Tools (1-2 hours)**
**Priority: MEDIUM** - Used by MCP server

1. **Split Literature Tools** (1-2 hours)
   - Group related tools into separate files
   - Maintain clean imports in main `literature_tools.py`

### **Phase 3: Citation Management (1-2 hours)**
**Priority: MEDIUM** - If time permits

1. **Split Citation Components** (1-2 hours)
   - Separate tracking, formatting, and export logic
   - Maintain clean coordinator class

## ğŸ“‹ **What Each File Will Do**

### **Notebook Files:**
- **`document_discovery.py`**: Scan folders, find PDFs, create DocumentStatus objects
- **`processing_coordinator.py`**: Process documents with progress tracking and error handling
- **`analytics_utils.py`**: Generate charts, graphs, and knowledge graph visualization
- **`notebook_interface.py`**: Simple class that ties everything together for notebooks

### **MCP Tools:**
- **`source_tools.py`**: Tools for gathering and verifying sources
- **`citation_tools.py`**: Tools for getting cited facts and tracking citations
- **`writing_tools.py`**: Tools for outlines and bibliography generation

### **Citation Management:**
- **`citation_tracker.py`**: Core citation tracking and storage
- **`citation_formatter.py`**: Format citations in different academic styles
- **`citation_export.py`**: Export citations to various formats

## âœ… **Benefits**

### **1. Improved Maintainability**
- Smaller, focused files are easier to understand
- Clear separation of concerns
- Easier to debug and modify

### **2. Better Contributor Experience**
- New contributors can focus on specific components
- Easier to understand the codebase structure
- Clear boundaries between different functionalities

### **3. Preserved Research Focus**
- Keeps the tool's academic research mission
- Doesn't over-engineer the solution
- Maintains simplicity while improving organization

### **4. Backward Compatibility**
- Existing imports and usage patterns remain the same
- Notebooks continue to work without changes
- MCP server functionality preserved

## â±ï¸ **Time Estimate**

- **Phase 1 (Notebook Interface)**: 2-3 hours
- **Phase 2 (MCP Tools)**: 1-2 hours
- **Phase 3 (Citation Management)**: 1-2 hours

**Total: 4-7 hours** of focused refactoring work.

This plan focuses on making the codebase cleaner and more maintainable while preserving its effectiveness as an open-source research tool.