# HISTORICAL REFERENCE: Implementation Plan: Scientific RAG + Knowledge Graph Platform

**âš ï¸ HISTORICAL DOCUMENT - This represents the original implementation plan but the system evolved differently. See current CLAUDE.md for actual architecture.**

## ðŸ§¹ Current Codebase Analysis & Cleanup

### **Files to Keep & Refactor:**
- âœ… `src/embedding_analyzer.py` â†’ Expand for RAG capabilities
- âœ… `src/database_manager.py` â†’ Add knowledge graph tables  
- âœ… `src/enhanced_citation_extractor.py` â†’ Keep for metadata extraction
- âœ… `database/database_setup.sql` â†’ Extend for graph schema
- âœ… `database/add_embeddings_schema.sql` â†’ Integrate into main schema
- âœ… `docs/` â†’ Keep all documentation
- âœ… `examples/d4sc03921a.pdf` â†’ Keep for testing

### **Files to Remove/Archive:**
- âŒ `src/citation_extractor.py` â†’ Legacy, superseded by enhanced version
- âŒ `notebooks/Tutorial.ipynb` â†’ Too basic for RAG platform
- âŒ `notebooks/Scientific_Paper_Analyzer.ipynb` â†’ Outdated approach
- âŒ `notebooks/Maximum_Context_Scientific_Analyzer.ipynb` â†’ Replace with RAG version

### **New Files to Create:**
- ðŸ†• `src/rag_system.py` â†’ Core RAG functionality with persistent storage
- ðŸ†• `src/knowledge_graph.py` â†’ LangGraph-based entity extraction and relationships
- ðŸ†• `src/unified_intelligence.py` â†’ RAG + Graph combined query engine
- ðŸ†• `notebooks/Scientific_RAG_Knowledge_Graph.ipynb` â†’ Main user interface
- ðŸ†• `database/complete_schema.sql` â†’ Unified schema for RAG + Graph

---

## ðŸŽ¯ Implementation Strategy

### **Phase 1: Foundation (Week 1-2)**

#### **1.1 Codebase Cleanup**
- Remove legacy files
- Consolidate database schemas  
- Update requirements.txt with LangGraph dependencies
- Restructure src/ for new architecture

#### **1.2 Core RAG System**
```python
# src/rag_system.py
class ScientificRAGSystem:
    def __init__(self):
        self.embeddings = OllamaEmbeddings("nomic-embed-text")
        self.llm = ChatOllama("llama3.1:8b")
        self.vector_store = PostgreSQLVectorStore()
    
    def ingest_paper(self, pdf_path: str) -> str:
        # Extract text, chunk, embed, store
        pass
    
    def query(self, question: str, paper_ids: List[str] = None) -> str:
        # Retrieve relevant chunks, generate answer
        pass
    
    def chat(self, session_id: str, message: str) -> str:
        # Conversational interface with context
        pass
```

#### **1.3 Database Schema Update**
```sql
-- Complete unified schema
-- Papers, embeddings, entities, relationships, chat sessions
```

### **Phase 2: Knowledge Graph (Week 3-4)**

#### **2.1 Entity Extraction**
```python
# src/knowledge_graph.py  
class ScientificKnowledgeGraph:
    def extract_entities(self, paper_content: str) -> List[Entity]:
        # LangGraph workflow for entity extraction
        # Authors, Methods, Concepts, Metrics, Institutions
        pass
    
    def build_relationships(self, entities: List[Entity]) -> List[Relationship]:
        # Citation analysis, method usage, concept relationships
        pass
```

#### **2.2 LangGraph Workflows**
- **Entity Extraction Workflow**: Paper â†’ Entities â†’ Store
- **Relationship Building**: Entities â†’ Relationships â†’ Graph
- **Graph Traversal**: Query â†’ Multi-hop â†’ Results

### **Phase 3: Unified Intelligence (Week 5-6)**

#### **3.1 Combined Query Engine**
```python
# src/unified_intelligence.py
class UnifiedIntelligence:
    def __init__(self):
        self.rag = ScientificRAGSystem()
        self.graph = ScientificKnowledgeGraph()
    
    def intelligent_query(self, question: str) -> IntelligentResponse:
        # Determine if RAG, Graph, or combined approach needed
        # Route query appropriately
        # Merge results intelligently
        pass
```

#### **3.2 Chat Interface**
- Natural language queries
- Context-aware conversations
- Multi-turn interactions
- Source attribution

### **Phase 4: User Interface (Week 7-8)**

#### **4.1 Comprehensive Notebook**
- Paper ingestion workflow
- RAG query examples  
- Knowledge graph exploration
- Visualization capabilities

#### **4.2 Advanced Features**
- Batch processing
- Relationship visualization
- Export capabilities
- Performance analytics

---

## ðŸ“‹ Detailed Technical Specifications

### **RAG System Architecture:**
```
PDF â†’ Text Extraction â†’ Chunking â†’ Embeddings â†’ PostgreSQL Vector Store
                                                        â†“
User Query â†’ Embedding â†’ Similarity Search â†’ Retrieve Chunks â†’ LLM â†’ Response
```

### **Knowledge Graph Architecture:**
```
Paper Content â†’ LangGraph Entity Extraction â†’ Entities (Authors, Methods, etc.)
                       â†“
             Relationship Detection â†’ Store in Graph DB
                       â†“
User Query â†’ Graph Traversal â†’ Related Entities â†’ Context for RAG
```

### **Database Schema Evolution:**
```sql
-- Core tables (existing, enhanced)
papers (enhanced with graph metadata)
document_embeddings (optimized for retrieval)

-- New knowledge graph tables
entities (id, type, name, properties, paper_id)
relationships (source_id, target_id, type, confidence)
entity_embeddings (entity_id, embedding_vector)

-- Chat and session management
chat_sessions (id, user_id, created_at)
chat_messages (id, session_id, role, content, timestamp)
query_cache (query_hash, results, created_at)
```

### **LangGraph Workflows:**

#### **Entity Extraction Workflow:**
```python
from langgraph.graph import StateGraph, Graph

def entity_extraction_workflow():
    graph = StateGraph()
    
    # Nodes
    graph.add_node("extract_authors", extract_authors_node)
    graph.add_node("extract_methods", extract_methods_node) 
    graph.add_node("extract_concepts", extract_concepts_node)
    graph.add_node("extract_metrics", extract_metrics_node)
    graph.add_node("validate_entities", validate_entities_node)
    
    # Edges
    graph.add_edge("extract_authors", "extract_methods")
    graph.add_edge("extract_methods", "extract_concepts")
    graph.add_edge("extract_concepts", "extract_metrics")
    graph.add_edge("extract_metrics", "validate_entities")
    
    return graph.compile()
```

---

## ðŸ› ï¸ Development Dependencies

### **New Requirements:**
```txt
# Existing (keep)
langchain>=0.1.0
langchain-community>=0.0.10  
langchain-ollama>=0.1.0
psycopg2-binary>=2.9.0
scikit-learn>=1.6.0

# New additions
langgraph>=0.1.0
networkx>=3.0
pyvis>=0.3.0
spacy>=3.7.0
en_core_web_sm>=3.7.0
```

### **Database Extensions:**
```sql
-- Enable vector and graph capabilities
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS ltree;  -- For hierarchical relationships
```

---

## ðŸŽ® User Experience Flows

### **Paper Ingestion Flow:**
1. Upload PDF â†’ "Processing paper..."
2. Extract text â†’ "Extracting content..."  
3. Generate embeddings â†’ "Creating embeddings..."
4. Extract entities â†’ "Finding authors, methods, concepts..."
5. Build relationships â†’ "Mapping connections..."
6. Ready for queries â†’ "Paper added to knowledge base!"

### **Query Flow:**
1. User types question â†’ "What are the key findings?"
2. System determines approach â†’ RAG + Graph  
3. Retrieve relevant chunks â†’ Show sources
4. Traverse relationships â†’ Show connected concepts
5. Generate comprehensive answer â†’ With attribution
6. Follow-up suggestions â†’ Related questions

### **Knowledge Discovery Flow:**
1. Start with paper â†’ Show its entities
2. Explore relationships â†’ "Papers that cite this"
3. Visual graph â†’ Interactive network
4. Deep dive â†’ RAG analysis of connections
5. Export insights â†’ Research report

---

## ðŸ“Š Testing Strategy

### **Unit Tests:**
- RAG embedding and retrieval accuracy
- Entity extraction precision/recall
- Relationship detection confidence
- Query response quality

### **Integration Tests:**
- End-to-end paper ingestion
- RAG + Graph combined queries
- Chat session management
- Database consistency

### **Performance Tests:**
- Query response time (<5s)
- Embedding generation speed
- Graph traversal efficiency
- Concurrent user handling

---

## ðŸš€ Deployment Plan

### **Local Development:**
- Jupyter notebook interface
- Docker PostgreSQL
- Local Ollama server

### **Production Ready:**
- Web interface (FastAPI + React)
- Cloud PostgreSQL with pgvector
- Container orchestration
- API rate limiting

---

## ðŸ“ˆ Success Metrics

### **Technical KPIs:**
- **RAG Accuracy**: >80% relevant chunks in top-5
- **Entity Extraction**: >90% precision for authors, >85% for methods
- **Response Time**: <5s for 95% of queries
- **Graph Completeness**: >80% of relationships captured

### **User Experience KPIs:**
- **Query Success Rate**: >90% satisfactory answers
- **Session Length**: >10 minutes average
- **Discovery Rate**: >3 new connections per session
- **Retention**: >70% weekly active users

---

**Next Steps:** 
1. Review and approve this plan
2. Execute codebase cleanup
3. Begin Phase 1 implementation
4. Create new unified notebook interface

**Ready to transform scientific paper analysis! ðŸš€**