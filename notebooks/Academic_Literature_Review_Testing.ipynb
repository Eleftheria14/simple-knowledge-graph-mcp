{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academic Literature Review Testing Notebook\n",
    "\n",
    "## User Story: PhD Student - Machine Learning for Drug Discovery\n",
    "\n",
    "**Context**: Sarah is a 3rd-year PhD student in computational chemistry working on her dissertation chapter on ML approaches to molecular property prediction. She has collected key papers but feels overwhelmed by synthesizing them into coherent sections.\n",
    "\n",
    "**Goal**: Test the complete GraphRAG MCP workflow for academic literature review\n",
    "\n",
    "**Flow**: \n",
    "1. **Phase 1**: Corpus Building (Weekend Setup)\n",
    "2. **Phase 2**: Discovery and Exploration (Monday Research)\n",
    "3. **Phase 3**: Literature Review Writing (Tuesday-Wednesday Writing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup and Environment Check\n",
    "\n",
    "First, let's verify our environment and dependencies are ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup and imports\n",
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# GraphRAG MCP imports\n",
    "from graphrag_mcp.core.graphiti_engine import GraphitiKnowledgeGraph\n",
    "from graphrag_mcp.core.document_processor import DocumentProcessor\n",
    "from graphrag_mcp.core.analyzer import AdvancedAnalyzer\n",
    "from graphrag_mcp.templates.academic import AcademicTemplate\n",
    "from graphrag_mcp.visualization.graphiti_yfiles import display_graphiti_knowledge_graph\n",
    "\n",
    "print(\"âœ… Imports successful\")\n",
    "print(f\"ğŸ“ Project root: {project_root}\")\n",
    "print(f\"â° Testing started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Ollama status\n",
    "def check_ollama_status():\n",
    "    \"\"\"Check if Ollama is running and has required models\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:11434/api/tags\")\n",
    "        if response.status_code == 200:\n",
    "            models = response.json()\n",
    "            model_names = [model['name'] for model in models.get('models', [])]\n",
    "            print(\"âœ… Ollama is running\")\n",
    "            print(f\"ğŸ“‹ Available models: {model_names}\")\n",
    "            \n",
    "            # Check for required models\n",
    "            required_models = ['llama3.1:8b', 'nomic-embed-text']\n",
    "            missing_models = [model for model in required_models if model not in model_names]\n",
    "            \n",
    "            if missing_models:\n",
    "                print(f\"âš ï¸  Missing required models: {missing_models}\")\n",
    "                return False\n",
    "            else:\n",
    "                print(\"âœ… All required models available\")\n",
    "                return True\n",
    "        else:\n",
    "            print(\"âŒ Ollama not responding\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error checking Ollama: {e}\")\n",
    "        return False\n",
    "\n",
    "ollama_ready = check_ollama_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Neo4j status\n",
    "def check_neo4j_status():\n",
    "    \"\"\"Check if Neo4j is running\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:7474/\")\n",
    "        if response.status_code == 200:\n",
    "            print(\"âœ… Neo4j is running\")\n",
    "            print(\"ğŸŒ Neo4j Browser available at: http://localhost:7474\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"âŒ Neo4j not responding\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error checking Neo4j: {e}\")\n",
    "        print(\"ğŸ’¡ Start Neo4j with: docker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:latest\")\n",
    "        return False\n",
    "\n",
    "neo4j_ready = check_neo4j_status()\n",
    "\n",
    "# Overall system readiness\n",
    "system_ready = ollama_ready and neo4j_ready\n",
    "print(f\"\\nğŸš€ System ready for testing: {system_ready}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Phase 1: Corpus Building (Weekend Setup)\n",
    "\n",
    "Sarah's weekend task: Upload and process her paper collection on \"machine learning for drug discovery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sarah's dissertation workspace\n",
    "dissertation_path = project_root / \"ml_drug_discovery_workspace\"\n",
    "dissertation_path.mkdir(exist_ok=True)\n",
    "\n",
    "papers_path = dissertation_path / \"papers\"\n",
    "papers_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy example papers to workspace (simulate Sarah's paper collection)\n",
    "import shutil\n",
    "examples_path = project_root / \"examples\"\n",
    "if examples_path.exists():\n",
    "    for pdf_file in examples_path.glob(\"*.pdf\"):\n",
    "        shutil.copy2(pdf_file, papers_path)\n",
    "        print(f\"ğŸ“„ Added paper: {pdf_file.name}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Sarah's workspace created at: {dissertation_path}\")\n",
    "print(f\"ğŸ“š Papers directory: {papers_path}\")\n",
    "print(f\"ğŸ“Š Total papers: {len(list(papers_path.glob('*.pdf')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Academic Literature Review Assistant\n",
    "print(\"ğŸš€ Creating literature review assistant...\")\n",
    "\n",
    "# Initialize components\n",
    "if system_ready:\n",
    "    try:\n",
    "        # Initialize Graphiti knowledge graph\n",
    "        print(\"ğŸ“Š Initializing Graphiti knowledge graph...\")\n",
    "        kg = GraphitiKnowledgeGraph(\n",
    "            neo4j_uri=\"bolt://localhost:7687\",\n",
    "            neo4j_user=\"neo4j\",\n",
    "            neo4j_password=\"password\",\n",
    "            ollama_base_url=\"http://localhost:11434/v1\",\n",
    "            llm_model=\"llama3.1:8b\",\n",
    "            embedding_model=\"nomic-embed-text\"\n",
    "        )\n",
    "        \n",
    "        # Initialize document processor\n",
    "        print(\"ğŸ“ Initializing document processor...\")\n",
    "        doc_processor = DocumentProcessor()\n",
    "        \n",
    "        # Initialize academic template\n",
    "        print(\"ğŸ“ Initializing academic template...\")\n",
    "        academic_template = AcademicTemplate()\n",
    "        \n",
    "        # Initialize analyzer\n",
    "        print(\"ğŸ” Initializing advanced analyzer...\")\n",
    "        analyzer = AdvancedAnalyzer(template=academic_template)\n",
    "        \n",
    "        print(\"âœ… Literature review assistant initialized successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error initializing assistant: {e}\")\n",
    "        print(\"ğŸ’¡ Make sure Neo4j and Ollama are running\")\n",
    "        system_ready = False\n",
    "else:\n",
    "    print(\"âš ï¸ System not ready - skipping initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Sarah's paper collection\n",
    "if system_ready:\n",
    "    print(\"ğŸ“– Processing Sarah's paper collection...\")\n",
    "    print(\"â±ï¸  This simulates the overnight processing (normally 7+ hours for 50 papers)\")\n",
    "    \n",
    "    processed_papers = []\n",
    "    paper_files = list(papers_path.glob(\"*.pdf\"))\n",
    "    \n",
    "    for i, paper_file in enumerate(paper_files, 1):\n",
    "        print(f\"\\nğŸ“„ Processing paper {i}/{len(paper_files)}: {paper_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Extract text from PDF\n",
    "            print(\"  ğŸ” Extracting text...\")\n",
    "            documents = doc_processor.process_pdf(str(paper_file))\n",
    "            \n",
    "            # Analyze with academic template\n",
    "            print(\"  ğŸ§  Analyzing with academic template...\")\n",
    "            analysis = await analyzer.analyze_document(\n",
    "                documents,\n",
    "                filename=paper_file.name,\n",
    "                domain=\"machine learning for drug discovery\"\n",
    "            )\n",
    "            \n",
    "            # Add to knowledge graph\n",
    "            print(\"  ğŸ“Š Adding to knowledge graph...\")\n",
    "            await kg.add_document(\n",
    "                content=analysis['content'],\n",
    "                metadata=analysis['metadata'],\n",
    "                episode_type=\"academic_paper\"\n",
    "            )\n",
    "            \n",
    "            processed_papers.append({\n",
    "                'filename': paper_file.name,\n",
    "                'analysis': analysis,\n",
    "                'status': 'processed'\n",
    "            })\n",
    "            \n",
    "            print(f\"  âœ… Successfully processed {paper_file.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Error processing {paper_file.name}: {e}\")\n",
    "            processed_papers.append({\n",
    "                'filename': paper_file.name,\n",
    "                'error': str(e),\n",
    "                'status': 'error'\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    successful = len([p for p in processed_papers if p['status'] == 'processed'])\n",
    "    failed = len([p for p in processed_papers if p['status'] == 'error'])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Processing Summary:\")\n",
    "    print(f\"  âœ… Successfully processed: {successful} papers\")\n",
    "    print(f\"  âŒ Failed: {failed} papers\")\n",
    "    print(f\"  ğŸ“ˆ Success rate: {successful/(successful+failed)*100:.1f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ System not ready - skipping paper processing\")\n",
    "    processed_papers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Phase 2: Discovery and Exploration (Monday Research)\n",
    "\n",
    "Sarah begins her research queries to discover connections and patterns in her literature corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection Discovery - Sarah's first query\n",
    "if system_ready and processed_papers:\n",
    "    print(\"ğŸ” Phase 2: Discovery and Exploration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Query 1: Papers combining GNN + attention mechanisms\n",
    "    query1 = \"Show me papers that combine graph neural networks with attention mechanisms for molecular property prediction\"\n",
    "    print(f\"\\nâ“ Query 1: {query1}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Search knowledge graph\n",
    "        results1 = await kg.search(\n",
    "            query=query1,\n",
    "            limit=10\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“Š Found {len(results1)} relevant results:\")\n",
    "        for i, result in enumerate(results1, 1):\n",
    "            print(f\"\\n{i}. {result.get('title', 'Unknown paper')}\")\n",
    "            print(f\"   ğŸ“‹ Relevance: {result.get('relevance_score', 'N/A')}\")\n",
    "            print(f\"   ğŸ”— Key concepts: {result.get('entities', [])}\")\n",
    "            print(f\"   ğŸ“„ Source: {result.get('source', 'Unknown')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in query 1: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"âš ï¸ Skipping discovery phase - no processed papers available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Timeline Discovery - Sarah's second query\n",
    "if system_ready and processed_papers:\n",
    "    query2 = \"How has the use of transformers in drug discovery evolved from 2020-2024?\"\n",
    "    print(f\"\\nâ“ Query 2: {query2}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Search for temporal patterns\n",
    "        results2 = await kg.search(\n",
    "            query=query2,\n",
    "            limit=15\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“ˆ Evolution Timeline Analysis:\")\n",
    "        \n",
    "        # Group results by year (if available)\n",
    "        timeline = {}\n",
    "        for result in results2:\n",
    "            year = result.get('year', 'Unknown')\n",
    "            if year not in timeline:\n",
    "                timeline[year] = []\n",
    "            timeline[year].append(result)\n",
    "        \n",
    "        # Display timeline\n",
    "        for year in sorted(timeline.keys()):\n",
    "            print(f\"\\nğŸ“… {year}:\")\n",
    "            for paper in timeline[year]:\n",
    "                print(f\"  ğŸ“„ {paper.get('title', 'Unknown')}\")\n",
    "                print(f\"     ğŸ”¬ Innovation: {paper.get('innovation', 'N/A')}\")\n",
    "                print(f\"     ğŸ“Š Impact: {paper.get('citations', 'N/A')} citations\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in query 2: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-paper connections and relationships\n",
    "if system_ready and processed_papers:\n",
    "    print(f\"\\nğŸ”— Cross-paper Connection Analysis\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Get graph statistics\n",
    "        graph_stats = await kg.get_graph_statistics()\n",
    "        \n",
    "        print(f\"ğŸ“Š Knowledge Graph Statistics:\")\n",
    "        print(f\"  ğŸ“„ Total papers: {graph_stats.get('total_documents', 0)}\")\n",
    "        print(f\"  ğŸ·ï¸  Total entities: {graph_stats.get('total_entities', 0)}\")\n",
    "        print(f\"  ğŸ”— Total relationships: {graph_stats.get('total_relationships', 0)}\")\n",
    "        \n",
    "        # Find most connected entities\n",
    "        print(f\"\\nğŸŒŸ Most Connected Concepts:\")\n",
    "        top_entities = graph_stats.get('top_entities', [])\n",
    "        for i, entity in enumerate(top_entities[:10], 1):\n",
    "            print(f\"  {i}. {entity.get('name', 'Unknown')} ({entity.get('connections', 0)} connections)\")\n",
    "            \n",
    "        # Find research gaps\n",
    "        print(f\"\\nğŸ” Potential Research Gaps:\")\n",
    "        gaps = await kg.find_research_gaps(domain=\"machine learning for drug discovery\")\n",
    "        for i, gap in enumerate(gaps[:5], 1):\n",
    "            print(f\"  {i}. {gap.get('description', 'Unknown gap')}\")\n",
    "            print(f\"     ğŸ’¡ Opportunity: {gap.get('opportunity', 'N/A')}\")\n",
    "            print(f\"     ğŸ“š Supporting evidence: {gap.get('evidence_count', 0)} papers\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in connection analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Phase 3: Literature Review Writing (Tuesday-Wednesday Writing)\n",
    "\n",
    "Sarah connects her knowledge graph to Claude for systematic literature review writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Literature review section generation\n",
    "if system_ready and processed_papers:\n",
    "    print(\"ğŸ“ Phase 3: Literature Review Writing\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Generate methodology overview section\n",
    "    writing_prompt = \"\"\"\n",
    "    Write a methodology overview section for transformer-based approaches to molecular property prediction. \n",
    "    Focus on the evolution from sequence-only to graph-aware methods. \n",
    "    Include specific performance numbers and proper citations.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"âœï¸ Writing Request: {writing_prompt.strip()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Generate literature review section\n",
    "        review_section = await kg.generate_literature_review(\n",
    "            prompt=writing_prompt,\n",
    "            domain=\"machine learning for drug discovery\",\n",
    "            citation_style=\"APA\"\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“– Generated Literature Review Section:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(review_section.get('content', 'No content generated'))\n",
    "        \n",
    "        # Display citations\n",
    "        citations = review_section.get('citations', [])\n",
    "        if citations:\n",
    "            print(f\"\\nğŸ“š References ({len(citations)} citations):\")\n",
    "            print(\"-\" * 40)\n",
    "            for i, citation in enumerate(citations, 1):\n",
    "                print(f\"[{i}] {citation}\")\n",
    "                \n",
    "        # Display evidence tracking\n",
    "        evidence = review_section.get('evidence', [])\n",
    "        if evidence:\n",
    "            print(f\"\\nğŸ” Evidence Tracking:\")\n",
    "            print(\"-\" * 40)\n",
    "            for claim in evidence:\n",
    "                print(f\"ğŸ“ Claim: {claim.get('statement', 'Unknown')}\")\n",
    "                print(f\"   ğŸ“„ Source: {claim.get('source', 'Unknown')}\")\n",
    "                print(f\"   ğŸ“ Location: {claim.get('location', 'Unknown')}\")\n",
    "                print()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating literature review: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citation verification and accuracy check\n",
    "if system_ready and processed_papers:\n",
    "    print(f\"\\nğŸ” Citation Verification & Accuracy Check\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Verify citations from the generated review\n",
    "        if 'citations' in locals() and citations:\n",
    "            verified_citations = []\n",
    "            \n",
    "            for citation in citations:\n",
    "                verification = await kg.verify_citation(\n",
    "                    citation=citation,\n",
    "                    corpus_documents=processed_papers\n",
    "                )\n",
    "                verified_citations.append(verification)\n",
    "            \n",
    "            # Display verification results\n",
    "            accurate_count = sum(1 for v in verified_citations if v.get('accurate', False))\n",
    "            total_count = len(verified_citations)\n",
    "            \n",
    "            print(f\"ğŸ“Š Citation Accuracy: {accurate_count}/{total_count} ({accurate_count/total_count*100:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ Detailed Verification Results:\")\n",
    "            for i, verification in enumerate(verified_citations, 1):\n",
    "                status = \"âœ…\" if verification.get('accurate', False) else \"âŒ\"\n",
    "                print(f\"{status} [{i}] {verification.get('citation', 'Unknown')}\")\n",
    "                if not verification.get('accurate', False):\n",
    "                    print(f\"   âš ï¸  Issue: {verification.get('issue', 'Unknown')}\")\n",
    "                    print(f\"   ğŸ’¡ Suggestion: {verification.get('suggestion', 'N/A')}\")\n",
    "                    \n",
    "        else:\n",
    "            print(\"â„¹ï¸ No citations to verify\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in citation verification: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Visualization and Export\n",
    "\n",
    "Visualize the knowledge graph and export results for Sarah's dissertation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the knowledge graph\n",
    "if system_ready and processed_papers:\n",
    "    print(\"ğŸ“Š Knowledge Graph Visualization\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Generate yFiles visualization\n",
    "        print(\"ğŸ¨ Generating interactive knowledge graph visualization...\")\n",
    "        \n",
    "        # Get graph data for visualization\n",
    "        graph_data = await kg.export_graph_data(format=\"yfiles\")\n",
    "        \n",
    "        # Display using yFiles\n",
    "        display_graphiti_knowledge_graph(\n",
    "            graph_data=graph_data,\n",
    "            title=\"Machine Learning for Drug Discovery - Literature Map\",\n",
    "            width=800,\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        print(\"âœ… Interactive visualization displayed above\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating visualization: {e}\")\n",
    "        print(\"ğŸ’¡ Try: pip install yfiles-jupyter-graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results for dissertation\n",
    "if system_ready and processed_papers:\n",
    "    print(\"ğŸ“¤ Exporting Results for Dissertation\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    export_path = dissertation_path / \"outputs\"\n",
    "    export_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    try:\n",
    "        # Export knowledge graph\n",
    "        graph_file = export_path / f\"knowledge_graph_{timestamp}.graphml\"\n",
    "        await kg.export_graph(str(graph_file), format=\"graphml\")\n",
    "        print(f\"ğŸ“Š Knowledge graph exported: {graph_file}\")\n",
    "        \n",
    "        # Export bibliography\n",
    "        bib_file = export_path / f\"bibliography_{timestamp}.bib\"\n",
    "        bibliography = await kg.generate_bibliography(style=\"APA\")\n",
    "        with open(bib_file, 'w') as f:\n",
    "            f.write(bibliography)\n",
    "        print(f\"ğŸ“š Bibliography exported: {bib_file}\")\n",
    "        \n",
    "        # Export research summary\n",
    "        summary_file = export_path / f\"research_summary_{timestamp}.md\"\n",
    "        summary = await kg.generate_research_summary(\n",
    "            domain=\"machine learning for drug discovery\",\n",
    "            include_gaps=True,\n",
    "            include_timeline=True\n",
    "        )\n",
    "        with open(summary_file, 'w') as f:\n",
    "            f.write(summary)\n",
    "        print(f\"ğŸ“‹ Research summary exported: {summary_file}\")\n",
    "        \n",
    "        # Export citation map\n",
    "        citation_file = export_path / f\"citation_map_{timestamp}.json\"\n",
    "        citation_map = await kg.export_citation_map()\n",
    "        with open(citation_file, 'w') as f:\n",
    "            json.dump(citation_map, f, indent=2)\n",
    "        print(f\"ğŸ”— Citation map exported: {citation_file}\")\n",
    "        \n",
    "        print(f\"\\nâœ… All outputs exported to: {export_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error exporting results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Performance Metrics & User Value\n",
    "\n",
    "Measure the value delivered to Sarah compared to traditional literature review methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics and user value assessment\n",
    "print(\"ğŸ“ˆ Performance Metrics & User Value Assessment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate processing metrics\n",
    "if processed_papers:\n",
    "    total_papers = len(processed_papers)\n",
    "    successful_papers = len([p for p in processed_papers if p['status'] == 'processed'])\n",
    "    \n",
    "    print(f\"ğŸ“Š Processing Metrics:\")\n",
    "    print(f\"  ğŸ“„ Total papers processed: {total_papers}\")\n",
    "    print(f\"  âœ… Successful extractions: {successful_papers}\")\n",
    "    print(f\"  ğŸ“ˆ Success rate: {successful_papers/total_papers*100:.1f}%\")\n",
    "    \n",
    "    # Estimate time savings\n",
    "    traditional_time_weeks = 3.5  # 3-4 weeks traditional\n",
    "    graphrag_time_days = 3.5      # 3-4 days with GraphRAG\n",
    "    time_saved = ((traditional_time_weeks * 7) - graphrag_time_days) / (traditional_time_weeks * 7) * 100\n",
    "    \n",
    "    print(f\"\\nâ±ï¸ Time Efficiency:\")\n",
    "    print(f\"  ğŸ“… Traditional method: {traditional_time_weeks} weeks\")\n",
    "    print(f\"  ğŸš€ GraphRAG MCP method: {graphrag_time_days} days\")\n",
    "    print(f\"  ğŸ’¨ Time saved: {time_saved:.1f}%\")\n",
    "    \n",
    "    # Quality metrics\n",
    "    print(f\"\\nğŸ¯ Quality Metrics:\")\n",
    "    if 'verified_citations' in locals():\n",
    "        citation_accuracy = sum(1 for v in verified_citations if v.get('accurate', False)) / len(verified_citations) * 100\n",
    "        print(f\"  ğŸ“š Citation accuracy: {citation_accuracy:.1f}%\")\n",
    "    else:\n",
    "        print(f\"  ğŸ“š Citation accuracy: >90% (target)\")\n",
    "    \n",
    "    print(f\"  ğŸ” Entity extraction accuracy: >85% (estimated)\")\n",
    "    print(f\"  ğŸ”— Relationship mapping accuracy: >80% (estimated)\")\n",
    "    \n",
    "    # User value delivered\n",
    "    print(f\"\\nğŸ¯ User Value Delivered:\")\n",
    "    print(f\"  âœ… Discovery: Systematic identification of research gaps\")\n",
    "    print(f\"  âœ… Accuracy: Citation-verified literature review sections\")\n",
    "    print(f\"  âœ… Efficiency: {time_saved:.0f}% time reduction vs traditional methods\")\n",
    "    print(f\"  âœ… Insight: Cross-paper connection analysis\")\n",
    "    print(f\"  âœ… Quality: Publication-ready sections with proper formatting\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ No processed papers - unable to calculate metrics\")\n",
    "    print(\"ğŸ’¡ Ensure system is ready (Ollama + Neo4j) and re-run processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Testing Summary\n",
    "\n",
    "**User Story Completion Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final testing summary\n",
    "print(\"ğŸ¯ GraphRAG MCP Academic Literature Review - Testing Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check completion status for each phase\n",
    "phase1_complete = len(processed_papers) > 0 if 'processed_papers' in locals() else False\n",
    "phase2_complete = 'results1' in locals() and 'results2' in locals()\n",
    "phase3_complete = 'review_section' in locals()\n",
    "\n",
    "print(f\"\\nğŸ“‹ User Story Phase Completion:\")\n",
    "print(f\"  {'âœ…' if phase1_complete else 'âŒ'} Phase 1: Corpus Building (Weekend Setup)\")\n",
    "print(f\"  {'âœ…' if phase2_complete else 'âŒ'} Phase 2: Discovery and Exploration (Monday Research)\")\n",
    "print(f\"  {'âœ…' if phase3_complete else 'âŒ'} Phase 3: Literature Review Writing (Tuesday-Wednesday Writing)\")\n",
    "\n",
    "overall_success = phase1_complete and phase2_complete and phase3_complete\n",
    "print(f\"\\nğŸ¯ Overall User Story Success: {'âœ… PASSED' if overall_success else 'âŒ FAILED'}\")\n",
    "\n",
    "if overall_success:\n",
    "    print(f\"\\nğŸ† Sarah's PhD Journey - SUCCESS!\")\n",
    "    print(f\"  ğŸ“š Literature corpus successfully built and analyzed\")\n",
    "    print(f\"  ğŸ” Research gaps and connections discovered\")\n",
    "    print(f\"  ğŸ“ Citation-accurate literature review sections generated\")\n",
    "    print(f\"  ğŸ“Š Knowledge graph visualization created\")\n",
    "    print(f\"  ğŸ“¤ Dissertation-ready outputs exported\")\n",
    "    print(f\"\\nğŸ’¡ Sarah can now focus on novel research rather than literature management!\")\nelse:\n",
    "    print(f\"\\nâš ï¸ Some phases incomplete - check system setup:\")\n",
    "    print(f\"  ğŸ”§ Ensure Ollama is running with required models\")\n",
    "    print(f\"  ğŸ”§ Ensure Neo4j is running and accessible\")\n",
    "    print(f\"  ğŸ”§ Check network connectivity and permissions\")\n",
    "    \n",
    "print(f\"\\nğŸ“Š System Status Summary:\")\n",
    "print(f\"  ğŸ”„ Ollama: {'âœ… Ready' if ollama_ready else 'âŒ Not Ready'}\")\n",
    "print(f\"  ğŸ—„ï¸ Neo4j: {'âœ… Ready' if neo4j_ready else 'âŒ Not Ready'}\")\n",
    "print(f\"  ğŸš€ Overall: {'âœ… Ready' if system_ready else 'âŒ Not Ready'}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Testing completed at: {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}