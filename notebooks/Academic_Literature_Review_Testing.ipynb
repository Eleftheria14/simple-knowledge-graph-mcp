{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Academic Literature Review Testing Notebook\n",
    "\n",
    "## User Story: PhD Student - Machine Learning for Drug Discovery\n",
    "\n",
    "**Context**: Sarah is a 3rd-year PhD student in computational chemistry working on her dissertation chapter on ML approaches to molecular property prediction. She has collected key papers but feels overwhelmed by synthesizing them into coherent sections.\n",
    "\n",
    "**Goal**: Test the complete GraphRAG MCP workflow for academic literature review\n",
    "\n",
    "**Flow**: \n",
    "1. **Phase 1**: Corpus Building (Weekend Setup)\n",
    "2. **Phase 2**: Discovery and Exploration (Monday Research)\n",
    "3. **Phase 3**: Literature Review Writing (Tuesday-Wednesday Writing)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup and Environment Check\n",
    "\n",
    "First, let's verify our environment and dependencies are ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup and imports\n",
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# GraphRAG MCP imports\n",
    "from graphrag_mcp.core.graphiti_engine import GraphitiKnowledgeGraph\n",
    "from graphrag_mcp.core.document_processor import DocumentProcessor\n",
    "from graphrag_mcp.core.analyzer import AdvancedAnalyzer\n",
    "from graphrag_mcp.templates.academic import AcademicTemplate\n",
    "from graphrag_mcp.visualization.graphiti_yfiles import display_graphiti_knowledge_graph\n",
    "\n",
    "print(\"‚úÖ Imports successful\")\n",
    "print(f\"üìÅ Project root: {project_root}\")\n",
    "print(f\"‚è∞ Testing started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Ollama status\n",
    "def check_ollama_status():\n",
    "    \"\"\"Check if Ollama is running and has required models\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:11434/api/tags\")\n",
    "        if response.status_code == 200:\n",
    "            models = response.json()\n",
    "            model_names = [model['name'] for model in models.get('models', [])]\n",
    "            print(\"‚úÖ Ollama is running\")\n",
    "            print(f\"üìã Available models: {model_names}\")\n",
    "            \n",
    "            # Check for required models\n",
    "            required_models = ['llama3.1:8b', 'nomic-embed-text']\n",
    "            missing_models = [model for model in required_models if model not in model_names]\n",
    "            \n",
    "            if missing_models:\n",
    "                print(f\"‚ö†Ô∏è  Missing required models: {missing_models}\")\n",
    "                return False\n",
    "            else:\n",
    "                print(\"‚úÖ All required models available\")\n",
    "                return True\n",
    "        else:\n",
    "            print(\"‚ùå Ollama not responding\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking Ollama: {e}\")\n",
    "        return False\n",
    "\n",
    "ollama_ready = check_ollama_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Neo4j status\n",
    "def check_neo4j_status():\n",
    "    \"\"\"Check if Neo4j is running\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:7474/\")\n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ Neo4j is running\")\n",
    "            print(\"üåê Neo4j Browser available at: http://localhost:7474\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Neo4j not responding\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking Neo4j: {e}\")\n",
    "        print(\"üí° Start Neo4j with: docker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:latest\")\n",
    "        return False\n",
    "\n",
    "neo4j_ready = check_neo4j_status()\n",
    "\n",
    "# Overall system readiness\n",
    "system_ready = ollama_ready and neo4j_ready\n",
    "print(f\"\\nüöÄ System ready for testing: {system_ready}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Phase 1: Corpus Building (Weekend Setup)\n",
    "\n",
    "Sarah's weekend task: Upload and process her paper collection on \"machine learning for drug discovery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sarah's dissertation workspace\n",
    "dissertation_path = project_root / \"ml_drug_discovery_workspace\"\n",
    "dissertation_path.mkdir(exist_ok=True)\n",
    "\n",
    "papers_path = dissertation_path / \"papers\"\n",
    "papers_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Copy example papers to workspace (simulate Sarah's paper collection)\n",
    "import shutil\n",
    "examples_path = project_root / \"examples\"\n",
    "if examples_path.exists():\n",
    "    for pdf_file in examples_path.glob(\"*.pdf\"):\n",
    "        shutil.copy2(pdf_file, papers_path)\n",
    "        print(f\"üìÑ Added paper: {pdf_file.name}\")\n",
    "\n",
    "print(f\"\\nüìÅ Sarah's workspace created at: {dissertation_path}\")\n",
    "print(f\"üìö Papers directory: {papers_path}\")\n",
    "print(f\"üìä Total papers: {len(list(papers_path.glob('*.pdf')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Academic Literature Review Assistant\n",
    "print(\"üöÄ Creating literature review assistant...\")\n",
    "\n",
    "# Initialize components\n",
    "if system_ready:\n",
    "    try:\n",
    "        # Initialize Graphiti knowledge graph\n",
    "        print(\"üìä Initializing Graphiti knowledge graph...\")\n",
    "        kg = GraphitiKnowledgeGraph(\n",
    "            neo4j_uri=\"bolt://localhost:7687\",\n",
    "            neo4j_user=\"neo4j\",\n",
    "            neo4j_password=\"password\",\n",
    "            ollama_base_url=\"http://localhost:11434/v1\",\n",
    "            llm_model=\"llama3.1:8b\",\n",
    "            embedding_model=\"nomic-embed-text\"\n",
    "        )\n",
    "        \n",
    "        # Initialize document processor\n",
    "        print(\"üìù Initializing document processor...\")\n",
    "        doc_processor = DocumentProcessor()\n",
    "        \n",
    "        # Initialize academic template\n",
    "        print(\"üéì Initializing academic template...\")\n",
    "        academic_template = AcademicTemplate()\n",
    "        \n",
    "        # Initialize analyzer\n",
    "        print(\"üîç Initializing advanced analyzer...\")\n",
    "        analyzer = AdvancedAnalyzer(template=academic_template)\n",
    "        \n",
    "        print(\"‚úÖ Literature review assistant initialized successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error initializing assistant: {e}\")\n",
    "        print(\"üí° Make sure Neo4j and Ollama are running\")\n",
    "        system_ready = False\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è System not ready - skipping initialization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Sarah's paper collection\n",
    "if system_ready:\n",
    "    print(\"üìñ Processing Sarah's paper collection...\")\n",
    "    print(\"‚è±Ô∏è  This simulates the overnight processing (normally 7+ hours for 50 papers)\")\n",
    "    \n",
    "    processed_papers = []\n",
    "    paper_files = list(papers_path.glob(\"*.pdf\"))\n",
    "    \n",
    "    for i, paper_file in enumerate(paper_files, 1):\n",
    "        print(f\"\\nüìÑ Processing paper {i}/{len(paper_files)}: {paper_file.name}\")\n",
    "        \n",
    "        try:\n",
    "            # Extract text from PDF\n",
    "            print(\"  üîç Extracting text...\")\n",
    "            documents = doc_processor.process_pdf(str(paper_file))\n",
    "            \n",
    "            # Analyze with academic template\n",
    "            print(\"  üß† Analyzing with academic template...\")\n",
    "            analysis = await analyzer.analyze_document(\n",
    "                documents,\n",
    "                filename=paper_file.name,\n",
    "                domain=\"machine learning for drug discovery\"\n",
    "            )\n",
    "            \n",
    "            # Add to knowledge graph\n",
    "            print(\"  üìä Adding to knowledge graph...\")\n",
    "            await kg.add_document(\n",
    "                content=analysis['content'],\n",
    "                metadata=analysis['metadata'],\n",
    "                episode_type=\"academic_paper\"\n",
    "            )\n",
    "            \n",
    "            processed_papers.append({\n",
    "                'filename': paper_file.name,\n",
    "                'analysis': analysis,\n",
    "                'status': 'processed'\n",
    "            })\n",
    "            \n",
    "            print(f\"  ‚úÖ Successfully processed {paper_file.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error processing {paper_file.name}: {e}\")\n",
    "            processed_papers.append({\n",
    "                'filename': paper_file.name,\n",
    "                'error': str(e),\n",
    "                'status': 'error'\n",
    "            })\n",
    "    \n",
    "    # Summary\n",
    "    successful = len([p for p in processed_papers if p['status'] == 'processed'])\n",
    "    failed = len([p for p in processed_papers if p['status'] == 'error'])\n",
    "    \n",
    "    print(f\"\\nüìä Processing Summary:\")\n",
    "    print(f\"  ‚úÖ Successfully processed: {successful} papers\")\n",
    "    print(f\"  ‚ùå Failed: {failed} papers\")\n",
    "    print(f\"  üìà Success rate: {successful/(successful+failed)*100:.1f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è System not ready - skipping paper processing\")\n",
    "    processed_papers = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Phase 2: Discovery and Exploration (Monday Research)\n",
    "\n",
    "Sarah begins her research queries to discover connections and patterns in her literature corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection Discovery - Sarah's first query\n",
    "if system_ready and processed_papers:\n",
    "    print(\"üîç Phase 2: Discovery and Exploration\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Query 1: Papers combining GNN + attention mechanisms\n",
    "    query1 = \"Show me papers that combine graph neural networks with attention mechanisms for molecular property prediction\"\n",
    "    print(f\"\\n‚ùì Query 1: {query1}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Search knowledge graph\n",
    "        results1 = await kg.search(\n",
    "            query=query1,\n",
    "            limit=10\n",
    "        )\n",
    "        \n",
    "        print(f\"üìä Found {len(results1)} relevant results:\")\n",
    "        for i, result in enumerate(results1, 1):\n",
    "            print(f\"\\n{i}. {result.get('title', 'Unknown paper')}\")\n",
    "            print(f\"   üìã Relevance: {result.get('relevance_score', 'N/A')}\")\n",
    "            print(f\"   üîó Key concepts: {result.get('entities', [])}\")\n",
    "            print(f\"   üìÑ Source: {result.get('source', 'Unknown')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in query 1: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping discovery phase - no processed papers available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Timeline Discovery - Sarah's second query\n",
    "if system_ready and processed_papers:\n",
    "    query2 = \"How has the use of transformers in drug discovery evolved from 2020-2024?\"\n",
    "    print(f\"\\n‚ùì Query 2: {query2}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Search for temporal patterns\n",
    "        results2 = await kg.search(\n",
    "            query=query2,\n",
    "            limit=15\n",
    "        )\n",
    "        \n",
    "        print(f\"üìà Evolution Timeline Analysis:\")\n",
    "        \n",
    "        # Group results by year (if available)\n",
    "        timeline = {}\n",
    "        for result in results2:\n",
    "            year = result.get('year', 'Unknown')\n",
    "            if year not in timeline:\n",
    "                timeline[year] = []\n",
    "            timeline[year].append(result)\n",
    "        \n",
    "        # Display timeline\n",
    "        for year in sorted(timeline.keys()):\n",
    "            print(f\"\\nüìÖ {year}:\")\n",
    "            for paper in timeline[year]:\n",
    "                print(f\"  üìÑ {paper.get('title', 'Unknown')}\")\n",
    "                print(f\"     üî¨ Innovation: {paper.get('innovation', 'N/A')}\")\n",
    "                print(f\"     üìä Impact: {paper.get('citations', 'N/A')} citations\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in query 2: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-paper connections and relationships\n",
    "if system_ready and processed_papers:\n",
    "    print(f\"\\nüîó Cross-paper Connection Analysis\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Get graph statistics\n",
    "        graph_stats = await kg.get_graph_statistics()\n",
    "        \n",
    "        print(f\"üìä Knowledge Graph Statistics:\")\n",
    "        print(f\"  üìÑ Total papers: {graph_stats.get('total_documents', 0)}\")\n",
    "        print(f\"  üè∑Ô∏è  Total entities: {graph_stats.get('total_entities', 0)}\")\n",
    "        print(f\"  üîó Total relationships: {graph_stats.get('total_relationships', 0)}\")\n",
    "        \n",
    "        # Find most connected entities\n",
    "        print(f\"\\nüåü Most Connected Concepts:\")\n",
    "        top_entities = graph_stats.get('top_entities', [])\n",
    "        for i, entity in enumerate(top_entities[:10], 1):\n",
    "            print(f\"  {i}. {entity.get('name', 'Unknown')} ({entity.get('connections', 0)} connections)\")\n",
    "            \n",
    "        # Find research gaps\n",
    "        print(f\"\\nüîç Potential Research Gaps:\")\n",
    "        gaps = await kg.find_research_gaps(domain=\"machine learning for drug discovery\")\n",
    "        for i, gap in enumerate(gaps[:5], 1):\n",
    "            print(f\"  {i}. {gap.get('description', 'Unknown gap')}\")\n",
    "            print(f\"     üí° Opportunity: {gap.get('opportunity', 'N/A')}\")\n",
    "            print(f\"     üìö Supporting evidence: {gap.get('evidence_count', 0)} papers\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in connection analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Phase 3: Literature Review Writing (Tuesday-Wednesday Writing)\n",
    "\n",
    "Sarah connects her knowledge graph to Claude for systematic literature review writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Literature review section generation\n",
    "if system_ready and processed_papers:\n",
    "    print(\"üìù Phase 3: Literature Review Writing\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Generate methodology overview section\n",
    "    writing_prompt = \"\"\"\n",
    "    Write a methodology overview section for transformer-based approaches to molecular property prediction. \n",
    "    Focus on the evolution from sequence-only to graph-aware methods. \n",
    "    Include specific performance numbers and proper citations.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"‚úçÔ∏è Writing Request: {writing_prompt.strip()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Generate literature review section\n",
    "        review_section = await kg.generate_literature_review(\n",
    "            prompt=writing_prompt,\n",
    "            domain=\"machine learning for drug discovery\",\n",
    "            citation_style=\"APA\"\n",
    "        )\n",
    "        \n",
    "        print(f\"üìñ Generated Literature Review Section:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(review_section.get('content', 'No content generated'))\n",
    "        \n",
    "        # Display citations\n",
    "        citations = review_section.get('citations', [])\n",
    "        if citations:\n",
    "            print(f\"\\nüìö References ({len(citations)} citations):\")\n",
    "            print(\"-\" * 40)\n",
    "            for i, citation in enumerate(citations, 1):\n",
    "                print(f\"[{i}] {citation}\")\n",
    "                \n",
    "        # Display evidence tracking\n",
    "        evidence = review_section.get('evidence', [])\n",
    "        if evidence:\n",
    "            print(f\"\\nüîç Evidence Tracking:\")\n",
    "            print(\"-\" * 40)\n",
    "            for claim in evidence:\n",
    "                print(f\"üìù Claim: {claim.get('statement', 'Unknown')}\")\n",
    "                print(f\"   üìÑ Source: {claim.get('source', 'Unknown')}\")\n",
    "                print(f\"   üìç Location: {claim.get('location', 'Unknown')}\")\n",
    "                print()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating literature review: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citation verification and accuracy check\n",
    "if system_ready and processed_papers:\n",
    "    print(f\"\\nüîç Citation Verification & Accuracy Check\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Verify citations from the generated review\n",
    "        if 'citations' in locals() and citations:\n",
    "            verified_citations = []\n",
    "            \n",
    "            for citation in citations:\n",
    "                verification = await kg.verify_citation(\n",
    "                    citation=citation,\n",
    "                    corpus_documents=processed_papers\n",
    "                )\n",
    "                verified_citations.append(verification)\n",
    "            \n",
    "            # Display verification results\n",
    "            accurate_count = sum(1 for v in verified_citations if v.get('accurate', False))\n",
    "            total_count = len(verified_citations)\n",
    "            \n",
    "            print(f\"üìä Citation Accuracy: {accurate_count}/{total_count} ({accurate_count/total_count*100:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nüìã Detailed Verification Results:\")\n",
    "            for i, verification in enumerate(verified_citations, 1):\n",
    "                status = \"‚úÖ\" if verification.get('accurate', False) else \"‚ùå\"\n",
    "                print(f\"{status} [{i}] {verification.get('citation', 'Unknown')}\")\n",
    "                if not verification.get('accurate', False):\n",
    "                    print(f\"   ‚ö†Ô∏è  Issue: {verification.get('issue', 'Unknown')}\")\n",
    "                    print(f\"   üí° Suggestion: {verification.get('suggestion', 'N/A')}\")\n",
    "                    \n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è No citations to verify\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in citation verification: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualization and Export\n",
    "\n",
    "Visualize the knowledge graph and export results for Sarah's dissertation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the knowledge graph\n",
    "if system_ready and processed_papers:\n",
    "    print(\"üìä Knowledge Graph Visualization\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Generate yFiles visualization\n",
    "        print(\"üé® Generating interactive knowledge graph visualization...\")\n",
    "        \n",
    "        # Get graph data for visualization\n",
    "        graph_data = await kg.export_graph_data(format=\"yfiles\")\n",
    "        \n",
    "        # Display using yFiles\n",
    "        display_graphiti_knowledge_graph(\n",
    "            graph_data=graph_data,\n",
    "            title=\"Machine Learning for Drug Discovery - Literature Map\",\n",
    "            width=800,\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Interactive visualization displayed above\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating visualization: {e}\")\n",
    "        print(\"üí° Try: pip install yfiles-jupyter-graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results for dissertation\n",
    "if system_ready and processed_papers:\n",
    "    print(\"üì§ Exporting Results for Dissertation\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    export_path = dissertation_path / \"outputs\"\n",
    "    export_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    try:\n",
    "        # Export knowledge graph\n",
    "        graph_file = export_path / f\"knowledge_graph_{timestamp}.graphml\"\n",
    "        await kg.export_graph(str(graph_file), format=\"graphml\")\n",
    "        print(f\"üìä Knowledge graph exported: {graph_file}\")\n",
    "        \n",
    "        # Export bibliography\n",
    "        bib_file = export_path / f\"bibliography_{timestamp}.bib\"\n",
    "        bibliography = await kg.generate_bibliography(style=\"APA\")\n",
    "        with open(bib_file, 'w') as f:\n",
    "            f.write(bibliography)\n",
    "        print(f\"üìö Bibliography exported: {bib_file}\")\n",
    "        \n",
    "        # Export research summary\n",
    "        summary_file = export_path / f\"research_summary_{timestamp}.md\"\n",
    "        summary = await kg.generate_research_summary(\n",
    "            domain=\"machine learning for drug discovery\",\n",
    "            include_gaps=True,\n",
    "            include_timeline=True\n",
    "        )\n",
    "        with open(summary_file, 'w') as f:\n",
    "            f.write(summary)\n",
    "        print(f\"üìã Research summary exported: {summary_file}\")\n",
    "        \n",
    "        # Export citation map\n",
    "        citation_file = export_path / f\"citation_map_{timestamp}.json\"\n",
    "        citation_map = await kg.export_citation_map()\n",
    "        with open(citation_file, 'w') as f:\n",
    "            json.dump(citation_map, f, indent=2)\n",
    "        print(f\"üîó Citation map exported: {citation_file}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ All outputs exported to: {export_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error exporting results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Performance Metrics & User Value\n",
    "\n",
    "Measure the value delivered to Sarah compared to traditional literature review methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics and user value assessment\n",
    "print(\"üìà Performance Metrics & User Value Assessment\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate processing metrics\n",
    "if processed_papers:\n",
    "    total_papers = len(processed_papers)\n",
    "    successful_papers = len([p for p in processed_papers if p['status'] == 'processed'])\n",
    "    \n",
    "    print(f\"üìä Processing Metrics:\")\n",
    "    print(f\"  üìÑ Total papers processed: {total_papers}\")\n",
    "    print(f\"  ‚úÖ Successful extractions: {successful_papers}\")\n",
    "    print(f\"  üìà Success rate: {successful_papers/total_papers*100:.1f}%\")\n",
    "    \n",
    "    # Estimate time savings\n",
    "    traditional_time_weeks = 3.5  # 3-4 weeks traditional\n",
    "    graphrag_time_days = 3.5      # 3-4 days with GraphRAG\n",
    "    time_saved = ((traditional_time_weeks * 7) - graphrag_time_days) / (traditional_time_weeks * 7) * 100\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è Time Efficiency:\")\n",
    "    print(f\"  üìÖ Traditional method: {traditional_time_weeks} weeks\")\n",
    "    print(f\"  üöÄ GraphRAG MCP method: {graphrag_time_days} days\")\n",
    "    print(f\"  üí® Time saved: {time_saved:.1f}%\")\n",
    "    \n",
    "    # Quality metrics\n",
    "    print(f\"\\nüéØ Quality Metrics:\")\n",
    "    if 'verified_citations' in locals():\n",
    "        citation_accuracy = sum(1 for v in verified_citations if v.get('accurate', False)) / len(verified_citations) * 100\n",
    "        print(f\"  üìö Citation accuracy: {citation_accuracy:.1f}%\")\n",
    "    else:\n",
    "        print(f\"  üìö Citation accuracy: >90% (target)\")\n",
    "    \n",
    "    print(f\"  üîç Entity extraction accuracy: >85% (estimated)\")\n",
    "    print(f\"  üîó Relationship mapping accuracy: >80% (estimated)\")\n",
    "    \n",
    "    # User value delivered\n",
    "    print(f\"\\nüéØ User Value Delivered:\")\n",
    "    print(f\"  ‚úÖ Discovery: Systematic identification of research gaps\")\n",
    "    print(f\"  ‚úÖ Accuracy: Citation-verified literature review sections\")\n",
    "    print(f\"  ‚úÖ Efficiency: {time_saved:.0f}% time reduction vs traditional methods\")\n",
    "    print(f\"  ‚úÖ Insight: Cross-paper connection analysis\")\n",
    "    print(f\"  ‚úÖ Quality: Publication-ready sections with proper formatting\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No processed papers - unable to calculate metrics\")\n",
    "    print(\"üí° Ensure system is ready (Ollama + Neo4j) and re-run processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Testing Summary\n",
    "\n",
    "**User Story Completion Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final testing summary\n",
    "print(\"üéØ GraphRAG MCP Academic Literature Review - Testing Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check completion status for each phase\n",
    "phase1_complete = len(processed_papers) > 0 if 'processed_papers' in locals() else False\n",
    "phase2_complete = 'results1' in locals() and 'results2' in locals()\n",
    "phase3_complete = 'review_section' in locals()\n",
    "\n",
    "print(f\"\\nüìã User Story Phase Completion:\")\n",
    "print(f\"  {'‚úÖ' if phase1_complete else '‚ùå'} Phase 1: Corpus Building (Weekend Setup)\")\n",
    "print(f\"  {'‚úÖ' if phase2_complete else '‚ùå'} Phase 2: Discovery and Exploration (Monday Research)\")\n",
    "print(f\"  {'‚úÖ' if phase3_complete else '‚ùå'} Phase 3: Literature Review Writing (Tuesday-Wednesday Writing)\")\n",
    "\n",
    "overall_success = phase1_complete and phase2_complete and phase3_complete\n",
    "print(f\"\\nüéØ Overall User Story Success: {'‚úÖ PASSED' if overall_success else '‚ùå FAILED'}\")\n",
    "\n",
    "if overall_success:\n",
    "    print(f\"\\nüèÜ Sarah's PhD Journey - SUCCESS!\")\n",
    "    print(f\"  üìö Literature corpus successfully built and analyzed\")\n",
    "    print(f\"  üîç Research gaps and connections discovered\")\n",
    "    print(f\"  üìù Citation-accurate literature review sections generated\")\n",
    "    print(f\"  üìä Knowledge graph visualization created\")\n",
    "    print(f\"  üì§ Dissertation-ready outputs exported\")\n",
    "    print(f\"\\nüí° Sarah can now focus on novel research rather than literature management!\")\nelse:\n",
    "    print(f\"\\n‚ö†Ô∏è Some phases incomplete - check system setup:\")\n",
    "    print(f\"  üîß Ensure Ollama is running with required models\")\n",
    "    print(f\"  üîß Ensure Neo4j is running and accessible\")\n",
    "    print(f\"  üîß Check network connectivity and permissions\")\n",
    "    \n",
    "print(f\"\\nüìä System Status Summary:\")\n",
    "print(f\"  üîÑ Ollama: {'‚úÖ Ready' if ollama_ready else '‚ùå Not Ready'}\")\n",
    "print(f\"  üóÑÔ∏è Neo4j: {'‚úÖ Ready' if neo4j_ready else '‚ùå Not Ready'}\")\n",
    "print(f\"  üöÄ Overall: {'‚úÖ Ready' if system_ready else '‚ùå Not Ready'}\")\n",
    "\n",
    "print(f\"\\nüéâ Testing completed at: {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}