{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 📚 GraphRAG MCP Document Processing\n\nTransform your PDF documents into an intelligent AI research assistant!\n\n## 🎯 What You'll Build\nBy the end of this notebook, you'll have:\n- 🕸️ **Knowledge Graph** - Your documents transformed into connected concepts\n- 🤖 **AI Research Assistant** - Chat with your documents via Claude Desktop\n- 📊 **Analytics** - See what entities and citations were extracted\n- 🔄 **Dual-Mode Tools** - Both conversational chat and formal literature review\n- 🎨 **Interactive Visualization** - See your knowledge graph in action\n\n## 📋 Prerequisites (5 minutes setup)\n\n**Before running this notebook, make sure you have:**\n\n### 1. **Environment Setup**\n```bash\n# Activate your Python environment\nsource graphrag-env/bin/activate  # or your environment name\n\n# Install dependencies\nuv pip install -r requirements.txt\n\n# Install visualization libraries\npip install plotly networkx\n```\n\n### 2. **Ollama (AI Models)**\n```bash\n# Install Ollama\nbrew install ollama  # macOS\n# or download from https://ollama.com\n\n# Download required models\nollama pull llama3.1:8b\nollama pull nomic-embed-text\n\n# Start Ollama server (keep this running)\nollama serve\n```\n\n### 3. **Neo4j Database**\n```bash\n# Start Neo4j with Docker (keep this running)\ndocker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:latest\n\n# Verify it's running\ncurl -f http://localhost:7474/\n```\n\n### 4. **Your Documents**\n- 📄 **PDFs ready**: Put your research papers in a folder\n- 📁 **Folder path**: Know where your documents are located\n- 📊 **5-20 documents**: Good size for testing (too many = long processing time)\n\n## 🚨 Troubleshooting\nIf you see errors below, check:\n- ✅ **Ollama running**: `curl -s http://localhost:11434/api/tags`\n- ✅ **Neo4j running**: `curl -f http://localhost:7474/`\n- ✅ **Models installed**: `ollama list`\n- ✅ **Python environment**: `which python`\n- ✅ **Plotly installed**: `pip install plotly networkx`\n\n---\n\n## 🏃‍♀️ Quick Start: Run All Cells\n1. **Update settings** in the Setup cell below\n2. **Run all cells** (Cell → Run All)\n3. **Wait for processing** (progress bars will show)\n4. **View your knowledge graph** visualization\n5. **Follow next steps** for Claude Desktop integration\n\n**⏱️ Processing Time:** ~2-10 minutes per document\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🚀 Setup & Configuration\n\n**📝 Customize these settings for your project:**"
  },
  {
   "cell_type": "code",
   "source": "# 🔍 Run comprehensive prerequisites check\nfrom processing_utils import check_prerequisites\n\n# This will check all services, packages, and configurations\nresult = check_prerequisites()\n\nif result[\"status\"] == \"passed\":\n    print(\"\\n🚀 All systems ready! You can proceed to the next cell.\")\nelse:\n    print(f\"\\n⚠️  Found {len(result['issues'])} issues that need to be fixed:\")\n    for i, issue in enumerate(result['issues'], 1):\n        print(f\"   {i}. ❌ {issue}\")\n    \n    print(\"\\n🛑 Please fix these issues before continuing!\")\n    print(\"💡 Refer to the detailed output above for specific solutions.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 🔍 Prerequisites Check\n\n**🚨 Let's verify all required services are running properly:**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from processing_utils import quick_setup, check_prerequisites\n\n# ⚙️ CUSTOMIZE THESE SETTINGS FOR YOUR PROJECT:\nPROJECT_NAME = \"my-research\"        # 📝 Change this to your project name\nDOCUMENTS_FOLDER = \"../../examples\"    # 📁 Change to your documents folder path\n\n# Examples of document folder paths:\n# DOCUMENTS_FOLDER = \"~/Documents/research-papers\"\n# DOCUMENTS_FOLDER = \"./my-pdfs\"\n# DOCUMENTS_FOLDER = \"/Users/yourname/Desktop/papers\"\n# DOCUMENTS_FOLDER = \"../../examples\"  # Default: examples folder in main project\n\nprint(\"🔧 Checking prerequisites...\")\ncheck_prerequisites()\n\nprint(f\"\\n🏗️  Initializing GraphRAG processor...\")\nprocessor = quick_setup(PROJECT_NAME, DOCUMENTS_FOLDER)\nprint(f\"✅ Ready to process project: {PROJECT_NAME}\")\nprint(f\"📁 Looking for documents in: {DOCUMENTS_FOLDER}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 📄 Document Discovery\n\n**🔍 Finding PDFs in your folder...**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🔍 Scan for PDF documents\ndocuments = processor.discover_documents(DOCUMENTS_FOLDER)\n\nif documents:\n    print(f\"\\n📊 Found {len(documents)} PDF documents:\")\n    total_size = sum(doc.size_mb for doc in documents)\n    est_time = len(documents) * 5  # Rough estimate: 5 minutes per document\n    \n    print(f\"   📏 Total size: {total_size:.2f} MB\")\n    print(f\"   ⏱️  Estimated processing time: {est_time} minutes\")\n    print(f\"\\n📋 Document list:\")\n    \n    for i, doc in enumerate(documents, 1):\n        print(f\"   {i:2d}. 📄 {doc.name} ({doc.size_mb} MB)\")\n    \n    print(f\"\\n✅ Ready to process {len(documents)} documents\")\n    \nelse:\n    print(\"❌ No PDF documents found!\")\n    print(f\"   📁 Checked folder: {DOCUMENTS_FOLDER}\")\n    print(f\"   💡 Make sure your PDF files are in the correct folder\")\n    print(f\"   🔧 Try updating DOCUMENTS_FOLDER path in the cell above\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🔄 Processing Documents\n\n**🚀 This will process all documents and build the knowledge graph...**\n\n*You'll see progress bars as documents are processed. This may take several minutes.*"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🚀 Process all documents with progress tracking\nif documents:\n    print(f\"🔄 Starting processing of {len(documents)} documents...\")\n    print(f\"⏳ Please wait - this may take several minutes...\")\n    \n    # Process documents (this will show progress bars)\n    results = await processor.process_documents(documents)\n    \n    # Show results summary\n    print(f\"\\n📊 Processing Complete!\")\n    print(f\"   ✅ Successfully processed: {results['success']}/{len(documents)} documents\")\n    \n    if results['failed'] > 0:\n        print(f\"   ❌ Failed: {results['failed']} documents\")\n        print(f\"   🔄 You can retry failed documents in the next section\")\n    \n    print(f\"   ⏱️  Total processing time: {results['total_time']/60:.1f} minutes\")\n    print(f\"   ⚡ Average per document: {results['avg_time']:.1f} seconds\")\n    \n    if results['success'] > 0:\n        print(f\"\\n🎉 Success! Your knowledge graph is ready!\")\n        print(f\"   🕸️  Documents are now connected in Neo4j database\")\n        print(f\"   🤖 Ready to create your AI research assistant\")\n    \nelse:\n    print(\"❌ No documents to process\")\n    print(\"   Go back to the 'Document Discovery' section and check your folder path\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 📊 Processing Results & Analytics\n\n**📈 See detailed results and performance metrics:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 📊 Show detailed processing results\nif documents:\n    print(\"📋 Detailed Processing Results:\")\n    print(\"=\" * 80)\n    \n    # Results table\n    df = processor.get_results_dataframe(documents)\n    print(df.to_string(index=False))\n    \n    # Key metrics\n    completed = df[df['Status'] == 'completed']\n    if not completed.empty:\n        print(f\"\\n📈 Key Metrics:\")\n        print(f\"   🔢 Total entities extracted: {completed['Entities'].sum()}\")\n        print(f\"   📚 Total citations found: {completed['Citations'].sum()}\")\n        print(f\"   ⚡ Average entities per document: {completed['Entities'].mean():.1f}\")\n        print(f\"   ⏱️  Fastest document: {completed['Time (s)'].min():.1f} seconds\")\n        print(f\"   🐌 Slowest document: {completed['Time (s)'].max():.1f} seconds\")\n    \n    print(f\"\\n📊 Generating analytics charts...\")\n    # Analytics charts (this will show visualizations)\n    processor.show_analytics(documents)\n    \nelse:\n    print(\"❌ No results to display\")\n    print(\"   Process documents first in the section above\")"
  },
  {
   "cell_type": "code",
   "source": "# 🕸️ Create interactive knowledge graph visualization\nif documents and any(doc.status == \"completed\" for doc in documents):\n    print(\"🎨 Creating interactive knowledge graph...\")\n    print(\"   📊 This shows documents (blue) and entities (red) with their connections\")\n    print(\"   🖱️  You can hover over nodes to see details\")\n    print(\"   🔍 Larger nodes have more connections\")\n    print()\n    \n    # Create the visualization\n    graph = processor.visualize_knowledge_graph(documents, max_nodes=50)\n    \n    if graph:\n        print(\"✅ Knowledge graph visualization complete!\")\n        print(\"   🎯 Blue nodes = Documents\")\n        print(\"   🎯 Red nodes = Entities\")\n        print(\"   🎯 Lines = Connections\")\n        print(\"   💡 This shows how your documents are connected through shared concepts\")\n    else:\n        print(\"❌ Could not create visualization\")\n        print(\"   📦 Install required libraries: pip install plotly networkx\")\n        \nelse:\n    print(\"❌ No completed documents to visualize\")\n    print(\"   Process documents first in the sections above\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 🕸️ Knowledge Graph Visualization\n\n**🎨 Interactive visualization of your knowledge graph:**",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🔄 Error Recovery (Optional)\n\n**🛠️ If some documents failed, you can retry them here:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🔍 Check for failed documents\nfailed_docs = processor.get_failed_documents(documents)\n\nif failed_docs:\n    print(f\"❌ Found {len(failed_docs)} failed documents:\")\n    print(f\"   📋 Failed documents and errors:\")\n    \n    for i, doc in enumerate(failed_docs, 1):\n        print(f\"   {i}. 📄 {doc.name}\")\n        print(f\"      💥 Error: {doc.error_message}\")\n        print()\n    \n    print(f\"🔄 To retry failed documents:\")\n    print(f\"   1. Uncomment the lines below\")\n    print(f\"   2. Run this cell again\")\n    print(f\"   3. Wait for processing to complete\")\n    print()\n    \n    # 🔄 UNCOMMENT THESE LINES TO RETRY FAILED DOCUMENTS:\n    # print(\"🔄 Retrying failed documents...\")\n    # processor.reset_for_retry(failed_docs)\n    # retry_results = await processor.process_documents(failed_docs)\n    # print(f\"✅ Retry complete: {retry_results['success']} success, {retry_results['failed']} still failed\")\n    \nelse:\n    print(\"✅ No failed documents - all processing successful!\")\n    print(\"   🎉 Your knowledge graph is complete and ready to use\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🎯 Next Steps: Create Your AI Research Assistant\n\n**🚀 Your knowledge graph is ready! Now connect it to Claude Desktop:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🎯 Show next steps for MCP server setup\nprint(\"🎉 Congratulations! Your GraphRAG MCP system is ready!\")\nprint(\"=\" * 60)\n\nprocessor.print_next_steps()\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"🎮 How to Use Your AI Research Assistant:\")\nprint()\nprint(\"📝 Conversational Mode (Explore & Discover):\")\nprint('   • \"Ask knowledge graph: What are the main themes in my research?\"')\nprint('   • \"Explore topic: machine learning applications\"')\nprint('   • \"Find connections between neural networks and optimization\"')\nprint('   • \"What do we know about drug discovery?\"')\nprint()\nprint(\"📚 Literature Review Mode (Formal Writing):\")\nprint('   • \"Gather sources for topic: transformer architectures\"')\nprint('   • \"Get facts with citations about attention mechanisms in APA style\"')\nprint('   • \"Verify claim with sources: BERT outperforms traditional NLP models\"')\nprint('   • \"Generate bibliography in IEEE style\"')\nprint()\nprint(\"🔍 Research Analysis:\")\nprint('   • \"Find research gaps in my field\"')\nprint('   • \"Compare methodologies for sentiment analysis\"')\nprint('   • \"Analyze contributions by [author name]\"')\nprint('   • \"Track evolution of [concept] over time\"')\nprint()\nprint(\"✨ Your documents are now an intelligent AI research assistant!\")\nprint(\"🎯 Happy researching! 🎓\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}