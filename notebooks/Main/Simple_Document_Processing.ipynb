{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸ“š GraphRAG MCP Document Processing\n\nTransform your PDF documents into an intelligent AI research assistant!\n\n## ğŸ¯ What You'll Build\nBy the end of this notebook, you'll have:\n- ğŸ•¸ï¸ **Knowledge Graph** - Your documents transformed into connected concepts\n- ğŸ¤– **AI Research Assistant** - Chat with your documents via Claude Desktop\n- ğŸ“Š **Analytics** - See what entities and citations were extracted\n- ğŸ”„ **Dual-Mode Tools** - Both conversational chat and formal literature review\n- ğŸ¨ **Interactive Visualization** - See your knowledge graph in action\n\n## ğŸ“‹ Prerequisites (5 minutes setup)\n\n**Before running this notebook, make sure you have:**\n\n### 1. **Environment Setup**\n```bash\n# Activate your Python environment\nsource graphrag-env/bin/activate  # or your environment name\n\n# Install dependencies\nuv pip install -r requirements.txt\n\n# Install visualization libraries\npip install plotly networkx\n```\n\n### 2. **Ollama (AI Models)**\n```bash\n# Install Ollama\nbrew install ollama  # macOS\n# or download from https://ollama.com\n\n# Download required models\nollama pull llama3.1:8b\nollama pull nomic-embed-text\n\n# Start Ollama server (keep this running)\nollama serve\n```\n\n### 3. **Neo4j Database**\n```bash\n# Start Neo4j with Docker (keep this running)\ndocker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:latest\n\n# Verify it's running\ncurl -f http://localhost:7474/\n```\n\n### 4. **Your Documents**\n- ğŸ“„ **PDFs ready**: Put your research papers in a folder\n- ğŸ“ **Folder path**: Know where your documents are located\n- ğŸ“Š **5-20 documents**: Good size for testing (too many = long processing time)\n\n## ğŸš¨ Troubleshooting\nIf you see errors below, check:\n- âœ… **Ollama running**: `curl -s http://localhost:11434/api/tags`\n- âœ… **Neo4j running**: `curl -f http://localhost:7474/`\n- âœ… **Models installed**: `ollama list`\n- âœ… **Python environment**: `which python`\n- âœ… **Plotly installed**: `pip install plotly networkx`\n\n---\n\n## ğŸƒâ€â™€ï¸ Quick Start: Run All Cells\n1. **Update settings** in the Setup cell below\n2. **Run all cells** (Cell â†’ Run All)\n3. **Wait for processing** (progress bars will show)\n4. **View your knowledge graph** visualization\n5. **Follow next steps** for Claude Desktop integration\n\n**â±ï¸ Processing Time:** ~2-10 minutes per document\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸš€ Setup & Configuration\n\n**ğŸ“ Customize these settings for your project:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Run comprehensive prerequisites check\n",
    "from processing_utils import check_prerequisites\n",
    "\n",
    "# This will check all services, packages, and configurations\n",
    "result = check_prerequisites()\n",
    "\n",
    "if result[\"status\"] == \"passed\":\n",
    "    print(\"\\nğŸš€ All systems ready! You can proceed to the next cell.\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Found {len(result['issues'])} issues that need to be fixed:\")\n",
    "    for i, issue in enumerate(result['issues'], 1):\n",
    "        print(f\"   {i}. âŒ {issue}\")\n",
    "\n",
    "    print(\"\\nğŸ›‘ Please fix these issues before continuing!\")\n",
    "    print(\"ğŸ’¡ Refer to the detailed output above for specific solutions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ” Prerequisites Check\n\n**ğŸš¨ Let's verify all required services are running properly:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing_utils import check_prerequisites, quick_setup\n",
    "\n",
    "# âš™ï¸ CUSTOMIZE THESE SETTINGS FOR YOUR PROJECT:\n",
    "PROJECT_NAME = \"my-research\"        # ğŸ“ Change this to your project name\n",
    "DOCUMENTS_FOLDER = \"../../examples\"    # ğŸ“ Change to your documents folder path\n",
    "\n",
    "# Examples of document folder paths:\n",
    "# DOCUMENTS_FOLDER = \"~/Documents/research-papers\"\n",
    "# DOCUMENTS_FOLDER = \"./my-pdfs\"\n",
    "# DOCUMENTS_FOLDER = \"/Users/yourname/Desktop/papers\"\n",
    "# DOCUMENTS_FOLDER = \"../../examples\"  # Default: examples folder in main project\n",
    "\n",
    "print(\"ğŸ”§ Checking prerequisites...\")\n",
    "check_prerequisites()\n",
    "\n",
    "print(\"\\nğŸ—ï¸  Initializing GraphRAG processor...\")\n",
    "processor = quick_setup(PROJECT_NAME, DOCUMENTS_FOLDER)\n",
    "print(f\"âœ… Ready to process project: {PROJECT_NAME}\")\n",
    "print(f\"ğŸ“ Looking for documents in: {DOCUMENTS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ“„ Document Discovery\n\n**ğŸ” Finding PDFs in your folder...**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Scan for PDF documents\n",
    "documents = processor.discover_documents(DOCUMENTS_FOLDER)\n",
    "\n",
    "if documents:\n",
    "    print(f\"\\nğŸ“Š Found {len(documents)} PDF documents:\")\n",
    "    total_size = sum(doc.size_mb for doc in documents)\n",
    "    est_time = len(documents) * 5  # Rough estimate: 5 minutes per document\n",
    "\n",
    "    print(f\"   ğŸ“ Total size: {total_size:.2f} MB\")\n",
    "    print(f\"   â±ï¸  Estimated processing time: {est_time} minutes\")\n",
    "    print(\"\\nğŸ“‹ Document list:\")\n",
    "\n",
    "    for i, doc in enumerate(documents, 1):\n",
    "        print(f\"   {i:2d}. ğŸ“„ {doc.name} ({doc.size_mb} MB)\")\n",
    "\n",
    "    print(f\"\\nâœ… Ready to process {len(documents)} documents\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No PDF documents found!\")\n",
    "    print(f\"   ğŸ“ Checked folder: {DOCUMENTS_FOLDER}\")\n",
    "    print(\"   ğŸ’¡ Make sure your PDF files are in the correct folder\")\n",
    "    print(\"   ğŸ”§ Try updating DOCUMENTS_FOLDER path in the cell above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ”„ Processing Documents\n\n**ğŸš€ This will process all documents and build the knowledge graph...**\n\n*You'll see progress bars as documents are processed. This may take several minutes.*"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ Process all documents with progress tracking\n",
    "if documents:\n",
    "    print(f\"ğŸ”„ Starting processing of {len(documents)} documents...\")\n",
    "    print(\"â³ Please wait - this may take several minutes...\")\n",
    "\n",
    "    # Process documents (this will show progress bars)\n",
    "    results = await processor.process_documents(documents)\n",
    "\n",
    "    # Show results summary\n",
    "    print(\"\\nğŸ“Š Processing Complete!\")\n",
    "    print(f\"   âœ… Successfully processed: {results['success']}/{len(documents)} documents\")\n",
    "\n",
    "    if results['failed'] > 0:\n",
    "        print(f\"   âŒ Failed: {results['failed']} documents\")\n",
    "        print(\"   ğŸ”„ You can retry failed documents in the next section\")\n",
    "\n",
    "    print(f\"   â±ï¸  Total processing time: {results['total_time']/60:.1f} minutes\")\n",
    "    print(f\"   âš¡ Average per document: {results['avg_time']:.1f} seconds\")\n",
    "\n",
    "    if results['success'] > 0:\n",
    "        print(\"\\nğŸ‰ Success! Your knowledge graph is ready!\")\n",
    "        print(\"   ğŸ•¸ï¸  Documents are now connected in Neo4j database\")\n",
    "        print(\"   ğŸ¤– Ready to create your AI research assistant\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No documents to process\")\n",
    "    print(\"   Go back to the 'Document Discovery' section and check your folder path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ“Š Processing Results & Analytics\n\n**ğŸ“ˆ See detailed results and performance metrics:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Show detailed processing results\n",
    "if documents:\n",
    "    print(\"ğŸ“‹ Detailed Processing Results:\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Results table\n",
    "    df = processor.get_results_dataframe(documents)\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    # Key metrics\n",
    "    completed = df[df['Status'] == 'completed']\n",
    "    if not completed.empty:\n",
    "        print(\"\\nğŸ“ˆ Key Metrics:\")\n",
    "        print(f\"   ğŸ”¢ Total entities extracted: {completed['Entities'].sum()}\")\n",
    "        print(f\"   ğŸ“š Total citations found: {completed['Citations'].sum()}\")\n",
    "        print(f\"   âš¡ Average entities per document: {completed['Entities'].mean():.1f}\")\n",
    "        print(f\"   â±ï¸  Fastest document: {completed['Time (s)'].min():.1f} seconds\")\n",
    "        print(f\"   ğŸŒ Slowest document: {completed['Time (s)'].max():.1f} seconds\")\n",
    "\n",
    "    print(\"\\nğŸ“Š Generating analytics charts...\")\n",
    "    # Analytics charts (this will show visualizations)\n",
    "    processor.show_analytics(documents)\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No results to display\")\n",
    "    print(\"   Process documents first in the section above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ•¸ï¸ Create interactive knowledge graph visualization\n",
    "if documents and any(doc.status == \"completed\" for doc in documents):\n",
    "    print(\"ğŸ¨ Creating interactive knowledge graph...\")\n",
    "    print(\"   ğŸ“Š This shows documents (blue) and entities (red) with their connections\")\n",
    "    print(\"   ğŸ–±ï¸  You can hover over nodes to see details\")\n",
    "    print(\"   ğŸ” Larger nodes have more connections\")\n",
    "    print()\n",
    "\n",
    "    # Create the visualization\n",
    "    graph = processor.visualize_knowledge_graph(documents, max_nodes=50)\n",
    "\n",
    "    if graph:\n",
    "        print(\"âœ… Knowledge graph visualization complete!\")\n",
    "        print(\"   ğŸ¯ Blue nodes = Documents\")\n",
    "        print(\"   ğŸ¯ Red nodes = Entities\")\n",
    "        print(\"   ğŸ¯ Lines = Connections\")\n",
    "        print(\"   ğŸ’¡ This shows how your documents are connected through shared concepts\")\n",
    "    else:\n",
    "        print(\"âŒ Could not create visualization\")\n",
    "        print(\"   ğŸ“¦ Install required libraries: pip install plotly networkx\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No completed documents to visualize\")\n",
    "    print(\"   Process documents first in the sections above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ•¸ï¸ Knowledge Graph Visualization\n\n**ğŸ¨ Interactive visualization of your knowledge graph:**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ”„ Error Recovery (Optional)\n\n**ğŸ› ï¸ If some documents failed, you can retry them here:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Check for failed documents\n",
    "failed_docs = processor.get_failed_documents(documents)\n",
    "\n",
    "if failed_docs:\n",
    "    print(f\"âŒ Found {len(failed_docs)} failed documents:\")\n",
    "    print(\"   ğŸ“‹ Failed documents and errors:\")\n",
    "\n",
    "    for i, doc in enumerate(failed_docs, 1):\n",
    "        print(f\"   {i}. ğŸ“„ {doc.name}\")\n",
    "        print(f\"      ğŸ’¥ Error: {doc.error_message}\")\n",
    "        print()\n",
    "\n",
    "    print(\"ğŸ”„ To retry failed documents:\")\n",
    "    print(\"   1. Uncomment the lines below\")\n",
    "    print(\"   2. Run this cell again\")\n",
    "    print(\"   3. Wait for processing to complete\")\n",
    "    print()\n",
    "\n",
    "    # ğŸ”„ UNCOMMENT THESE LINES TO RETRY FAILED DOCUMENTS:\n",
    "    # print(\"ğŸ”„ Retrying failed documents...\")\n",
    "    # processor.reset_for_retry(failed_docs)\n",
    "    # retry_results = await processor.process_documents(failed_docs)\n",
    "    # print(f\"âœ… Retry complete: {retry_results['success']} success, {retry_results['failed']} still failed\")\n",
    "\n",
    "else:\n",
    "    print(\"âœ… No failed documents - all processing successful!\")\n",
    "    print(\"   ğŸ‰ Your knowledge graph is complete and ready to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ¯ Next Steps: Create Your AI Research Assistant\n\n**ğŸš€ Your knowledge graph is ready! Now connect it to Claude Desktop:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Show next steps for MCP server setup\n",
    "print(\"ğŸ‰ Congratulations! Your GraphRAG MCP system is ready!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "processor.print_next_steps()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ® How to Use Your AI Research Assistant:\")\n",
    "print()\n",
    "print(\"ğŸ“ Conversational Mode (Explore & Discover):\")\n",
    "print('   â€¢ \"Ask knowledge graph: What are the main themes in my research?\"')\n",
    "print('   â€¢ \"Explore topic: machine learning applications\"')\n",
    "print('   â€¢ \"Find connections between neural networks and optimization\"')\n",
    "print('   â€¢ \"What do we know about drug discovery?\"')\n",
    "print()\n",
    "print(\"ğŸ“š Literature Review Mode (Formal Writing):\")\n",
    "print('   â€¢ \"Gather sources for topic: transformer architectures\"')\n",
    "print('   â€¢ \"Get facts with citations about attention mechanisms in APA style\"')\n",
    "print('   â€¢ \"Verify claim with sources: BERT outperforms traditional NLP models\"')\n",
    "print('   â€¢ \"Generate bibliography in IEEE style\"')\n",
    "print()\n",
    "print(\"ğŸ” Research Analysis:\")\n",
    "print('   â€¢ \"Find research gaps in my field\"')\n",
    "print('   â€¢ \"Compare methodologies for sentiment analysis\"')\n",
    "print('   â€¢ \"Analyze contributions by [author name]\"')\n",
    "print('   â€¢ \"Track evolution of [concept] over time\"')\n",
    "print()\n",
    "print(\"âœ¨ Your documents are now an intelligent AI research assistant!\")\n",
    "print(\"ğŸ¯ Happy researching! ğŸ“\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}