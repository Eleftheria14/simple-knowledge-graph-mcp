{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 📚 GraphRAG MCP Document Processing\n\nTransform your PDF documents into an intelligent AI research assistant!\n\n## 🎯 What You'll Build\nBy the end of this notebook, you'll have:\n- 🕸️ **Knowledge Graph** - Your documents transformed into connected concepts\n- 🤖 **AI Research Assistant** - Chat with your documents via Claude Desktop\n- 📊 **Analytics** - See what entities and citations were extracted\n- 🔄 **Dual-Mode Tools** - Both conversational chat and formal literature review\n- 🎨 **Interactive Visualization** - See your knowledge graph in action\n\n## 📋 Prerequisites (5 minutes setup)\n\n**Before running this notebook, make sure you have:**\n\n### 1. **Environment Setup**\n```bash\n# Activate your Python environment\nsource graphrag-env/bin/activate  # or your environment name\n\n# Install dependencies\nuv pip install -r requirements.txt\n\n# Install visualization libraries\npip install plotly networkx\n```\n\n### 2. **Ollama (AI Models)**\n```bash\n# Install Ollama\nbrew install ollama  # macOS\n# or download from https://ollama.com\n\n# Download required models\nollama pull llama3.1:8b\nollama pull nomic-embed-text\n\n# Start Ollama server (keep this running)\nollama serve\n```\n\n### 3. **Neo4j Database**\n```bash\n# Start Neo4j with Docker (keep this running)\ndocker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:latest\n\n# Verify it's running\ncurl -f http://localhost:7474/\n```\n\n### 4. **Your Documents**\n- 📄 **PDFs ready**: Put your research papers in a folder\n- 📁 **Folder path**: Know where your documents are located\n- 📊 **5-20 documents**: Good size for testing (too many = long processing time)\n\n## 🚨 Troubleshooting\nIf you see errors below, check:\n- ✅ **Ollama running**: `curl -s http://localhost:11434/api/tags`\n- ✅ **Neo4j running**: `curl -f http://localhost:7474/`\n- ✅ **Models installed**: `ollama list`\n- ✅ **Python environment**: `which python`\n- ✅ **Plotly installed**: `pip install plotly networkx`\n\n---\n\n## 🏃‍♀️ Quick Start: Run All Cells\n1. **Update settings** in the Setup cell below\n2. **Run all cells** (Cell → Run All)\n3. **Wait for processing** (progress bars will show)\n4. **View your knowledge graph** visualization\n5. **Follow next steps** for Claude Desktop integration\n\n**⏱️ Processing Time:** ~2-10 minutes per document\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🚀 Setup & Configuration\n\n**📝 Customize these settings for your project:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Run comprehensive prerequisites check\n",
    "from processing_utils import check_prerequisites\n",
    "\n",
    "# This will check all services, packages, and configurations\n",
    "result = check_prerequisites()\n",
    "\n",
    "if result[\"status\"] == \"passed\":\n",
    "    print(\"\\n🚀 All systems ready! You can proceed to the next cell.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Found {len(result['issues'])} issues that need to be fixed:\")\n",
    "    for i, issue in enumerate(result['issues'], 1):\n",
    "        print(f\"   {i}. ❌ {issue}\")\n",
    "\n",
    "    print(\"\\n🛑 Please fix these issues before continuing!\")\n",
    "    print(\"💡 Refer to the detailed output above for specific solutions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🔍 Prerequisites Check\n\n**🚨 Let's verify all required services are running properly:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing_utils import check_prerequisites, quick_setup\n",
    "\n",
    "# ⚙️ CUSTOMIZE THESE SETTINGS FOR YOUR PROJECT:\n",
    "PROJECT_NAME = \"my-research\"        # 📝 Change this to your project name\n",
    "DOCUMENTS_FOLDER = \"../../examples\"    # 📁 Change to your documents folder path\n",
    "\n",
    "# Examples of document folder paths:\n",
    "# DOCUMENTS_FOLDER = \"~/Documents/research-papers\"\n",
    "# DOCUMENTS_FOLDER = \"./my-pdfs\"\n",
    "# DOCUMENTS_FOLDER = \"/Users/yourname/Desktop/papers\"\n",
    "# DOCUMENTS_FOLDER = \"../../examples\"  # Default: examples folder in main project\n",
    "\n",
    "print(\"🔧 Checking prerequisites...\")\n",
    "check_prerequisites()\n",
    "\n",
    "print(\"\\n🏗️  Initializing GraphRAG processor...\")\n",
    "processor = quick_setup(PROJECT_NAME, DOCUMENTS_FOLDER)\n",
    "print(f\"✅ Ready to process project: {PROJECT_NAME}\")\n",
    "print(f\"📁 Looking for documents in: {DOCUMENTS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 📄 Document Discovery\n\n**🔍 Finding PDFs in your folder...**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Scan for PDF documents\n",
    "documents = processor.discover_documents(DOCUMENTS_FOLDER)\n",
    "\n",
    "if documents:\n",
    "    print(f\"\\n📊 Found {len(documents)} PDF documents:\")\n",
    "    total_size = sum(doc.size_mb for doc in documents)\n",
    "    est_time = len(documents) * 5  # Rough estimate: 5 minutes per document\n",
    "\n",
    "    print(f\"   📏 Total size: {total_size:.2f} MB\")\n",
    "    print(f\"   ⏱️  Estimated processing time: {est_time} minutes\")\n",
    "    print(\"\\n📋 Document list:\")\n",
    "\n",
    "    for i, doc in enumerate(documents, 1):\n",
    "        print(f\"   {i:2d}. 📄 {doc.name} ({doc.size_mb} MB)\")\n",
    "\n",
    "    print(f\"\\n✅ Ready to process {len(documents)} documents\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No PDF documents found!\")\n",
    "    print(f\"   📁 Checked folder: {DOCUMENTS_FOLDER}\")\n",
    "    print(\"   💡 Make sure your PDF files are in the correct folder\")\n",
    "    print(\"   🔧 Try updating DOCUMENTS_FOLDER path in the cell above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🔄 Processing Documents\n\n**🚀 This will process all documents and build the knowledge graph...**\n\n*You'll see progress bars as documents are processed. This may take several minutes.*"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 Process all documents with progress tracking\n",
    "if documents:\n",
    "    print(f\"🔄 Starting processing of {len(documents)} documents...\")\n",
    "    print(\"⏳ Please wait - this may take several minutes...\")\n",
    "\n",
    "    # Process documents (this will show progress bars)\n",
    "    results = await processor.process_documents(documents)\n",
    "\n",
    "    # Show results summary\n",
    "    print(\"\\n📊 Processing Complete!\")\n",
    "    print(f\"   ✅ Successfully processed: {results['success']}/{len(documents)} documents\")\n",
    "\n",
    "    if results['failed'] > 0:\n",
    "        print(f\"   ❌ Failed: {results['failed']} documents\")\n",
    "        print(\"   🔄 You can retry failed documents in the next section\")\n",
    "\n",
    "    print(f\"   ⏱️  Total processing time: {results['total_time']/60:.1f} minutes\")\n",
    "    print(f\"   ⚡ Average per document: {results['avg_time']:.1f} seconds\")\n",
    "\n",
    "    if results['success'] > 0:\n",
    "        print(\"\\n🎉 Success! Your knowledge graph is ready!\")\n",
    "        print(\"   🕸️  Documents are now connected in Neo4j database\")\n",
    "        print(\"   🤖 Ready to create your AI research assistant\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No documents to process\")\n",
    "    print(\"   Go back to the 'Document Discovery' section and check your folder path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 📊 Processing Results & Analytics\n\n**📈 See detailed results and performance metrics:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Show detailed processing results\n",
    "if documents:\n",
    "    print(\"📋 Detailed Processing Results:\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Results table\n",
    "    df = processor.get_results_dataframe(documents)\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "    # Key metrics\n",
    "    completed = df[df['Status'] == 'completed']\n",
    "    if not completed.empty:\n",
    "        print(\"\\n📈 Key Metrics:\")\n",
    "        print(f\"   🔢 Total entities extracted: {completed['Entities'].sum()}\")\n",
    "        print(f\"   📚 Total citations found: {completed['Citations'].sum()}\")\n",
    "        print(f\"   ⚡ Average entities per document: {completed['Entities'].mean():.1f}\")\n",
    "        print(f\"   ⏱️  Fastest document: {completed['Time (s)'].min():.1f} seconds\")\n",
    "        print(f\"   🐌 Slowest document: {completed['Time (s)'].max():.1f} seconds\")\n",
    "\n",
    "    print(\"\\n📊 Generating analytics charts...\")\n",
    "    # Analytics charts (this will show visualizations)\n",
    "    processor.show_analytics(documents)\n",
    "\n",
    "else:\n",
    "    print(\"❌ No results to display\")\n",
    "    print(\"   Process documents first in the section above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🕸️ Create interactive knowledge graph visualization\n",
    "if documents and any(doc.status == \"completed\" for doc in documents):\n",
    "    print(\"🎨 Creating interactive knowledge graph...\")\n",
    "    print(\"   📊 This shows documents (blue) and entities (red) with their connections\")\n",
    "    print(\"   🖱️  You can hover over nodes to see details\")\n",
    "    print(\"   🔍 Larger nodes have more connections\")\n",
    "    print()\n",
    "\n",
    "    # Create the visualization\n",
    "    graph = processor.visualize_knowledge_graph(documents, max_nodes=50)\n",
    "\n",
    "    if graph:\n",
    "        print(\"✅ Knowledge graph visualization complete!\")\n",
    "        print(\"   🎯 Blue nodes = Documents\")\n",
    "        print(\"   🎯 Red nodes = Entities\")\n",
    "        print(\"   🎯 Lines = Connections\")\n",
    "        print(\"   💡 This shows how your documents are connected through shared concepts\")\n",
    "    else:\n",
    "        print(\"❌ Could not create visualization\")\n",
    "        print(\"   📦 Install required libraries: pip install plotly networkx\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No completed documents to visualize\")\n",
    "    print(\"   Process documents first in the sections above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🕸️ Knowledge Graph Visualization\n\n**🎨 Interactive visualization of your knowledge graph:**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🔄 Error Recovery (Optional)\n\n**🛠️ If some documents failed, you can retry them here:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Check for failed documents\n",
    "failed_docs = processor.get_failed_documents(documents)\n",
    "\n",
    "if failed_docs:\n",
    "    print(f\"❌ Found {len(failed_docs)} failed documents:\")\n",
    "    print(\"   📋 Failed documents and errors:\")\n",
    "\n",
    "    for i, doc in enumerate(failed_docs, 1):\n",
    "        print(f\"   {i}. 📄 {doc.name}\")\n",
    "        print(f\"      💥 Error: {doc.error_message}\")\n",
    "        print()\n",
    "\n",
    "    print(\"🔄 To retry failed documents:\")\n",
    "    print(\"   1. Uncomment the lines below\")\n",
    "    print(\"   2. Run this cell again\")\n",
    "    print(\"   3. Wait for processing to complete\")\n",
    "    print()\n",
    "\n",
    "    # 🔄 UNCOMMENT THESE LINES TO RETRY FAILED DOCUMENTS:\n",
    "    # print(\"🔄 Retrying failed documents...\")\n",
    "    # processor.reset_for_retry(failed_docs)\n",
    "    # retry_results = await processor.process_documents(failed_docs)\n",
    "    # print(f\"✅ Retry complete: {retry_results['success']} success, {retry_results['failed']} still failed\")\n",
    "\n",
    "else:\n",
    "    print(\"✅ No failed documents - all processing successful!\")\n",
    "    print(\"   🎉 Your knowledge graph is complete and ready to use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 🎯 Next Steps: Create Your AI Research Assistant\n\n**🚀 Your knowledge graph is ready! Now connect it to Claude Desktop:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Show next steps for MCP server setup\n",
    "print(\"🎉 Congratulations! Your GraphRAG MCP system is ready!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "processor.print_next_steps()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎮 How to Use Your AI Research Assistant:\")\n",
    "print()\n",
    "print(\"📝 Conversational Mode (Explore & Discover):\")\n",
    "print('   • \"Ask knowledge graph: What are the main themes in my research?\"')\n",
    "print('   • \"Explore topic: machine learning applications\"')\n",
    "print('   • \"Find connections between neural networks and optimization\"')\n",
    "print('   • \"What do we know about drug discovery?\"')\n",
    "print()\n",
    "print(\"📚 Literature Review Mode (Formal Writing):\")\n",
    "print('   • \"Gather sources for topic: transformer architectures\"')\n",
    "print('   • \"Get facts with citations about attention mechanisms in APA style\"')\n",
    "print('   • \"Verify claim with sources: BERT outperforms traditional NLP models\"')\n",
    "print('   • \"Generate bibliography in IEEE style\"')\n",
    "print()\n",
    "print(\"🔍 Research Analysis:\")\n",
    "print('   • \"Find research gaps in my field\"')\n",
    "print('   • \"Compare methodologies for sentiment analysis\"')\n",
    "print('   • \"Analyze contributions by [author name]\"')\n",
    "print('   • \"Track evolution of [concept] over time\"')\n",
    "print()\n",
    "print(\"✨ Your documents are now an intelligent AI research assistant!\")\n",
    "print(\"🎯 Happy researching! 🎓\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}