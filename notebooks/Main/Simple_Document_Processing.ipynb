{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# \ud83d\udcda GraphRAG MCP Document Processing\n\nTransform your PDF documents into an intelligent AI research assistant!\n\n## \ud83c\udfaf What You'll Build\nBy the end of this notebook, you'll have:\n- \ud83d\udd78\ufe0f **Knowledge Graph** - Your documents transformed into connected concepts\n- \ud83e\udd16 **AI Research Assistant** - Chat with your documents via Claude Desktop\n- \ud83d\udcca **Analytics** - See what entities and citations were extracted\n- \ud83d\udd04 **Dual-Mode Tools** - Both conversational chat and formal literature review\n- \ud83c\udfa8 **Interactive Visualization** - See your knowledge graph in action\n\n## \ud83d\udccb Prerequisites (5 minutes setup)\n\n**Before running this notebook, make sure you have:**\n\n### 1. **Environment Setup**\n```bash\n# Activate your Python environment\nsource graphrag-env/bin/activate  # or your environment name\n\n# Install dependencies\nuv pip install -r requirements.txt\n\n# Install visualization libraries\npip install plotly networkx\n```\n\n### 2. **Ollama (AI Models)**\n```bash\n# Install Ollama\nbrew install ollama  # macOS\n# or download from https://ollama.com\n\n# Download required models\nollama pull llama3.1:8b\nollama pull nomic-embed-text\n\n# Start Ollama server (keep this running)\nollama serve\n```\n\n### 3. **Neo4j Database**\n```bash\n# Start Neo4j with Docker (keep this running)\ndocker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:latest\n\n# Verify it's running\ncurl -f http://localhost:7474/\n```\n\n### 4. **Your Documents**\n- \ud83d\udcc4 **PDFs ready**: Put your research papers in a folder\n- \ud83d\udcc1 **Folder path**: Know where your documents are located\n- \ud83d\udcca **5-20 documents**: Good size for testing (too many = long processing time)\n\n## \ud83d\udea8 Troubleshooting\nIf you see errors below, check:\n- \u2705 **Ollama running**: `curl -s http://localhost:11434/api/tags`\n- \u2705 **Neo4j running**: `curl -f http://localhost:7474/`\n- \u2705 **Models installed**: `ollama list`\n- \u2705 **Python environment**: `which python`\n- \u2705 **Plotly installed**: `pip install plotly networkx`\n\n---\n\n## \ud83c\udfc3\u200d\u2640\ufe0f Quick Start: Run All Cells\n1. **Update settings** in the Setup cell below\n2. **Run all cells** (Cell \u2192 Run All)\n3. **Wait for processing** (progress bars will show)\n4. **View your knowledge graph** visualization\n5. **Follow next steps** for Claude Desktop integration\n\n**\u23f1\ufe0f Processing Time:** ~2-10 minutes per document\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\ude80 Setup & Configuration\n\n**\ud83d\udcdd Customize these settings for your project:**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# \ud83d\udd0d Run comprehensive prerequisites check\ntry:\n    from processing_utils import check_prerequisites\n    print(\"\u2705 GraphRAG MCP components imported successfully\")\n    \n    # This will check all services, packages, and configurations\n    result = check_prerequisites()\n    \n    # Convert ValidationResult to dict for compatibility\n    if hasattr(result, 'to_dict'):\n        result_dict = result.to_dict()\n    else:\n        result_dict = {\"status\": result.status, \"issues\": result.issues}\n\n    if result.status == \"passed\":\n        print(\"\\n\ud83d\ude80 All systems ready! You can proceed to the next cell.\")\n    else:\n        print(f\"\\n\u26a0\ufe0f  Found {len(result.issues)} issues that need to be fixed:\")\n        for i, issue in enumerate(result.issues, 1):\n            print(f\"   {i}. \u274c {issue}\")\n\n        print(\"\\n\ud83d\uded1 Please fix these issues before continuing!\")\n        print(\"\ud83d\udca1 Refer to the detailed output above for specific solutions.\")\n        \nexcept ImportError as e:\n    print(f\"\u274c Import error: {e}\")\n    print(\"\ud83d\udd27 Make sure you're using the 'GraphRAG MCP' kernel\")\n    print(\"   Go to Kernel \u2192 Change Kernel \u2192 GraphRAG MCP\")\n    print(\"   Or restart this notebook with the correct kernel\")\nexcept Exception as e:\n    print(f\"\u274c Error: {e}\")\n    print(\"\ud83d\udd27 Check that all services are running properly\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udd0d Prerequisites Check\n\n**\ud83d\udea8 Let's verify all required services are running properly:**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from processing_utils import check_prerequisites, quick_setup\n\n# \u2699\ufe0f CUSTOMIZE THESE SETTINGS FOR YOUR PROJECT:\nPROJECT_NAME = \"my-research\"        # \ud83d\udcdd Change this to your project name\nDOCUMENTS_FOLDER = \"../../examples\"    # \ud83d\udcc1 Change to your documents folder path\n\n# Examples of document folder paths:\n# DOCUMENTS_FOLDER = \"~/Documents/research-papers\"\n# DOCUMENTS_FOLDER = \"./my-pdfs\"\n# DOCUMENTS_FOLDER = \"/Users/yourname/Desktop/papers\"\n# DOCUMENTS_FOLDER = \"../../examples\"  # Default: examples folder in main project\n\nprint(\"\ud83d\udd27 Checking prerequisites...\")\nresult = check_prerequisites()\n\nif result.status == \"passed\":\n    print(\"\\n\ud83d\ude80 All systems ready!\")\n    print(\"\\n\ud83c\udfd7\ufe0f  Initializing GraphRAG processor...\")\n    processor = quick_setup(PROJECT_NAME, DOCUMENTS_FOLDER)\n    print(f\"\u2705 Ready to process project: {PROJECT_NAME}\")\n    print(f\"\ud83d\udcc1 Looking for documents in: {DOCUMENTS_FOLDER}\")\nelse:\n    print(f\"\\n\u26a0\ufe0f  Found {len(result.issues)} issues that need to be fixed:\")\n    for i, issue in enumerate(result.issues, 1):\n        print(f\"   {i}. \u274c {issue}\")\n    print(\"\\n\ud83d\uded1 Please fix these issues before continuing!\")\n    print(\"\ud83d\udca1 Make sure all services are running with: ./start_tutorial.sh\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcc4 Document Discovery\n\n**\ud83d\udd0d Finding PDFs in your folder...**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# \ud83d\udd0d Scan for PDF documents\ntry:\n    documents = processor.discover_documents(DOCUMENTS_FOLDER)\nexcept NameError:\n    print(\"\u274c Error: processor not defined!\")\n    print(\"   \ud83d\udca1 Go back and run the 'Setup & Configuration' cell first\")\n    print(\"   \ud83d\udd27 Make sure all prerequisites are met\")\n    documents = None\n\nif documents:\n    print(f\"\\n\ud83d\udcca Found {len(documents)} PDF documents:\")\n    total_size = sum(doc.size_mb for doc in documents)\n    est_time = len(documents) * 5  # Rough estimate: 5 minutes per document\n\n    print(f\"   \ud83d\udccf Total size: {total_size:.2f} MB\")\n    print(f\"   \u23f1\ufe0f  Estimated processing time: {est_time} minutes\")\n    print(\"\\n\ud83d\udccb Document list:\")\n\n    for i, doc in enumerate(documents, 1):\n        print(f\"   {i:2d}. \ud83d\udcc4 {doc.name} ({doc.size_mb:.1f} MB)\")\n\n    print(f\"\\n\u2705 Ready to process {len(documents)} documents\")\n\nelif documents is not None:  # Empty list (no documents found)\n    print(\"\u274c No PDF documents found!\")\n    print(f\"   \ud83d\udcc1 Checked folder: {DOCUMENTS_FOLDER}\")\n    print(\"   \ud83d\udca1 Make sure your PDF files are in the correct folder\")\n    print(\"   \ud83d\udd27 Try updating DOCUMENTS_FOLDER path in the cell above\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udd04 Processing Documents\n\n**\ud83d\ude80 This will process all documents and build the knowledge graph...**\n\n*You'll see progress bars as documents are processed. This may take several minutes.*"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\ude80 Process all documents with progress tracking\n",
        "if documents:\n",
        "    print(f\"\ud83d\udd04 Starting processing of {len(documents)} documents...\")\n",
        "    print(\"\u23f3 Please wait - this may take several minutes...\")\n",
        "\n",
        "    # Process documents (this will show progress bars)\n",
        "    results = await processor.process_documents(documents)\n",
        "\n",
        "    # Show results summary\n",
        "    print(\"\\n\ud83d\udcca Processing Complete!\")\n",
        "    print(f\"   \u2705 Successfully processed: {results['success']}/{len(documents)} documents\")\n",
        "\n",
        "    if results['failed'] > 0:\n",
        "        print(f\"   \u274c Failed: {results['failed']} documents\")\n",
        "        print(\"   \ud83d\udd04 You can retry failed documents in the next section\")\n",
        "\n",
        "    print(f\"   \u23f1\ufe0f  Total processing time: {results['total_time']/60:.1f} minutes\")\n",
        "    print(f\"   \u26a1 Average per document: {results['avg_time']:.1f} seconds\")\n",
        "\n",
        "    if results['success'] > 0:\n",
        "        print(\"\\n\ud83c\udf89 Success! Your knowledge graph is ready!\")\n",
        "        print(\"   \ud83d\udd78\ufe0f  Documents are now connected in Neo4j database\")\n",
        "        print(\"   \ud83e\udd16 Ready to create your AI research assistant\")\n",
        "\n",
        "else:\n",
        "    print(\"\u274c No documents to process\")\n",
        "    print(\"   Go back to the 'Document Discovery' section and check your folder path\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udcca Processing Results & Analytics\n\n**\ud83d\udcc8 See detailed results and performance metrics:**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udcca Show detailed processing results\n",
        "if documents:\n",
        "    print(\"\ud83d\udccb Detailed Processing Results:\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Results table\n",
        "    df = processor.get_results_dataframe(documents)\n",
        "    print(df.to_string(index=False))\n",
        "\n",
        "    # Key metrics\n",
        "    completed = df[df['Status'] == 'completed']\n",
        "    if not completed.empty:\n",
        "        print(\"\\n\ud83d\udcc8 Key Metrics:\")\n",
        "        print(f\"   \ud83d\udd22 Total entities extracted: {completed['Entities'].sum()}\")\n",
        "        print(f\"   \ud83d\udcda Total citations found: {completed['Citations'].sum()}\")\n",
        "        print(f\"   \u26a1 Average entities per document: {completed['Entities'].mean():.1f}\")\n",
        "        print(f\"   \u23f1\ufe0f  Fastest document: {completed['Time (s)'].min():.1f} seconds\")\n",
        "        print(f\"   \ud83d\udc0c Slowest document: {completed['Time (s)'].max():.1f} seconds\")\n",
        "\n",
        "    print(\"\\n\ud83d\udcca Generating analytics charts...\")\n",
        "    # Analytics charts (this will show visualizations)\n",
        "    processor.show_analytics(documents)\n",
        "\n",
        "else:\n",
        "    print(\"\u274c No results to display\")\n",
        "    print(\"   Process documents first in the section above\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd78\ufe0f Create interactive knowledge graph visualization\n",
        "if documents and any(doc.status == \"completed\" for doc in documents):\n",
        "    print(\"\ud83c\udfa8 Creating interactive knowledge graph...\")\n",
        "    print(\"   \ud83d\udcca This shows documents (blue) and entities (red) with their connections\")\n",
        "    print(\"   \ud83d\uddb1\ufe0f  You can hover over nodes to see details\")\n",
        "    print(\"   \ud83d\udd0d Larger nodes have more connections\")\n",
        "    print()\n",
        "\n",
        "    # Create the visualization\n",
        "    graph = processor.visualize_knowledge_graph(documents, max_nodes=50)\n",
        "\n",
        "    if graph:\n",
        "        print(\"\u2705 Knowledge graph visualization complete!\")\n",
        "        print(\"   \ud83c\udfaf Blue nodes = Documents\")\n",
        "        print(\"   \ud83c\udfaf Red nodes = Entities\")\n",
        "        print(\"   \ud83c\udfaf Lines = Connections\")\n",
        "        print(\"   \ud83d\udca1 This shows how your documents are connected through shared concepts\")\n",
        "    else:\n",
        "        print(\"\u274c Could not create visualization\")\n",
        "        print(\"   \ud83d\udce6 Install required libraries: pip install plotly networkx\")\n",
        "\n",
        "else:\n",
        "    print(\"\u274c No completed documents to visualize\")\n",
        "    print(\"   Process documents first in the sections above\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udd78\ufe0f Knowledge Graph Visualization\n\n**\ud83c\udfa8 Interactive visualization of your knowledge graph:**"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83d\udd04 Error Recovery (Optional)\n\n**\ud83d\udee0\ufe0f If some documents failed, you can retry them here:**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd0d Check for failed documents\n",
        "failed_docs = processor.get_failed_documents(documents)\n",
        "\n",
        "if failed_docs:\n",
        "    print(f\"\u274c Found {len(failed_docs)} failed documents:\")\n",
        "    print(\"   \ud83d\udccb Failed documents and errors:\")\n",
        "\n",
        "    for i, doc in enumerate(failed_docs, 1):\n",
        "        print(f\"   {i}. \ud83d\udcc4 {doc.name}\")\n",
        "        print(f\"      \ud83d\udca5 Error: {doc.error_message}\")\n",
        "        print()\n",
        "\n",
        "    print(\"\ud83d\udd04 To retry failed documents:\")\n",
        "    print(\"   1. Uncomment the lines below\")\n",
        "    print(\"   2. Run this cell again\")\n",
        "    print(\"   3. Wait for processing to complete\")\n",
        "    print()\n",
        "\n",
        "    # \ud83d\udd04 UNCOMMENT THESE LINES TO RETRY FAILED DOCUMENTS:\n",
        "    # print(\"\ud83d\udd04 Retrying failed documents...\")\n",
        "    # processor.reset_for_retry(failed_docs)\n",
        "    # retry_results = await processor.process_documents(failed_docs)\n",
        "    # print(f\"\u2705 Retry complete: {retry_results['success']} success, {retry_results['failed']} still failed\")\n",
        "\n",
        "else:\n",
        "    print(\"\u2705 No failed documents - all processing successful!\")\n",
        "    print(\"   \ud83c\udf89 Your knowledge graph is complete and ready to use\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## \ud83c\udfaf Next Steps: Create Your AI Research Assistant\n\n**\ud83d\ude80 Your knowledge graph is ready! Now connect it to Claude Desktop:**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83c\udfaf Show next steps for MCP server setup\n",
        "print(\"\ud83c\udf89 Congratulations! Your GraphRAG MCP system is ready!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "processor.print_next_steps()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"\ud83c\udfae How to Use Your AI Research Assistant:\")\n",
        "print()\n",
        "print(\"\ud83d\udcdd Conversational Mode (Explore & Discover):\")\n",
        "print('   \u2022 \"Ask knowledge graph: What are the main themes in my research?\"')\n",
        "print('   \u2022 \"Explore topic: machine learning applications\"')\n",
        "print('   \u2022 \"Find connections between neural networks and optimization\"')\n",
        "print('   \u2022 \"What do we know about drug discovery?\"')\n",
        "print()\n",
        "print(\"\ud83d\udcda Literature Review Mode (Formal Writing):\")\n",
        "print('   \u2022 \"Gather sources for topic: transformer architectures\"')\n",
        "print('   \u2022 \"Get facts with citations about attention mechanisms in APA style\"')\n",
        "print('   \u2022 \"Verify claim with sources: BERT outperforms traditional NLP models\"')\n",
        "print('   \u2022 \"Generate bibliography in IEEE style\"')\n",
        "print()\n",
        "print(\"\ud83d\udd0d Research Analysis:\")\n",
        "print('   \u2022 \"Find research gaps in my field\"')\n",
        "print('   \u2022 \"Compare methodologies for sentiment analysis\"')\n",
        "print('   \u2022 \"Analyze contributions by [author name]\"')\n",
        "print('   \u2022 \"Track evolution of [concept] over time\"')\n",
        "print()\n",
        "print(\"\u2728 Your documents are now an intelligent AI research assistant!\")\n",
        "print(\"\ud83c\udfaf Happy researching! \ud83c\udf93\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "GraphRAG MCP",
      "language": "python",
      "name": "graphrag-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}