{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸ“š GraphRAG MCP Document Processing\n\nTransform your research papers into an intelligent knowledge graph for AI-powered literature review.\n\n## ğŸ¯ What You'll Build\n\nBy the end of this notebook, you'll have:\n- ğŸ•¸ï¸ **Knowledge Graph** - Your documents connected through entities and relationships\n- ğŸ“Š **Interactive Visualization** - See how your papers connect to each other\n- ğŸ’¾ **Persistent Storage** - Knowledge graph stored in Neo4j for future use\n- ğŸ¨ **Beautiful Visualization** - Interactive graph showing document relationships\n\n## ğŸ“‹ Prerequisites\n\n**Before starting:**\n1. **Services running**: Ollama and Neo4j\n2. **Documents ready**: PDF papers in a folder\n3. **Environment**: GraphRAG MCP toolkit installed\n\n---\n\n## ğŸš€ Let's Get Started!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. ğŸ” System Check\n\n**First, let's verify all required services are running:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ” SYSTEM VALIDATION - Run this first!\nimport subprocess\nimport os\nimport time\nfrom pathlib import Path\nfrom IPython.display import display, HTML\nfrom tqdm import tqdm\nimport json\n\ndef check_service(command, service_name, timeout=10):\n    \"\"\"Check if a service is running\"\"\"\n    try:\n        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=timeout)\n        return result.returncode == 0, result.stdout, result.stderr\n    except subprocess.TimeoutExpired:\n        return False, \"\", \"Timeout\"\n    except Exception as e:\n        return False, \"\", str(e)\n\nprint(\"ğŸ” Checking system prerequisites...\")\nprint(\"=\" * 50)\n\n# Check Neo4j\nprint(\"ğŸ”§ Checking Neo4j...\")\nneo4j_ok, _, _ = check_service(\"curl -f -s http://localhost:7474/\", \"Neo4j\")\nif neo4j_ok:\n    print(\"âœ… Neo4j is running\")\nelse:\n    print(\"âŒ Neo4j not accessible\")\n    print(\"   ğŸ’¡ Start with: docker run -d --name neo4j -p 7474:7474 -p 7687:7687 -e NEO4J_AUTH=neo4j/password neo4j:latest\")\n\n# Check Ollama\nprint(\"\\nğŸ”§ Checking Ollama...\")\nollama_ok, _, _ = check_service(\"curl -s http://localhost:11434/api/tags\", \"Ollama\")\nif ollama_ok:\n    print(\"âœ… Ollama is running\")\nelse:\n    print(\"âŒ Ollama not accessible\")\n    print(\"   ğŸ’¡ Start with: ollama serve\")\n\n# Check CLI availability\nprint(\"\\nğŸ”§ Checking GraphRAG MCP CLI...\")\ncli_ok, _, _ = check_service(\"graphrag-mcp --help\", \"CLI\")\nif cli_ok:\n    print(\"âœ… GraphRAG MCP CLI is available\")\nelse:\n    print(\"âŒ GraphRAG MCP CLI not found\")\n    print(\"   ğŸ’¡ Install with: pip install graphrag-mcp-toolkit\")\n\n# Overall status\nprint(\"\\n\" + \"=\" * 50)\nif neo4j_ok and ollama_ok and cli_ok:\n    print(\"ğŸš€ All systems ready! You can proceed to configuration.\")\n    system_ready = True\nelse:\n    print(\"âš ï¸  Please fix the issues above before continuing.\")\n    system_ready = False"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. ğŸ”§ Configuration\n\n**Set up your project details:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ”§ PROJECT SETTINGS - Customize these for your research\nPROJECT_NAME = \"literature-assistant\"    # Your project name\nDOCUMENTS_FOLDER = \"../../examples\"       # Path to your PDF papers\nTEMPLATE = \"academic\"                     # Template for academic research\n\n# Display settings\nprint(f\"ğŸ“‹ Project Configuration:\")\nprint(f\"   ğŸ¯ Project Name: {PROJECT_NAME}\")\nprint(f\"   ğŸ“ Documents Folder: {DOCUMENTS_FOLDER}\")\nprint(f\"   ğŸ“ Template: {TEMPLATE}\")\nprint(f\"   ğŸ“ Working Directory: {os.getcwd()}\")\n\n# Check if system validation passed\nif 'system_ready' in globals() and system_ready:\n    print(\"\\nâœ… Configuration complete - system validated\")\nelse:\n    print(\"\\nâš ï¸  Run the system check cell first to validate prerequisites\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. ğŸ“„ Document Discovery\n\n**Find your research papers:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“„ DOCUMENT DISCOVERY\n",
    "print(\"ğŸ” Scanning for PDF documents...\")\n",
    "\n",
    "# Find PDF files\n",
    "doc_path = Path(DOCUMENTS_FOLDER)\n",
    "if not doc_path.exists():\n",
    "    print(f\"âŒ Folder not found: {DOCUMENTS_FOLDER}\")\n",
    "    print(\"   ğŸ’¡ Update DOCUMENTS_FOLDER path in the configuration cell\")\n",
    "else:\n",
    "    pdf_files = list(doc_path.glob(\"*.pdf\"))\n",
    "    \n",
    "    if pdf_files:\n",
    "        total_size = sum(f.stat().st_size for f in pdf_files) / (1024 * 1024)  # MB\n",
    "        \n",
    "        print(f\"ğŸ“Š Found {len(pdf_files)} PDF documents ({total_size:.1f} MB total):\")\n",
    "        print()\n",
    "        \n",
    "        for i, pdf_file in enumerate(pdf_files, 1):\n",
    "            size_mb = pdf_file.stat().st_size / (1024 * 1024)\n",
    "            print(f\"   {i:2d}. ğŸ“„ {pdf_file.name} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        # Processing time estimate\n",
    "        est_minutes = len(pdf_files) * 3  # ~3 minutes per document\n",
    "        print(f\"\\nâ±ï¸  Estimated processing time: {est_minutes} minutes\")\n",
    "        print(\"âœ… Document discovery complete\")\n",
    "        \n",
    "        # Store for later use\n",
    "        documents_found = True\n",
    "        document_count = len(pdf_files)\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ No PDF files found in {DOCUMENTS_FOLDER}\")\n",
    "        print(\"   ğŸ’¡ Add PDF files to the folder or update the path\")\n",
    "        documents_found = False\n",
    "        document_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. ğŸ—ï¸ Create Project\n\n**Set up your GraphRAG project:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ—ï¸ PROJECT CREATION - with real-time feedback\nprint(\"ğŸ”¨ Creating GraphRAG project...\")\n\n# Check if project already exists\nimport os\nproject_dir = os.path.expanduser(f\"~/.graphrag-mcp/projects/{PROJECT_NAME}\")\nif os.path.exists(project_dir):\n    print(f\"ğŸ“ Project '{PROJECT_NAME}' already exists, using --force to overwrite\")\n    force_flag = \"--force\"\nelse:\n    print(f\"ğŸ“ Creating new project '{PROJECT_NAME}'\")\n    force_flag = \"\"\n\nprint(\"ğŸ“Š This may take a moment to:\")\nprint(\"   - Create project directory\")\nprint(\"   - Set up template configuration\")\nprint(\"   - Initialize database connections\")\nprint(\"   - Validate prerequisites\")\nprint()\n\n# Create project using CLI with real-time output\ncreate_cmd = f\"graphrag-mcp create {PROJECT_NAME} --template {TEMPLATE} {force_flag}\".strip()\nprint(f\"ğŸ“ Command: {create_cmd}\")\nprint(\"â³ Running...\")\n\n# Run with real-time output\nimport subprocess\nprocess = subprocess.Popen(create_cmd, shell=True, stdout=subprocess.PIPE, \n                          stderr=subprocess.STDOUT, text=True, bufsize=1)\n\n# Show output in real-time\noutput_lines = []\nwhile True:\n    line = process.stdout.readline()\n    if not line and process.poll() is not None:\n        break\n    if line:\n        print(f\"   {line.strip()}\")\n        output_lines.append(line.strip())\n\n# Get final result\nreturn_code = process.wait()\n\nif return_code == 0:\n    print(\"\\nâœ… Project created successfully!\")\n    print(f\"ğŸ“ Project location: ~/.graphrag-mcp/projects/{PROJECT_NAME}\")\n    print(f\"ğŸ“ Using template: {TEMPLATE}\")\n    project_created = True\n    \nelse:\n    print(\"\\nâŒ Project creation failed\")\n    print(\"Check the output above for details\")\n    project_created = False"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. ğŸ“¥ Add Documents\n\n**Add your papers to the project:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¥ ADD DOCUMENTS\n",
    "if documents_found and project_created:\n",
    "    print(\"ğŸ“¥ Adding documents to project...\")\n",
    "    \n",
    "    # Add documents using CLI\n",
    "    add_cmd = f\"graphrag-mcp add-documents {PROJECT_NAME} {DOCUMENTS_FOLDER} --recursive\"\n",
    "    print(f\"ğŸ“ Command: {add_cmd}\")\n",
    "    \n",
    "    result = subprocess.run(add_cmd, shell=True, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"âœ… Successfully added {document_count} documents to project\")\n",
    "        \n",
    "        if result.stdout:\n",
    "            print(f\"\\nğŸ“‹ Output:\")\n",
    "            print(result.stdout)\n",
    "            \n",
    "        documents_added = True\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Failed to add documents\")\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "        documents_added = False\n",
    "        \n",
    "else:\n",
    "    print(\"âš ï¸  Skipping document addition - prerequisites not met\")\n",
    "    documents_added = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. ğŸ¦™ Process Documents\n\n**Transform papers into knowledge graph (this takes several minutes):**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ¦™ DOCUMENT PROCESSING - Setup\nif documents_added:\n    print(\"ğŸš€ Starting document processing...\")\n    print(\"ğŸ“Š This will:\")\n    print(\"   1. ğŸ“„ Extract text from PDFs\")\n    print(\"   2. ğŸ“ Create text chunks\")\n    print(\"   3. ğŸ¦™ Extract entities with LLM\")\n    print(\"   4. ğŸ“š Parse citations\")\n    print(\"   5. ğŸ”— Build relationships\")\n    print(\"   6. ğŸ’¾ Store in Neo4j + ChromaDB\")\n    print()\n    \n    # Set up the command\n    process_cmd = f\"graphrag-mcp process {PROJECT_NAME}\"\n    print(f\"ğŸ“ Command: {process_cmd}\")\n    print(\"â³ This may take several minutes...\")\n    print(\"ğŸ’¡ Run the next cell to start processing\")\n    \n    # Make command available for next cell\n    processing_ready = True\n    \nelse:\n    print(\"âš ï¸  Cannot start processing - documents not added\")\n    print(\"   Go back and run the document addition cell first\")\n    processing_ready = False"
  },
  {
   "cell_type": "code",
   "source": "# ğŸ”„ RUN PROCESSING - Execute the document processing\nif 'processing_ready' in globals() and processing_ready:\n    print(\"ğŸš€ Starting document processing...\")\n    print(\"ğŸ“„ Processing PDF into knowledge graph...\")\n    print(\"â³ This will take approximately 5 minutes...\")\n    print()\n    \n    import subprocess\n    import logging\n    import sys\n    import re\n    \n    # Set cleaner logging\n    logging.getLogger('graphrag_mcp').setLevel(logging.WARNING)\n    logging.getLogger('httpx').setLevel(logging.WARNING)\n    logging.getLogger('neo4j').setLevel(logging.WARNING)\n    \n    print(f\"ğŸ”§ Running: {process_cmd}\")\n    print(\"ğŸ“Š Progress milestones:\")\n    print(\"-\" * 40)\n    \n    # Run processing with smart filtering\n    try:\n        process = subprocess.Popen(\n            process_cmd, \n            shell=True, \n            stdout=subprocess.PIPE, \n            stderr=subprocess.STDOUT,\n            text=True,\n            bufsize=1,\n            universal_newlines=True\n        )\n        \n        last_status = \"\"\n        \n        while True:\n            output = process.stdout.readline()\n            if output == '' and process.poll() is not None:\n                break\n            if output:\n                line = output.strip()\n                \n                # Skip spinner characters and repetitive lines\n                if any(char in line for char in ['â ', 'â ‹', 'â ™', 'â ¹', 'â ¸', 'â ¼', 'â ´', 'â ¦', 'â §', 'â ‡']):\n                    continue\n                    \n                # Skip HTTP request logs\n                if 'HTTP Request:' in line or 'INFO:httpx:' in line:\n                    continue\n                \n                # Skip empty lines\n                if not line:\n                    continue\n                \n                # Only show meaningful status changes\n                clean_line = re.sub(r'^[â â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡]\\s*', '', line)\n                if clean_line != last_status and len(clean_line) > 5:\n                    print(f\"  {clean_line}\")\n                    last_status = clean_line\n                    sys.stdout.flush()\n        \n        # Get final return code\n        return_code = process.poll()\n        \n        print(\"-\" * 40)\n        print()\n        \n        if return_code == 0:\n            print(\"âœ… Processing completed successfully!\")\n            print(\"ğŸ“Š Your documents are now in the knowledge graph\")\n            processing_complete = True\n        else:\n            print(f\"âŒ Processing failed (code: {return_code})\")\n            print(\"ğŸ’¡ Check the output above for issues\")\n            processing_complete = False\n            \n    except KeyboardInterrupt:\n        print(\"\\nâ¸ï¸ Processing interrupted by user\")\n        processing_complete = False\n        \n    except Exception as e:\n        print(f\"\\nâŒ Exception: {str(e)}\")\n        processing_complete = False\n        \nelse:\n    print(\"âš ï¸  Run the previous cell first to set up processing\")\n    processing_complete = False",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ğŸ“Š CHECK PROCESSING RESULTS\nif 'processing_complete' in globals() and processing_complete:\n    print(\"ğŸ‰ Processing Results:\")\n    print(\"=\" * 40)\n    \n    # Check project status\n    import subprocess\n    result = subprocess.run(f\"graphrag-mcp status {PROJECT_NAME}\", shell=True, capture_output=True, text=True)\n    \n    if result.returncode == 0:\n        print(\"âœ… Project status:\")\n        print(result.stdout)\n    else:\n        print(\"âš ï¸  Status check failed\")\n        print(result.stderr)\n    \n    print(\"\\nğŸ“Š Your knowledge graph is ready:\")\n    print(\"   - Entities extracted and connected\")\n    print(\"   - Citations tracked and indexed\")\n    print(\"   - Relationships mapped across papers\")\n    print(\"   - Data stored in Neo4j + ChromaDB\")\n    print(\"\\nğŸ’¡ Ready for visualization in the next cell!\")\n    \nelif 'processing_complete' in globals() and not processing_complete:\n    print(\"âŒ Processing was not successful\")\n    print(\"   Check the previous cell for error details\")\n    print(\"   You may need to fix issues and re-run processing\")\n    \nelse:\n    print(\"âš ï¸  Processing not yet attempted\")\n    print(\"   Run the processing cells above first\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. ğŸ•¸ï¸ Visualize Knowledge Graph\n\n**See your research papers as an interactive knowledge graph:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ•¸ï¸ KNOWLEDGE GRAPH VISUALIZATION - REAL DATA\nif processing_complete:\n    print(\"ğŸ¨ Creating knowledge graph visualization...\")\n    \n    # Try CLI visualization first\n    viz_cmd = f\"graphrag-mcp visualize {PROJECT_NAME} --max-nodes 50 --interactive\"\n    print(f\"ğŸ“ Command: {viz_cmd}\")\n    \n    result = subprocess.run(viz_cmd, shell=True, capture_output=True, text=True)\n    \n    if result.returncode == 0:\n        print(\"âœ… Knowledge graph visualization created!\")\n        print(\"ğŸ“Š Your visualization shows:\")\n        print(\"   - ğŸ”µ Documents (blue nodes)\")\n        print(\"   - ğŸ”´ Entities (red nodes)\")\n        print(\"   - ğŸ”— Relationships (connecting lines)\")\n        print(\"   - ğŸ“ Node sizes indicate importance\")\n        print(\"   - ğŸ¯ Clusters show related concepts\")\n        \n        if result.stdout:\n            print(f\"\\nğŸ“‹ Visualization details:\")\n            print(result.stdout)\n            \n    else:\n        print(\"âš ï¸  CLI visualization failed, creating Python visualization with REAL data...\")\n        print(f\"Debug: {result.stderr}\")\n    \n    # Create visualization using REAL processed data\n    try:\n        import matplotlib.pyplot as plt\n        import networkx as nx\n        import sys\n        from pathlib import Path\n        \n        # Add project root to path to import managers\n        project_root = Path.cwd().parent.parent\n        sys.path.append(str(project_root))\n        \n        print(\"\\nğŸ Creating Python visualization with REAL knowledge graph data...\")\n        \n        # Import the managers to query actual data\n        from graphrag_mcp.core.chromadb_citation_manager import ChromaDBCitationManager\n        from graphrag_mcp.core.neo4j_entity_manager import Neo4jEntityManager\n        from graphrag_mcp.core.knowledge_graph_integrator import KnowledgeGraphIntegrator\n        \n        # Initialize the knowledge graph integrator\n        print(\"ğŸ”— Connecting to knowledge graph...\")\n        kg_integrator = KnowledgeGraphIntegrator(\n            neo4j_uri=\"bolt://localhost:7687\",\n            neo4j_auth=(\"neo4j\", \"password\"),\n            chromadb_collection=\"graphrag_citations\",\n            chromadb_persist_dir=\"chroma_graph_db\"\n        )\n        \n        # Get real data from the knowledge graph\n        print(\"ğŸ“Š Querying real entities and citations...\")\n        \n        # Get statistics first\n        stats = kg_integrator.get_knowledge_graph_stats()\n        print(f\"ğŸ“ˆ Knowledge Graph Stats:\")\n        print(f\"   - Entities: {stats.get('neo4j_entities', 0)}\")\n        print(f\"   - Citations: {stats.get('chromadb_citations', 0)}\")\n        print(f\"   - Relationships: {stats.get('neo4j_relationships', 0)}\")\n        \n        # Get all entities from Neo4j\n        neo4j_stats = kg_integrator.neo4j_manager.get_statistics()\n        print(f\"ğŸ” Querying {neo4j_stats.get('total_entities', 0)} entities...\")\n        \n        # Query entities from Neo4j\n        with kg_integrator.neo4j_manager.driver.session() as session:\n            # Get entities\n            entity_result = session.run(\"\"\"\n                MATCH (e:Entity) \n                RETURN e.entity_id as id, e.name as name, e.type as type, e.description as description\n                LIMIT 20\n            \"\"\")\n            entities = [dict(record) for record in entity_result]\n            \n            # Get relationships\n            rel_result = session.run(\"\"\"\n                MATCH (e1:Entity)-[r:RELATES_TO]->(e2:Entity)\n                RETURN e1.entity_id as source, e2.entity_id as target, r.relationship_type as type\n                LIMIT 30\n            \"\"\")\n            relationships = [dict(record) for record in rel_result]\n        \n        # Get citations from ChromaDB\n        citations = kg_integrator.chromadb_manager._get_all_citations()\n        \n        print(f\"ğŸ“š Found {len(entities)} entities, {len(relationships)} relationships, {len(citations)} citations\")\n        \n        # Create network graph with REAL data\n        G = nx.Graph()\n        \n        # Add document nodes (from processing metadata)\n        with open(f'/Users/aimiegarces/.graphrag-mcp/projects/{PROJECT_NAME}/processing_metadata.json', 'r') as f:\n            metadata = json.load(f)\n            \n        doc_nodes = []\n        for doc in metadata['documents_processed']:\n            doc_id = doc['document_id']\n            doc_title = doc['title']\n            G.add_node(doc_id, node_type='document', label=doc_title, size=1000)\n            doc_nodes.append(doc_id)\n        \n        # Add entity nodes from REAL Neo4j data\n        entity_nodes = []\n        for entity in entities:\n            entity_id = entity['id']\n            entity_name = entity['name'] or entity_id\n            G.add_node(entity_id, node_type='entity', label=entity_name, size=500)\n            entity_nodes.append(entity_id)\n        \n        # Add citation nodes from REAL ChromaDB data\n        citation_nodes = []\n        for citation in citations[:5]:  # Limit to top 5 citations\n            cite_id = f\"cite_{citation.citation_key}\"\n            cite_label = citation.title[:30] + \"...\" if len(citation.title) > 30 else citation.title\n            G.add_node(cite_id, node_type='citation', label=cite_label, size=300)\n            citation_nodes.append(cite_id)\n            \n            # Connect citations to their linked entities\n            for entity_id in citation.linked_entities:\n                if entity_id in entity_nodes:\n                    G.add_edge(cite_id, entity_id)\n        \n        # Add relationships from REAL Neo4j data\n        for rel in relationships:\n            source = rel['source']\n            target = rel['target']\n            if source in entity_nodes and target in entity_nodes:\n                G.add_edge(source, target, relationship=rel['type'])\n        \n        # Connect documents to entities (simplified - in real implementation would be more precise)\n        for doc_id in doc_nodes:\n            for entity_id in entity_nodes[:5]:  # Connect to top entities\n                G.add_edge(doc_id, entity_id)\n        \n        # Create visualization\n        plt.figure(figsize=(15, 10))\n        \n        # Calculate layout\n        pos = nx.spring_layout(G, k=3, iterations=50, seed=42)\n        \n        # Draw different node types with different colors and sizes\n        if doc_nodes:\n            nx.draw_networkx_nodes(G, pos, nodelist=doc_nodes, node_color='lightblue', \n                                  node_size=3000, alpha=0.8, label='Documents')\n        \n        if entity_nodes:\n            nx.draw_networkx_nodes(G, pos, nodelist=entity_nodes, node_color='lightcoral', \n                                  node_size=2000, alpha=0.8, label='Entities')\n        \n        if citation_nodes:\n            nx.draw_networkx_nodes(G, pos, nodelist=citation_nodes, node_color='lightgreen', \n                                  node_size=1500, alpha=0.8, label='Citations')\n        \n        # Draw edges with different styles\n        nx.draw_networkx_edges(G, pos, alpha=0.6, width=1.5, edge_color='gray')\n        \n        # Add labels (simplified for readability)\n        labels = {}\n        for node in G.nodes():\n            node_data = G.nodes[node]\n            label = node_data.get('label', node)\n            # Truncate long labels\n            labels[node] = label[:15] + \"...\" if len(label) > 15 else label\n        \n        nx.draw_networkx_labels(G, pos, labels, font_size=8, font_weight='bold')\n        \n        plt.title(f\"Real Knowledge Graph: {PROJECT_NAME}\\n\"\n                 f\"{len(doc_nodes)} Documents, {len(entity_nodes)} Entities, \"\n                 f\"{len(citation_nodes)} Citations, {len(relationships)} Relationships\", \n                 fontsize=14, fontweight='bold')\n        plt.legend(loc='upper right')\n        plt.axis('off')\n        plt.tight_layout()\n        plt.show()\n        \n        print(\"âœ… Real data visualization complete!\")\n        print(f\"ğŸ“Š Displayed {G.number_of_nodes()} nodes and {G.number_of_edges()} edges from your processed knowledge graph\")\n        \n        # Show some sample entities and their details\n        print(\"\\nğŸ” Sample Entities from your knowledge graph:\")\n        for i, entity in enumerate(entities[:5], 1):\n            print(f\"   {i}. {entity['name']} ({entity['type']})\")\n            if entity['description']:\n                desc = entity['description'][:100] + \"...\" if len(entity['description']) > 100 else entity['description']\n                print(f\"      {desc}\")\n        \n        # Close the knowledge graph connection\n        kg_integrator.neo4j_manager.close()\n        \n    except ImportError as e:\n        print(f\"\\nğŸ“ Install required packages: pip install matplotlib networkx\")\n        print(f\"   Error: {e}\")\n        \n    except Exception as e:\n        print(f\"\\nâŒ Visualization error: {str(e)}\")\n        print(\"ğŸ’¡ This might be due to Neo4j connection issues or missing data\")\n        print(\"   Try running the CLI visualization command directly\")\n        \nelse:\n    print(\"âš ï¸  Skipping visualization - processing not complete\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. ğŸ“Š Final Status\n\n**Summary of your knowledge graph:**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š FINAL STATUS\n",
    "print(\"ğŸ“ˆ Getting final system status...\")\n",
    "\n",
    "# Check project status\n",
    "status_cmd = f\"graphrag-mcp status {PROJECT_NAME}\"\n",
    "print(f\"ğŸ“ Command: {status_cmd}\")\n",
    "\n",
    "result = subprocess.run(status_cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… Project status retrieved successfully\")\n",
    "    if result.stdout:\n",
    "        print(\"\\nğŸ“‹ Status Details:\")\n",
    "        print(result.stdout)\n",
    "else:\n",
    "    print(\"âŒ Status check failed\")\n",
    "    print(f\"Error: {result.stderr}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ KNOWLEDGE GRAPH CREATION COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if processing_complete:\n",
    "    print(\"\\nğŸ“Š Your research papers are now:\")\n",
    "    print(\"   âœ… Processed into entities and relationships\")\n",
    "    print(\"   âœ… Stored in persistent Neo4j database\")\n",
    "    print(\"   âœ… Citations tracked and indexed\")\n",
    "    print(\"   âœ… Ready for AI-powered queries\")\n",
    "    print(\"   âœ… Visualized as an interactive graph\")\n",
    "    \n",
    "    print(\"\\nğŸš€ Next Steps:\")\n",
    "    print(\"   1. Start MCP server: graphrag-mcp serve literature-assistant --transport stdio\")\n",
    "    print(\"   2. Connect to Claude Desktop for AI assistant\")\n",
    "    print(\"   3. Use dual-mode tools:\")\n",
    "    print(\"      â€¢ Chat: 'Ask knowledge graph about transformer architectures'\")\n",
    "    print(\"      â€¢ Literature: 'Get facts with citations in APA style'\")\n",
    "    print(\"   4. Generate literature reviews with perfect citations\")\n",
    "    \n",
    "    print(\"\\nğŸ“š You now have an intelligent research assistant!\")\n",
    "    print(\"ğŸ¯ Your knowledge graph reveals connections across your entire corpus.\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâš ï¸  Some steps were not completed successfully.\")\n",
    "    print(\"ğŸ’¡ Review the errors above and ensure all prerequisites are met.\")\n",
    "    print(\"ğŸ”„ You can re-run individual cells to retry specific steps.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}