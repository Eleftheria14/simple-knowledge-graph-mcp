{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Complete Ollama + Knowledge Graph System\n",
    "\n",
    "**All-in-one notebook: Ollama setup + Knowledge graph processing**\n",
    "\n",
    "This notebook:\n",
    "- Installs and starts Ollama in Colab\n",
    "- Downloads required models (llama3.1:8b, nomic-embed-text)\n",
    "- Processes one research paper into a knowledge graph\n",
    "- Creates embeddings and vector store\n",
    "- Shows comprehensive results\n",
    "\n",
    "**Requirements:** Enable GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration: Real vs Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration: Choose your data source\n# Set USE_SAMPLE_DATA = True to test with fake data (fast, no PDF needed)\n# Set USE_SAMPLE_DATA = False to process real PDF papers (requires PDF upload)\n\nUSE_SAMPLE_DATA = True  # Change to False for real PDF processing\n\nif USE_SAMPLE_DATA:\n    print(\"üé≠ DEMO MODE: Using sample data\")\n    print(\"   ‚ö° Fast testing without PDF upload\")\n    print(\"   üß™ Pre-extracted entities and content\")\n    print(\"   üöÄ Perfect for testing the knowledge graph system\")\n    print(\"   üìã Still uses Ollama for processing and embeddings\")\n    print(\"\")\n    print(\"üí° To process real PDFs:\")\n    print(\"   1. Set USE_SAMPLE_DATA = False\")\n    print(\"   2. Wait for Ollama setup (10-15 minutes)\")\n    print(\"   3. Upload your own PDF file\")\nelse:\n    print(\"üìÑ REAL DATA MODE: Processing actual PDFs\")\n    print(\"   üìã Full Ollama setup required\")\n    print(\"   üß† Uses LLM for entity extraction\")\n    print(\"   ‚è±Ô∏è Takes 15-20 minutes total (setup + processing)\")\n    print(\"\")\n    print(\"üí° For quick testing:\")\n    print(\"   1. Set USE_SAMPLE_DATA = True\")\n    print(\"   2. Still gets full Ollama + LLM experience\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in Google Colab and GPU status\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"‚úÖ Running in Google Colab\")\n",
    "    \n",
    "    # Check GPU\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No GPU detected!\")\n",
    "        print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")\n",
    "        if not USE_SAMPLE_DATA:\n",
    "            print(\"   GPU is REQUIRED for real data processing!\")\n",
    "else:\n",
    "    print(\"üè† Running locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if IN_COLAB:\n    print(\"üì¶ Installing dependencies...\")\n    !pip install -q langchain langchain-ollama langchain-chroma\n    !pip install -q chromadb>=0.4.0\n    !pip install -q matplotlib networkx\n    !pip install -q scikit-learn\n    !pip install -q yfiles_jupyter_graphs\n    \n    if not USE_SAMPLE_DATA:\n        print(\"üì¶ Installing PDF processing dependencies...\")\n        !pip install -q PyPDF2 pdfplumber\n    \n    print(\"‚úÖ Dependencies installed!\")\nelse:\n    print(\"üè† Using local environment\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Install and Start Ollama (Real Data Mode Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if IN_COLAB:\n    print(\"üöÄ Installing Ollama in Colab...\")\n    print(\"‚è±Ô∏è This takes about 2-3 minutes...\")\n    \n    # Download and install Ollama\n    !curl -fsSL https://ollama.ai/install.sh | sh\n    \n    print(\"‚úÖ Ollama installed!\")\n    \nelse:\n    print(\"üè† Assuming local Ollama is running\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Start Ollama Server (Real Data Mode Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if IN_COLAB:\n    import subprocess\n    import time\n    import threading\n    import os\n    \n    print(\"üöÄ Starting Ollama server...\")\n    \n    # Function to run Ollama serve in background\n    def run_ollama_serve():\n        os.system(\"ollama serve > /dev/null 2>&1 &\")\n    \n    # Start Ollama in a separate thread\n    ollama_thread = threading.Thread(target=run_ollama_serve, daemon=True)\n    ollama_thread.start()\n    \n    # Wait for server to start\n    print(\"‚è≥ Waiting for server to start...\")\n    time.sleep(10)\n    \n    # Test if server is running\n    try:\n        result = !curl -s http://localhost:11434/api/version\n        if result:\n            print(\"‚úÖ Ollama server is running!\")\n            print(f\"   Version info: {result[0] if result else 'N/A'}\")\n        else:\n            print(\"‚ùå Server not responding\")\n    except:\n        print(\"‚ùå Failed to check server status\")\n        \nelse:\n    print(\"üè† Assuming local Ollama server is running\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Download Models (Real Data Mode Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if IN_COLAB:\n    print(\"üì• Downloading models (this takes 5-10 minutes)...\")\n    print(\"‚òï Perfect time for a coffee break!\")\n    print(\"\")\n    \n    # Download LLM model\n    print(\"üß† Downloading llama3.1:8b (main LLM)...\")\n    !ollama pull llama3.1:8b\n    \n    print(\"\")\n    print(\"üî§ Downloading nomic-embed-text (embeddings)...\")\n    !ollama pull nomic-embed-text\n    \n    print(\"\")\n    print(\"‚úÖ All models downloaded and ready!\")\n    \nelse:\n    print(\"üè† Check local models with: ollama list\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Ollama Connection (Real Data Mode Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test basic LLM functionality\ntry:\n    from langchain_ollama import ChatOllama\n    \n    print(\"üß™ Testing LLM connection...\")\n    \n    # Create LLM instance\n    llm = ChatOllama(\n        model=\"llama3.1:8b\",\n        temperature=0.1\n    )\n    \n    # Simple test\n    response = llm.invoke(\"Say 'Hello from Colab!' and nothing else.\")\n    print(f\"‚úÖ LLM Response: {response.content}\")\n    \n    # Test embeddings\n    from langchain_ollama import OllamaEmbeddings\n    \n    print(\"üî§ Testing embeddings...\")\n    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n    \n    test_embedding = embeddings.embed_query(\"This is a test.\")\n    print(f\"‚úÖ Embedding created: {len(test_embedding)} dimensions\")\n    \n    print(\"\")\n    print(\"üéâ SUCCESS! Ollama is working perfectly in Colab!\")\n    print(\"üöÄ Ready to process research papers!\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Test failed: {e}\")\n    print(\"üí° You may need to restart runtime and try again\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Load Paper Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\nif USE_SAMPLE_DATA:\n    print(\"üé≠ Loading sample paper data...\")\n    \n    # Use built-in sample data (no download needed)\n    SAMPLE_PAPER_DATA = {\n        \"title\": \"Machine Learning for Drug Discovery: A Comprehensive Review\",\n        \"content\": \"\"\"Machine Learning for Drug Discovery: A Comprehensive Review\n\nAuthors: Dr. Sarah Chen (MIT), Prof. Michael Torres (Stanford), Dr. Lisa Wang (UC Berkeley)\n\nAbstract:\nThis comprehensive review examines the application of machine learning techniques to drug discovery processes. \nWe analyze various computational approaches including deep learning, graph neural networks, and transformer \narchitectures for molecular property prediction and drug-target interaction modeling.\n\nMethods:\nWe conducted a systematic review of machine learning applications in drug discovery, focusing on:\n\n1. Molecular Property Prediction\n- Graph Convolutional Networks (GCNs) for molecular representation\n- Transformer models adapted for SMILES sequences\n- Recurrent Neural Networks for sequential molecular data\n\n2. Drug-Target Interaction Prediction\n- Matrix factorization techniques\n- Deep neural networks with protein sequence embeddings\n- Graph-based approaches combining molecular and protein structures\n\nTechnologies and Tools:\n- Deep Learning: TensorFlow, PyTorch, Keras\n- Cheminformatics: RDKit, OpenEye, ChemAxon\n- Graph Processing: DGL, PyTorch Geometric, NetworkX\n\nConclusions:\nMachine learning has fundamentally transformed drug discovery by enabling more efficient exploration of chemical \nand biological space. Future success will depend on continued collaboration between computational scientists, \nmedicinal chemists, and clinical researchers.\"\"\",\n        \"pages\": 12,\n        \"char_count\": 1234\n    }\n    \n    # Pre-extracted entities\n    SAMPLE_ENTITIES = {\n        \"authors\": [\"Dr. Sarah Chen\", \"Prof. Michael Torres\", \"Dr. Lisa Wang\"],\n        \"institutions\": [\"MIT\", \"Stanford\", \"UC Berkeley\"],\n        \"methods\": [\"Graph Convolutional Networks\", \"Transformer models\", \"Recurrent Neural Networks\"],\n        \"concepts\": [\"Drug discovery\", \"Machine learning\", \"Molecular property prediction\"],\n        \"datasets\": [\"ChEMBL\", \"PubChem\", \"ZINC\"],\n        \"technologies\": [\"TensorFlow\", \"PyTorch\", \"RDKit\", \"NetworkX\"]\n    }\n    \n    # Use sample data\n    paper_path = \"sample_data\"  # Placeholder\n    paper_title = SAMPLE_PAPER_DATA[\"title\"]\n    text_content = SAMPLE_PAPER_DATA[\"content\"]\n    entities = SAMPLE_ENTITIES  # Pre-extracted entities\n    \n    print(f\"‚úÖ Sample data loaded!\")\n    print(f\"üì∞ Title: {paper_title}\")\n    print(f\"üìä Content length: {len(text_content):,} characters\")\n    print(f\"üè∑Ô∏è Pre-extracted entities: {sum(len(v) for v in entities.values())}\")\n    print(f\"üìÑ Simulated pages: {SAMPLE_PAPER_DATA['pages']}\")\n    \nelif IN_COLAB:\n    print(\"üì§ Choose how to load your PDF:\")\n    print(\"   1Ô∏è‚É£ Upload file using file picker\")\n    print(\"   2Ô∏è‚É£ Use file already in Colab storage\")\n    print(\"\")\n    \n    # Check for existing PDFs in current directory\n    existing_pdfs = [f for f in os.listdir('.') if f.endswith('.pdf')]\n    \n    if existing_pdfs:\n        print(f\"üìÅ Found {len(existing_pdfs)} PDF(s) in current directory:\")\n        for i, pdf in enumerate(existing_pdfs, 1):\n            file_size = os.path.getsize(pdf) / (1024*1024)  # MB\n            print(f\"   {i}. {pdf} ({file_size:.1f} MB)\")\n        print(\"\")\n        \n        choice = input(\"Type filename to use existing PDF, or press Enter to upload new file: \").strip()\n        \n        if choice and choice in existing_pdfs:\n            paper_path = choice\n            print(f\"‚úÖ Using existing file: {paper_path}\")\n        else:\n            print(\"üì§ Upload a new PDF file...\")\n            from google.colab import files\n            uploaded = files.upload()\n            \n            # Get the first PDF\n            paper_path = None\n            for filename in uploaded.keys():\n                if filename.endswith('.pdf'):\n                    paper_path = filename\n                    break\n    else:\n        print(\"üìÅ No existing PDFs found in current directory\")\n        print(\"üì§ Upload a PDF file...\")\n        from google.colab import files\n        uploaded = files.upload()\n        \n        # Get the first PDF\n        paper_path = None\n        for filename in uploaded.keys():\n            if filename.endswith('.pdf'):\n                paper_path = filename\n                break\n    \n    if paper_path:\n        file_size = os.path.getsize(paper_path) / (1024*1024)  # MB\n        print(f\"‚úÖ Paper selected: {paper_path} ({file_size:.1f} MB)\")\n        \n        # Show file details\n        print(f\"üìÅ File location: /content/{paper_path}\")\n        print(f\"üìä File size: {file_size:.1f} MB\")\n    else:\n        print(\"‚ùå No PDF file found! Please upload a PDF.\")\n        \nelse:\n    # Use local example\n    paper_path = '../../examples/d4sc03921a.pdf'\n    if os.path.exists(paper_path):\n        print(f\"‚úÖ Using local paper: {paper_path}\")\n    else:\n        print(f\"‚ùå Local paper not found: {paper_path}\")\n        paper_path = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Extract Text from PDF (Real Data Mode Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SAMPLE_DATA:\n",
    "    print(\"üé≠ Using sample text content (already loaded)\")\n",
    "    print(f\"‚úÖ Text content ready!\")\n",
    "    print(f\"üì∞ Title: {paper_title}\")\n",
    "    print(f\"üìä Content length: {len(text_content):,} characters\")\n",
    "    print(f\"üìÑ Sample paper simulates {SAMPLE_PAPER_DATA['pages']} pages\")\n",
    "    \n",
    "elif paper_path:\n",
    "    import pdfplumber\n",
    "    \n",
    "    print(f\"üìÑ Extracting text from: {paper_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract text\n",
    "        with pdfplumber.open(paper_path) as pdf:\n",
    "            text_content = \"\"\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text_content += page_text + \"\\n\\n\"\n",
    "        \n",
    "        # Get paper title (first substantial line)\n",
    "        lines = text_content.split('\\n')\n",
    "        paper_title = \"Unknown Title\"\n",
    "        for line in lines:\n",
    "            if len(line.strip()) > 20 and not line.strip().isdigit():\n",
    "                paper_title = line.strip()[:100]\n",
    "                break\n",
    "        \n",
    "        print(f\"‚úÖ Text extracted successfully!\")\n",
    "        print(f\"üì∞ Title: {paper_title}\")\n",
    "        print(f\"üìä Content length: {len(text_content):,} characters\")\n",
    "        print(f\"üìÑ Pages processed: {len(pdf.pages)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to extract text: {e}\")\n",
    "        text_content = None\n",
    "        paper_title = None\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No paper to process\")\n",
    "    text_content = None\n",
    "    paper_title = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Extract Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if USE_SAMPLE_DATA:\n    print(\"üé≠ Using pre-extracted sample entities\")\n    print(f\"‚úÖ Entities already loaded!\")\n    \n    # Count total entities\n    total_entities = sum(len(entity_list) for entity_list in entities.values())\n    print(f\"üìä Total entities: {total_entities}\")\n    \n    # Show entity breakdown\n    print(f\"\\nüìã Entity categories:\")\n    for category, entity_list in entities.items():\n        if entity_list:\n            print(f\"   ‚Ä¢ {category}: {len(entity_list)} items\")\n    \nelif text_content:\n    from langchain_ollama import ChatOllama\n    from langchain_core.prompts import ChatPromptTemplate\n    import json\n    \n    print(\"üß† Extracting entities with LLM...\")\n    print(\"‚è±Ô∏è This takes 3-5 minutes for full paper analysis...\")\n    \n    # Create LLM\n    llm = ChatOllama(\n        model=\"llama3.1:8b\",\n        temperature=0.1\n    )\n    \n    # Enhanced entity extraction prompt for full paper\n    prompt_text = '''You are an expert at extracting entities from research papers. Analyze the ENTIRE paper content below and extract ALL relevant entities in these categories. Be comprehensive and thorough.\n\nExtract entities from the complete paper content:\n\n{content}\n\nReturn ONLY a valid JSON object with these categories. Extract as many relevant entities as possible:\n\n{\n  \"authors\": [\"All author names mentioned\"],\n  \"institutions\": [\"All universities, companies, organizations\"],\n  \"methods\": [\"All techniques, algorithms, approaches, methodologies\"],\n  \"concepts\": [\"All key concepts, theories, principles, phenomena\"],\n  \"datasets\": [\"All datasets, databases, corpora mentioned\"],\n  \"technologies\": [\"All software, tools, frameworks, programming languages\"],\n  \"chemicals\": [\"All chemical compounds, molecules, materials\"],\n  \"metrics\": [\"All evaluation metrics, measurements, scores\"],\n  \"applications\": [\"All use cases, applications, domains\"],\n  \"findings\": [\"All key results, discoveries, conclusions\"]\n}\n\nBe exhaustive - extract everything relevant. Include abbreviations and full names.\n\nJSON:'''\n    \n    prompt = ChatPromptTemplate.from_template(prompt_text)\n    \n    try:\n        # Process entire paper content (chunked if too long)\n        max_chars = 25000  # Safe limit for llama3.1:8b\n        \n        if len(text_content) > max_chars:\n            print(f\"üìÑ Paper is long ({len(text_content):,} chars), processing in chunks...\")\n            \n            # Split into chunks\n            chunk_size = max_chars\n            chunks = [text_content[i:i+chunk_size] for i in range(0, len(text_content), chunk_size)]\n            \n            all_entities = {\n                \"authors\": set(),\n                \"institutions\": set(),\n                \"methods\": set(),\n                \"concepts\": set(),\n                \"datasets\": set(),\n                \"technologies\": set(),\n                \"chemicals\": set(),\n                \"metrics\": set(),\n                \"applications\": set(),\n                \"findings\": set()\n            }\n            \n            print(f\"üîÑ Processing {len(chunks)} chunks...\")\n            \n            for i, chunk in enumerate(chunks, 1):\n                print(f\"   Processing chunk {i}/{len(chunks)}...\")\n                \n                chain = prompt | llm\n                result = chain.invoke({\n                    \"content\": chunk\n                })\n                \n                # Extract JSON from response\n                response_text = result.content\n                json_start = response_text.find('{')\n                json_end = response_text.rfind('}') + 1\n                \n                if json_start != -1 and json_end != -1:\n                    try:\n                        json_str = response_text[json_start:json_end]\n                        chunk_entities = json.loads(json_str)\n                        \n                        # Merge entities from this chunk\n                        for category, entity_list in chunk_entities.items():\n                            if category in all_entities and isinstance(entity_list, list):\n                                all_entities[category].update(entity_list)\n                                \n                    except json.JSONDecodeError:\n                        print(f\"   ‚ö†Ô∏è Could not parse JSON from chunk {i}\")\n                        continue\n            \n            # Convert sets back to lists\n            entities = {k: list(v) for k, v in all_entities.items()}\n            \n        else:\n            print(f\"üìÑ Processing complete paper ({len(text_content):,} chars)...\")\n            \n            # Process entire paper at once\n            chain = prompt | llm\n            result = chain.invoke({\n                \"content\": text_content\n            })\n            \n            # Extract JSON from response\n            response_text = result.content\n            json_start = response_text.find('{')\n            json_end = response_text.rfind('}') + 1\n            \n            if json_start != -1 and json_end != -1:\n                json_str = response_text[json_start:json_end]\n                entities = json.loads(json_str)\n            else:\n                print(\"‚ùå Could not parse JSON response\")\n                entities = None\n        \n        if entities:\n            print(\"‚úÖ Entities extracted successfully!\")\n            \n            # Count total entities\n            total_entities = sum(len(entity_list) for entity_list in entities.values())\n            print(f\"üìä Total entities found: {total_entities}\")\n            \n            # Show detailed breakdown\n            print(f\"\\nüìã Detailed entity breakdown:\")\n            for category, entity_list in entities.items():\n                if entity_list:\n                    print(f\"   ‚Ä¢ {category}: {len(entity_list)} items\")\n                    if len(entity_list) <= 5:\n                        print(f\"     Examples: {', '.join(entity_list)}\")\n                    else:\n                        print(f\"     Examples: {', '.join(entity_list[:5])}...\")\n            \n        else:\n            print(\"‚ùå No entities extracted\")\n            \n    except Exception as e:\n        print(f\"‚ùå Entity extraction failed: {e}\")\n        entities = None\n        \nelse:\n    print(\"‚ùå No text content to process\")\n    entities = None"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Create Embeddings and Vector Store (Real Data Mode Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if text_content and entities:\n    from langchain_ollama import OllamaEmbeddings\n    from langchain_chroma import Chroma\n    from langchain_core.documents import Document\n    from langchain.text_splitter import RecursiveCharacterTextSplitter\n    import json\n    \n    print(\"üî§ Creating embeddings and vector store...\")\n    print(\"‚è±Ô∏è This takes 2-3 minutes...\")\n    \n    # Create embeddings model\n    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n    \n    # Split text into chunks for embeddings\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,\n        chunk_overlap=200,\n        length_function=len\n    )\n    \n    chunks = text_splitter.split_text(text_content)\n    print(f\"üìÑ Created {len(chunks)} text chunks\")\n    \n    # Create documents with metadata\n    documents = []\n    for i, chunk in enumerate(chunks):\n        metadata = {\n            'paper_title': paper_title,\n            'chunk_id': f\"chunk_{i}\",\n            'chunk_index': i,\n            'total_chunks': len(chunks),\n            # Add entity metadata for graph connections\n            'authors': json.dumps(entities.get('authors', [])),\n            'institutions': json.dumps(entities.get('institutions', [])),\n            'methods': json.dumps(entities.get('methods', [])),\n            'concepts': json.dumps(entities.get('concepts', [])),\n            'datasets': json.dumps(entities.get('datasets', [])),\n            'technologies': json.dumps(entities.get('technologies', []))\n        }\n        \n        doc = Document(page_content=chunk, metadata=metadata)\n        documents.append(doc)\n    \n    # Create vector store\n    persist_directory = \"/tmp/chroma_test\"\n    \n    print(\"üóÑÔ∏è Creating vector store with ChromaDB...\")\n    vector_store = Chroma(\n        embedding_function=embeddings,\n        persist_directory=persist_directory\n    )\n    \n    # Add documents to vector store\n    document_ids = vector_store.add_documents(documents)\n    \n    print(f\"‚úÖ Vector store created!\")\n    print(f\"   üìù {len(documents)} documents added\")\n    print(f\"   üî§ Embeddings created with nomic-embed-text\")\n    print(f\"   üóÑÔ∏è Stored in ChromaDB at {persist_directory}\")\n    \n    # Test semantic search\n    print(\"\\nüîç Testing semantic search...\")\n    query = \"What methods were used in this research?\"\n    results = vector_store.similarity_search(query, k=3)\n    \n    print(f\"Query: '{query}'\")\n    print(f\"Found {len(results)} relevant chunks:\")\n    for i, result in enumerate(results, 1):\n        print(f\"  {i}. {result.page_content[:100]}...\")\n    \nelse:\n    print(\"‚ùå No text content or entities to process - skipping vector store creation\")\n    vector_store = None\n    documents = []"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Build Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if entities:\n",
    "    import networkx as nx\n",
    "    \n",
    "    print(\"üï∏Ô∏è Building knowledge graph structure...\")\n",
    "    \n",
    "    # Create NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add entity nodes\n",
    "    node_colors = {\n",
    "        'authors': 'lightblue',\n",
    "        'institutions': 'lightgreen', \n",
    "        'methods': 'orange',\n",
    "        'concepts': 'pink',\n",
    "        'datasets': 'yellow',\n",
    "        'technologies': 'lightgray'\n",
    "    }\n",
    "    \n",
    "    all_nodes = []\n",
    "    node_color_map = []\n",
    "    \n",
    "    for category, entity_list in entities.items():\n",
    "        for entity in entity_list:\n",
    "            G.add_node(entity, category=category)\n",
    "            all_nodes.append(entity)\n",
    "            node_color_map.append(node_colors.get(category, 'white'))\n",
    "    \n",
    "    # Add edges between entities (simple co-occurrence)\n",
    "    categories = list(entities.keys())\n",
    "    \n",
    "    for i, cat1 in enumerate(categories):\n",
    "        for cat2 in categories[i:]:  # Include same category connections\n",
    "            entities1 = entities[cat1]\n",
    "            entities2 = entities[cat2]\n",
    "            \n",
    "            if cat1 == cat2:\n",
    "                # Connect entities within same category\n",
    "                for j, entity1 in enumerate(entities1):\n",
    "                    for entity2 in entities1[j+1:]:\n",
    "                        G.add_edge(entity1, entity2, relationship=f\"same_{cat1}\")\n",
    "            else:\n",
    "                # Connect across categories (sample connections)\n",
    "                for entity1 in entities1[:2]:  # Limit connections\n",
    "                    for entity2 in entities2[:2]:\n",
    "                        G.add_edge(entity1, entity2, relationship=f\"{cat1}_to_{cat2}\")\n",
    "    \n",
    "    # Graph statistics\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "    \n",
    "    print(f\"‚úÖ Knowledge graph built successfully!\")\n",
    "    print(f\"   üîó Nodes: {num_nodes}\")\n",
    "    print(f\"   üìä Edges: {num_edges}\")\n",
    "    print(f\"   üìÇ Categories: {len([k for k, v in entities.items() if v])}\")\n",
    "    \n",
    "    # Store for visualization\n",
    "    knowledge_graph = {\n",
    "        'graph': G,\n",
    "        'entities': entities,\n",
    "        'node_colors': node_color_map,\n",
    "        'stats': {\n",
    "            'nodes': num_nodes,\n",
    "            'edges': num_edges,\n",
    "            'categories': len([k for k, v in entities.items() if v])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No entities to build graph from\")\n",
    "    knowledge_graph = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if entities and knowledge_graph:\n    print(\"üìä Creating interactive yFiles knowledge graph visualization...\")\n    \n    try:\n        from yfiles_jupyter_graphs import GraphWidget\n        import networkx as nx\n        \n        G = knowledge_graph['graph']\n        \n        if G.number_of_nodes() > 0:\n            print(f\"üéÆ Building interactive graph with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges...\")\n            \n            # Create yFiles widget\n            widget = GraphWidget(graph=G)\n            \n            # Configure node styling by category\n            def configure_node_style(node):\n                category = G.nodes[node].get('category', 'unknown')\n                \n                # Color mapping for categories\n                colors = {\n                    'authors': '#4A90E2',       # Professional blue\n                    'institutions': '#7ED321',  # Fresh green\n                    'methods': '#F5A623',       # Warm orange\n                    'concepts': '#D0021B',      # Strong red\n                    'datasets': '#9013FE',      # Purple\n                    'technologies': '#50E3C2',  # Teal\n                    'chemicals': '#B8E986',     # Light green\n                    'metrics': '#4BD5EE',       # Cyan\n                    'applications': '#F8E71C',  # Yellow\n                    'findings': '#BD10E0'       # Magenta\n                }\n                \n                # Size based on connections\n                node_degree = G.degree(node)\n                size = max(20, min(60, node_degree * 8))\n                \n                return {\n                    'color': colors.get(category, '#999999'),\n                    'size': size,\n                    'label': node[:25] + \"...\" if len(node) > 25 else node\n                }\n            \n            # Apply node styling\n            widget.set_node_styles_mapping(configure_node_style)\n            \n            # Configure edge styling\n            def configure_edge_style(edge):\n                return {\n                    'color': '#CCCCCC',\n                    'thickness': 2,\n                    'style': 'solid'\n                }\n            \n            widget.set_edge_styles_mapping(configure_edge_style)\n            \n            # Set layout\n            widget.set_layout('organic')  # Nice organic layout\n            \n            # Enable overview and navigation\n            widget.overview_enabled = True\n            widget.context_start_with = 'clean-slate'\n            \n            print(\"‚úÖ Interactive yFiles graph created!\")\n            print(\"üéÆ Controls:\")\n            print(\"   ‚Ä¢ Drag nodes to rearrange\")\n            print(\"   ‚Ä¢ Zoom with mouse wheel\")\n            print(\"   ‚Ä¢ Click nodes to highlight connections\")\n            print(\"   ‚Ä¢ Use overview panel for navigation\")\n            print(\"\")\n            \n            # Show the widget\n            display(widget)\n            \n            # Create legend\n            print(\"üé® Entity Categories:\")\n            legend_items = [\n                (\"Authors\", \"üë§\", \"#4A90E2\"),\n                (\"Institutions\", \"üèõÔ∏è\", \"#7ED321\"),\n                (\"Methods\", \"üî¨\", \"#F5A623\"),\n                (\"Concepts\", \"üí°\", \"#D0021B\"),\n                (\"Datasets\", \"üìä\", \"#9013FE\"),\n                (\"Technologies\", \"‚öôÔ∏è\", \"#50E3C2\"),\n                (\"Chemicals\", \"üß™\", \"#B8E986\"),\n                (\"Metrics\", \"üìè\", \"#4BD5EE\"),\n                (\"Applications\", \"üéØ\", \"#F8E71C\"),\n                (\"Findings\", \"üîç\", \"#BD10E0\")\n            ]\n            \n            for name, emoji, color in legend_items:\n                count = len(entities.get(name.lower(), []))\n                if count > 0:\n                    print(f\"   {emoji} {name}: {count} items\")\n            \n        else:\n            print(\"‚ùå No nodes in graph to visualize\")\n            \n    except ImportError:\n        print(\"‚ùå yfiles_jupyter_graphs not available\")\n        print(\"üí° Install with: pip install yfiles_jupyter_graphs\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error creating yFiles visualization: {e}\")\n        print(\"üìä Falling back to summary statistics\")\n    \n    # Print graph summary\n    print(f\"\\nüìä KNOWLEDGE GRAPH SUMMARY:\")\n    print(f\"   üìÑ Paper: {paper_title[:50]}...\")\n    print(f\"   üè∑Ô∏è Total entities: {sum(len(entity_list) for entity_list in entities.values())}\")\n    print(f\"   üîó Graph nodes: {knowledge_graph['stats']['nodes']}\")\n    print(f\"   üìä Graph edges: {knowledge_graph['stats']['edges']}\")\n    print(f\"   üî§ Document chunks: {len(documents) if 'documents' in locals() else 0}\")\n    print(f\"   üóÑÔ∏è Vector store: {'‚úÖ Created' if 'vector_store' in locals() and vector_store else 'üé≠ Simulated (demo mode)'}\")\n    \nelse:\n    print(\"‚ùå No data to visualize\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# üíæ Save Knowledge Graph and Results\n\nif entities and knowledge_graph:\n    import json\n    import pickle\n    from datetime import datetime\n    \n    print(\"üíæ Saving knowledge graph and results...\")\n    \n    # Create timestamp for unique filenames\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    paper_name = paper_title[:30].replace(\" \", \"_\").replace(\"/\", \"_\") if paper_title else \"unknown_paper\"\n    base_filename = f\"{paper_name}_{timestamp}\"\n    \n    # 1. Save entities as JSON (human-readable)\n    entities_file = f\"{base_filename}_entities.json\"\n    with open(entities_file, 'w') as f:\n        json.dump(entities, f, indent=2)\n    print(f\"‚úÖ Entities saved: {entities_file}\")\n    \n    # 2. Save graph as GraphML (standard format, works with many tools)\n    graph_file = f\"{base_filename}_graph.graphml\"\n    import networkx as nx\n    nx.write_graphml(knowledge_graph['graph'], graph_file)\n    print(f\"‚úÖ Graph saved: {graph_file}\")\n    \n    # 3. Save complete knowledge graph as pickle (Python objects)\n    kg_file = f\"{base_filename}_knowledge_graph.pkl\"\n    with open(kg_file, 'wb') as f:\n        pickle.dump(knowledge_graph, f)\n    print(f\"‚úÖ Complete KG saved: {kg_file}\")\n    \n    # 4. Save paper metadata and text\n    metadata_file = f\"{base_filename}_metadata.json\"\n    metadata = {\n        \"title\": paper_title,\n        \"timestamp\": timestamp,\n        \"content_length\": len(text_content) if text_content else 0,\n        \"total_entities\": sum(len(entity_list) for entity_list in entities.values()),\n        \"graph_nodes\": knowledge_graph['stats']['nodes'],\n        \"graph_edges\": knowledge_graph['stats']['edges'],\n        \"file_path\": paper_path if paper_path != \"sample_data\" else \"sample_data\"\n    }\n    \n    if not USE_SAMPLE_DATA and text_content:\n        # Save text content for real papers\n        text_file = f\"{base_filename}_content.txt\"\n        with open(text_file, 'w', encoding='utf-8') as f:\n            f.write(text_content)\n        metadata[\"content_file\"] = text_file\n        print(f\"‚úÖ Text content saved: {text_file}\")\n    \n    with open(metadata_file, 'w') as f:\n        json.dump(metadata, f, indent=2)\n    print(f\"‚úÖ Metadata saved: {metadata_file}\")\n    \n    # 5. Create a summary report\n    report_file = f\"{base_filename}_report.md\"\n    with open(report_file, 'w') as f:\n        f.write(f\"# Knowledge Graph Report\\n\\n\")\n        f.write(f\"**Paper:** {paper_title}\\n\")\n        f.write(f\"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n        f.write(f\"**Mode:** {'Sample Data' if USE_SAMPLE_DATA else 'Real PDF'}\\n\\n\")\n        f.write(f\"## Statistics\\n\\n\")\n        f.write(f\"- **Total Entities:** {sum(len(entity_list) for entity_list in entities.values())}\\n\")\n        f.write(f\"- **Graph Nodes:** {knowledge_graph['stats']['nodes']}\\n\")\n        f.write(f\"- **Graph Edges:** {knowledge_graph['stats']['edges']}\\n\")\n        f.write(f\"- **Content Length:** {len(text_content) if text_content else 0:,} characters\\n\\n\")\n        f.write(f\"## Entity Breakdown\\n\\n\")\n        for category, entity_list in entities.items():\n            f.write(f\"### {category.title()}\\n\")\n            for entity in entity_list:\n                f.write(f\"- {entity}\\n\")\n            f.write(f\"\\n\")\n        f.write(f\"## Files Generated\\n\\n\")\n        f.write(f\"- `{entities_file}` - Entities in JSON format\\n\")\n        f.write(f\"- `{graph_file}` - Graph in GraphML format\\n\")\n        f.write(f\"- `{kg_file}` - Complete knowledge graph (Python pickle)\\n\")\n        f.write(f\"- `{metadata_file}` - Paper metadata\\n\")\n        if not USE_SAMPLE_DATA and text_content:\n            f.write(f\"- `{text_file}` - Extracted text content\\n\")\n        f.write(f\"- `{report_file}` - This report\\n\")\n    \n    print(f\"‚úÖ Report saved: {report_file}\")\n    \n    print(f\"\\nüìä SAVED FILES SUMMARY:\")\n    print(f\"üìÅ All files saved to: /content/\")\n    print(f\"üè∑Ô∏è Base filename: {base_filename}\")\n    print(f\"üìÑ Files created:\")\n    print(f\"   ‚Ä¢ {entities_file} (JSON entities)\")\n    print(f\"   ‚Ä¢ {graph_file} (GraphML graph)\")\n    print(f\"   ‚Ä¢ {kg_file} (Python pickle)\")\n    print(f\"   ‚Ä¢ {metadata_file} (metadata)\")\n    if not USE_SAMPLE_DATA and text_content:\n        print(f\"   ‚Ä¢ {text_file} (text content)\")\n    print(f\"   ‚Ä¢ {report_file} (summary report)\")\n    \n    # 6. Download files option (Colab only)\n    if IN_COLAB:\n        print(f\"\\nüì• DOWNLOAD FILES:\")\n        print(f\"Right-click files in the file panel to download\")\n        print(f\"Or run this code to download all at once:\")\n        print(f\"```python\")\n        print(f\"from google.colab import files\")\n        print(f\"files.download('{entities_file}')\")\n        print(f\"files.download('{graph_file}')\")\n        print(f\"files.download('{kg_file}')\")\n        print(f\"files.download('{metadata_file}')\")\n        if not USE_SAMPLE_DATA and text_content:\n            print(f\"files.download('{text_file}')\")\n        print(f\"files.download('{report_file}')\")\n        print(f\"```\")\n    \n    # 7. How to reload the knowledge graph\n    print(f\"\\nüîÑ TO RELOAD THIS KNOWLEDGE GRAPH LATER:\")\n    print(f\"```python\")\n    print(f\"import pickle\")\n    print(f\"import json\")\n    print(f\"import networkx as nx\")\n    print(f\"\")\n    print(f\"# Load entities\")\n    print(f\"with open('{entities_file}', 'r') as f:\")\n    print(f\"    entities = json.load(f)\")\n    print(f\"\")\n    print(f\"# Load complete knowledge graph\")\n    print(f\"with open('{kg_file}', 'rb') as f:\")\n    print(f\"    knowledge_graph = pickle.load(f)\")\n    print(f\"\")\n    print(f\"# Load graph separately (if needed)\")\n    print(f\"graph = nx.read_graphml('{graph_file}')\")\n    print(f\"```\")\n    \nelse:\n    print(\"‚ùå No knowledge graph to save\")"
  },
  {
   "cell_type": "markdown",
   "source": "## üéâ Complete Success!\n\nIf you see results above, you have successfully created a **complete knowledge graph system** with Ollama running in Colab!\n\n### ‚úÖ What You Accomplished:\n\n**Infrastructure:**\n- ‚úÖ **Installed Ollama** in Google Colab environment\n- ‚úÖ **Downloaded models** (llama3.1:8b + nomic-embed-text)\n- ‚úÖ **Started server** successfully in background\n\n**Knowledge Graph System:**\n- ‚úÖ **Processed research paper** with PDF text extraction  \n- ‚úÖ **Extracted entities** using local Ollama LLM\n- ‚úÖ **Created embeddings** with nomic-embed-text model (real mode)\n- ‚úÖ **Built vector store** with ChromaDB for semantic search (real mode)\n- ‚úÖ **Constructed knowledge graph** with NetworkX relationships\n- ‚úÖ **Interactive visualization** with Cytoscape widgets\n- ‚úÖ **Saved complete results** in multiple formats\n\n### üîç Technical Stack Validated:\n\n**Local LLM Processing**: Ollama running on Colab T4 GPU  \n**Entity Extraction**: Authors, institutions, methods, concepts, datasets, technologies  \n**Vector Embeddings**: Semantic search capabilities over paper chunks  \n**Knowledge Graph**: NetworkX graph with entity relationships  \n**Vector Store**: ChromaDB with persistent storage  \n**Hybrid Retrieval**: Both vector similarity and graph traversal  \n**Interactive Visualization**: Drag, zoom, click nodes with ipycytoscape\n**Complete Save System**: JSON, GraphML, pickle, and summary files\n\n### üöÄ Next Steps:\n- Process multiple papers for cross-paper connections\n- Build full corpus for literature review generation\n- Integrate with MCP server for Claude Max access\n- Scale to 10-50 papers for comprehensive literature analysis\n\n**You've proven the complete technical feasibility!** üéØ\n\nThis same system scales to full literature review generation with citation-accurate writing!",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}